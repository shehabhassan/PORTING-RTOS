
RTOS_PORTING.elf:     file format elf32-avr

Sections:
Idx Name          Size      VMA       LMA       File off  Algn
  0 .text         00002876  00000000  00000000  00000094  2**1
                  CONTENTS, ALLOC, LOAD, READONLY, CODE
  1 .data         0000000c  00800060  00002876  0000290a  2**0
                  CONTENTS, ALLOC, LOAD, DATA
  2 .bss          0000067c  0080006c  0080006c  00002916  2**0
                  ALLOC
  3 .stab         00000750  00000000  00000000  00002918  2**2
                  CONTENTS, READONLY, DEBUGGING
  4 .stabstr      000000e7  00000000  00000000  00003068  2**0
                  CONTENTS, READONLY, DEBUGGING
  5 .debug_aranges 00000160  00000000  00000000  00003150  2**3
                  CONTENTS, READONLY, DEBUGGING
  6 .debug_info   00003666  00000000  00000000  000032b0  2**0
                  CONTENTS, READONLY, DEBUGGING
  7 .debug_abbrev 00000c60  00000000  00000000  00006916  2**0
                  CONTENTS, READONLY, DEBUGGING
  8 .debug_line   00001376  00000000  00000000  00007576  2**0
                  CONTENTS, READONLY, DEBUGGING
  9 .debug_frame  00000b74  00000000  00000000  000088ec  2**2
                  CONTENTS, READONLY, DEBUGGING
 10 .debug_str    00001517  00000000  00000000  00009460  2**0
                  CONTENTS, READONLY, DEBUGGING
 11 .debug_loc    000041d5  00000000  00000000  0000a977  2**0
                  CONTENTS, READONLY, DEBUGGING
 12 .debug_ranges 00000150  00000000  00000000  0000eb4c  2**0
                  CONTENTS, READONLY, DEBUGGING

Disassembly of section .text:

00000000 <__vectors>:
       0:	0c 94 2a 00 	jmp	0x54	; 0x54 <__ctors_end>
       4:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
       8:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
       c:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      10:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      14:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      18:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      1c:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      20:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      24:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      28:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      2c:	0c 94 ef 06 	jmp	0xdde	; 0xdde <__vector_11>
      30:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      34:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      38:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      3c:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      40:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      44:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      48:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      4c:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>
      50:	0c 94 47 00 	jmp	0x8e	; 0x8e <__bad_interrupt>

00000054 <__ctors_end>:
      54:	11 24       	eor	r1, r1
      56:	1f be       	out	0x3f, r1	; 63
      58:	cf e5       	ldi	r28, 0x5F	; 95
      5a:	d8 e0       	ldi	r29, 0x08	; 8
      5c:	de bf       	out	0x3e, r29	; 62
      5e:	cd bf       	out	0x3d, r28	; 61

00000060 <__do_copy_data>:
      60:	10 e0       	ldi	r17, 0x00	; 0
      62:	a0 e6       	ldi	r26, 0x60	; 96
      64:	b0 e0       	ldi	r27, 0x00	; 0
      66:	e6 e7       	ldi	r30, 0x76	; 118
      68:	f8 e2       	ldi	r31, 0x28	; 40
      6a:	02 c0       	rjmp	.+4      	; 0x70 <__do_copy_data+0x10>
      6c:	05 90       	lpm	r0, Z+
      6e:	0d 92       	st	X+, r0
      70:	ac 36       	cpi	r26, 0x6C	; 108
      72:	b1 07       	cpc	r27, r17
      74:	d9 f7       	brne	.-10     	; 0x6c <__do_copy_data+0xc>

00000076 <__do_clear_bss>:
      76:	16 e0       	ldi	r17, 0x06	; 6
      78:	ac e6       	ldi	r26, 0x6C	; 108
      7a:	b0 e0       	ldi	r27, 0x00	; 0
      7c:	01 c0       	rjmp	.+2      	; 0x80 <.do_clear_bss_start>

0000007e <.do_clear_bss_loop>:
      7e:	1d 92       	st	X+, r1

00000080 <.do_clear_bss_start>:
      80:	a8 3e       	cpi	r26, 0xE8	; 232
      82:	b1 07       	cpc	r27, r17
      84:	e1 f7       	brne	.-8      	; 0x7e <.do_clear_bss_loop>
      86:	0e 94 69 0c 	call	0x18d2	; 0x18d2 <main>
      8a:	0c 94 39 14 	jmp	0x2872	; 0x2872 <_exit>

0000008e <__bad_interrupt>:
      8e:	0c 94 00 00 	jmp	0	; 0x0 <__vectors>

00000092 <xCoRoutineCreate>:
static void prvCheckDelayedList( void );

/*-----------------------------------------------------------*/

BaseType_t xCoRoutineCreate( crCOROUTINE_CODE pxCoRoutineCode, UBaseType_t uxPriority, UBaseType_t uxIndex )
{
      92:	af 92       	push	r10
      94:	bf 92       	push	r11
      96:	cf 92       	push	r12
      98:	df 92       	push	r13
      9a:	ef 92       	push	r14
      9c:	ff 92       	push	r15
      9e:	0f 93       	push	r16
      a0:	1f 93       	push	r17
      a2:	cf 93       	push	r28
      a4:	df 93       	push	r29
      a6:	6c 01       	movw	r12, r24
      a8:	e6 2e       	mov	r14, r22
      aa:	f4 2e       	mov	r15, r20
BaseType_t xReturn;
CRCB_t *pxCoRoutine;

	/* Allocate the memory that will store the co-routine control block. */
	pxCoRoutine = ( CRCB_t * ) pvPortMalloc( sizeof( CRCB_t ) );
      ac:	8a e1       	ldi	r24, 0x1A	; 26
      ae:	90 e0       	ldi	r25, 0x00	; 0
      b0:	0e 94 0e 04 	call	0x81c	; 0x81c <pvPortMalloc>
      b4:	8c 01       	movw	r16, r24
	if( pxCoRoutine )
      b6:	00 97       	sbiw	r24, 0x00	; 0
      b8:	09 f4       	brne	.+2      	; 0xbc <xCoRoutineCreate+0x2a>
      ba:	62 c0       	rjmp	.+196    	; 0x180 <xCoRoutineCreate+0xee>
	{
		/* If pxCurrentCoRoutine is NULL then this is the first co-routine to
		be created and the co-routine data structures need initialising. */
		if( pxCurrentCoRoutine == NULL )
      bc:	80 91 6c 00 	lds	r24, 0x006C
      c0:	90 91 6d 00 	lds	r25, 0x006D
      c4:	00 97       	sbiw	r24, 0x00	; 0
      c6:	39 f5       	brne	.+78     	; 0x116 <xCoRoutineCreate+0x84>
		{
			pxCurrentCoRoutine = pxCoRoutine;
      c8:	10 93 6d 00 	sts	0x006D, r17
      cc:	00 93 6c 00 	sts	0x006C, r16
{
UBaseType_t uxPriority;

	for( uxPriority = 0; uxPriority < configMAX_CO_ROUTINE_PRIORITIES; uxPriority++ )
	{
		vListInitialise( ( List_t * ) &( pxReadyCoRoutineLists[ uxPriority ] ) );
      d0:	cf e6       	ldi	r28, 0x6F	; 111
      d2:	d0 e0       	ldi	r29, 0x00	; 0
      d4:	ce 01       	movw	r24, r28
      d6:	0e 94 e7 04 	call	0x9ce	; 0x9ce <vListInitialise>
      da:	ce 01       	movw	r24, r28
      dc:	09 96       	adiw	r24, 0x09	; 9
      de:	0e 94 e7 04 	call	0x9ce	; 0x9ce <vListInitialise>
	}

	vListInitialise( ( List_t * ) &xDelayedCoRoutineList1 );
      e2:	c1 e8       	ldi	r28, 0x81	; 129
      e4:	d0 e0       	ldi	r29, 0x00	; 0
      e6:	ce 01       	movw	r24, r28
      e8:	0e 94 e7 04 	call	0x9ce	; 0x9ce <vListInitialise>
	vListInitialise( ( List_t * ) &xDelayedCoRoutineList2 );
      ec:	0f 2e       	mov	r0, r31
      ee:	fa e8       	ldi	r31, 0x8A	; 138
      f0:	af 2e       	mov	r10, r31
      f2:	f0 e0       	ldi	r31, 0x00	; 0
      f4:	bf 2e       	mov	r11, r31
      f6:	f0 2d       	mov	r31, r0
      f8:	c5 01       	movw	r24, r10
      fa:	0e 94 e7 04 	call	0x9ce	; 0x9ce <vListInitialise>
	vListInitialise( ( List_t * ) &xPendingReadyCoRoutineList );
      fe:	83 e9       	ldi	r24, 0x93	; 147
     100:	90 e0       	ldi	r25, 0x00	; 0
     102:	0e 94 e7 04 	call	0x9ce	; 0x9ce <vListInitialise>

	/* Start with pxDelayedCoRoutineList using list1 and the
	pxOverflowDelayedCoRoutineList using list2. */
	pxDelayedCoRoutineList = &xDelayedCoRoutineList1;
     106:	d0 93 9d 00 	sts	0x009D, r29
     10a:	c0 93 9c 00 	sts	0x009C, r28
	pxOverflowDelayedCoRoutineList = &xDelayedCoRoutineList2;
     10e:	b0 92 9f 00 	sts	0x009F, r11
     112:	a0 92 9e 00 	sts	0x009E, r10
     116:	ce 2d       	mov	r28, r14
     118:	e1 10       	cpse	r14, r1
     11a:	c1 e0       	ldi	r28, 0x01	; 1
		{
			uxPriority = configMAX_CO_ROUTINE_PRIORITIES - 1;
		}

		/* Fill out the co-routine control block from the function parameters. */
		pxCoRoutine->uxState = corINITIAL_STATE;
     11c:	f8 01       	movw	r30, r16
     11e:	11 8e       	std	Z+25, r1	; 0x19
     120:	10 8e       	std	Z+24, r1	; 0x18
		pxCoRoutine->uxPriority = uxPriority;
     122:	c6 8b       	std	Z+22, r28	; 0x16
		pxCoRoutine->uxIndex = uxIndex;
     124:	f7 8a       	std	Z+23, r15	; 0x17
		pxCoRoutine->pxCoRoutineFunction = pxCoRoutineCode;
     126:	c1 92       	st	Z+, r12
     128:	d1 92       	st	Z+, r13
     12a:	7f 01       	movw	r14, r30

		/* Initialise all the other co-routine control block parameters. */
		vListInitialiseItem( &( pxCoRoutine->xGenericListItem ) );
     12c:	cf 01       	movw	r24, r30
     12e:	0e 94 f5 04 	call	0x9ea	; 0x9ea <vListInitialiseItem>
		vListInitialiseItem( &( pxCoRoutine->xEventListItem ) );
     132:	c8 01       	movw	r24, r16
     134:	0c 96       	adiw	r24, 0x0c	; 12
     136:	0e 94 f5 04 	call	0x9ea	; 0x9ea <vListInitialiseItem>

		/* Set the co-routine control block as a link back from the ListItem_t.
		This is so we can get back to the containing CRCB from a generic item
		in a list. */
		listSET_LIST_ITEM_OWNER( &( pxCoRoutine->xGenericListItem ), pxCoRoutine );
     13a:	f8 01       	movw	r30, r16
     13c:	11 87       	std	Z+9, r17	; 0x09
     13e:	00 87       	std	Z+8, r16	; 0x08
		listSET_LIST_ITEM_OWNER( &( pxCoRoutine->xEventListItem ), pxCoRoutine );
     140:	13 8b       	std	Z+19, r17	; 0x13
     142:	02 8b       	std	Z+18, r16	; 0x12

		/* Event lists are always in priority order. */
		listSET_LIST_ITEM_VALUE( &( pxCoRoutine->xEventListItem ), ( ( TickType_t ) configMAX_CO_ROUTINE_PRIORITIES - ( TickType_t ) uxPriority ) );
     144:	82 e0       	ldi	r24, 0x02	; 2
     146:	90 e0       	ldi	r25, 0x00	; 0
     148:	8c 1b       	sub	r24, r28
     14a:	91 09       	sbc	r25, r1
     14c:	95 87       	std	Z+13, r25	; 0x0d
     14e:	84 87       	std	Z+12, r24	; 0x0c

		/* Now the co-routine has been initialised it can be added to the ready
		list at the correct priority. */
		prvAddCoRoutineToReadyQueue( pxCoRoutine );
     150:	86 89       	ldd	r24, Z+22	; 0x16
     152:	90 91 6e 00 	lds	r25, 0x006E
     156:	98 17       	cp	r25, r24
     158:	10 f4       	brcc	.+4      	; 0x15e <xCoRoutineCreate+0xcc>
     15a:	80 93 6e 00 	sts	0x006E, r24
     15e:	90 e0       	ldi	r25, 0x00	; 0
     160:	9c 01       	movw	r18, r24
     162:	22 0f       	add	r18, r18
     164:	33 1f       	adc	r19, r19
     166:	22 0f       	add	r18, r18
     168:	33 1f       	adc	r19, r19
     16a:	22 0f       	add	r18, r18
     16c:	33 1f       	adc	r19, r19
     16e:	82 0f       	add	r24, r18
     170:	93 1f       	adc	r25, r19
     172:	81 59       	subi	r24, 0x91	; 145
     174:	9f 4f       	sbci	r25, 0xFF	; 255
     176:	b7 01       	movw	r22, r14
     178:	0e 94 f9 04 	call	0x9f2	; 0x9f2 <vListInsertEnd>

		xReturn = pdPASS;
     17c:	81 e0       	ldi	r24, 0x01	; 1
     17e:	01 c0       	rjmp	.+2      	; 0x182 <xCoRoutineCreate+0xf0>
	}
	else
	{
		xReturn = errCOULD_NOT_ALLOCATE_REQUIRED_MEMORY;
     180:	8f ef       	ldi	r24, 0xFF	; 255
	}

	return xReturn;
}
     182:	df 91       	pop	r29
     184:	cf 91       	pop	r28
     186:	1f 91       	pop	r17
     188:	0f 91       	pop	r16
     18a:	ff 90       	pop	r15
     18c:	ef 90       	pop	r14
     18e:	df 90       	pop	r13
     190:	cf 90       	pop	r12
     192:	bf 90       	pop	r11
     194:	af 90       	pop	r10
     196:	08 95       	ret

00000198 <vCoRoutineAddToDelayedList>:
/*-----------------------------------------------------------*/

void vCoRoutineAddToDelayedList( TickType_t xTicksToDelay, List_t *pxEventList )
{
     198:	0f 93       	push	r16
     19a:	1f 93       	push	r17
     19c:	cf 93       	push	r28
     19e:	df 93       	push	r29
     1a0:	8b 01       	movw	r16, r22
TickType_t xTimeToWake;

	/* Calculate the time to wake - this may overflow but this is
	not a problem. */
	xTimeToWake = xCoRoutineTickCount + xTicksToDelay;
     1a2:	c0 91 a0 00 	lds	r28, 0x00A0
     1a6:	d0 91 a1 00 	lds	r29, 0x00A1
     1aa:	c8 0f       	add	r28, r24
     1ac:	d9 1f       	adc	r29, r25

	/* We must remove ourselves from the ready list before adding
	ourselves to the blocked list as the same list item is used for
	both lists. */
	( void ) uxListRemove( ( ListItem_t * ) &( pxCurrentCoRoutine->xGenericListItem ) );
     1ae:	80 91 6c 00 	lds	r24, 0x006C
     1b2:	90 91 6d 00 	lds	r25, 0x006D
     1b6:	02 96       	adiw	r24, 0x02	; 2
     1b8:	0e 94 4a 05 	call	0xa94	; 0xa94 <uxListRemove>

	/* The list item will be inserted in wake time order. */
	listSET_LIST_ITEM_VALUE( &( pxCurrentCoRoutine->xGenericListItem ), xTimeToWake );
     1bc:	e0 91 6c 00 	lds	r30, 0x006C
     1c0:	f0 91 6d 00 	lds	r31, 0x006D
     1c4:	d3 83       	std	Z+3, r29	; 0x03
     1c6:	c2 83       	std	Z+2, r28	; 0x02

	if( xTimeToWake < xCoRoutineTickCount )
     1c8:	80 91 a0 00 	lds	r24, 0x00A0
     1cc:	90 91 a1 00 	lds	r25, 0x00A1
     1d0:	c8 17       	cp	r28, r24
     1d2:	d9 07       	cpc	r29, r25
     1d4:	50 f4       	brcc	.+20     	; 0x1ea <vCoRoutineAddToDelayedList+0x52>
	{
		/* Wake time has overflowed.  Place this item in the
		overflow list. */
		vListInsert( ( List_t * ) pxOverflowDelayedCoRoutineList, ( ListItem_t * ) &( pxCurrentCoRoutine->xGenericListItem ) );
     1d6:	bf 01       	movw	r22, r30
     1d8:	6e 5f       	subi	r22, 0xFE	; 254
     1da:	7f 4f       	sbci	r23, 0xFF	; 255
     1dc:	80 91 9e 00 	lds	r24, 0x009E
     1e0:	90 91 9f 00 	lds	r25, 0x009F
     1e4:	0e 94 18 05 	call	0xa30	; 0xa30 <vListInsert>
     1e8:	09 c0       	rjmp	.+18     	; 0x1fc <vCoRoutineAddToDelayedList+0x64>
	}
	else
	{
		/* The wake time has not overflowed, so we can use the
		current block list. */
		vListInsert( ( List_t * ) pxDelayedCoRoutineList, ( ListItem_t * ) &( pxCurrentCoRoutine->xGenericListItem ) );
     1ea:	bf 01       	movw	r22, r30
     1ec:	6e 5f       	subi	r22, 0xFE	; 254
     1ee:	7f 4f       	sbci	r23, 0xFF	; 255
     1f0:	80 91 9c 00 	lds	r24, 0x009C
     1f4:	90 91 9d 00 	lds	r25, 0x009D
     1f8:	0e 94 18 05 	call	0xa30	; 0xa30 <vListInsert>
	}

	if( pxEventList )
     1fc:	01 15       	cp	r16, r1
     1fe:	11 05       	cpc	r17, r1
     200:	49 f0       	breq	.+18     	; 0x214 <vCoRoutineAddToDelayedList+0x7c>
	{
		/* Also add the co-routine to an event list.  If this is done then the
		function must be called with interrupts disabled. */
		vListInsert( pxEventList, &( pxCurrentCoRoutine->xEventListItem ) );
     202:	60 91 6c 00 	lds	r22, 0x006C
     206:	70 91 6d 00 	lds	r23, 0x006D
     20a:	64 5f       	subi	r22, 0xF4	; 244
     20c:	7f 4f       	sbci	r23, 0xFF	; 255
     20e:	c8 01       	movw	r24, r16
     210:	0e 94 18 05 	call	0xa30	; 0xa30 <vListInsert>
	}
}
     214:	df 91       	pop	r29
     216:	cf 91       	pop	r28
     218:	1f 91       	pop	r17
     21a:	0f 91       	pop	r16
     21c:	08 95       	ret

0000021e <vCoRoutineSchedule>:
	xLastTickCount = xCoRoutineTickCount;
}
/*-----------------------------------------------------------*/

void vCoRoutineSchedule( void )
{
     21e:	ef 92       	push	r14
     220:	ff 92       	push	r15
     222:	0f 93       	push	r16
     224:	1f 93       	push	r17
     226:	cf 93       	push	r28
     228:	df 93       	push	r29
static void prvCheckPendingReadyList( void )
{
	/* Are there any co-routines waiting to get moved to the ready list?  These
	are co-routines that have been readied by an ISR.  The ISR cannot access
	the	ready lists itself. */
	while( listLIST_IS_EMPTY( &xPendingReadyCoRoutineList ) == pdFALSE )
     22a:	80 91 93 00 	lds	r24, 0x0093
     22e:	88 23       	and	r24, r24
     230:	91 f1       	breq	.+100    	; 0x296 <vCoRoutineSchedule+0x78>
     232:	0f 2e       	mov	r0, r31
     234:	f3 e9       	ldi	r31, 0x93	; 147
     236:	ef 2e       	mov	r14, r31
     238:	f0 e0       	ldi	r31, 0x00	; 0
     23a:	ff 2e       	mov	r15, r31
     23c:	f0 2d       	mov	r31, r0
	{
		CRCB_t *pxUnblockedCRCB;

		/* The pending ready list can be accessed by an ISR. */
		portDISABLE_INTERRUPTS();
     23e:	f8 94       	cli
		{
			pxUnblockedCRCB = ( CRCB_t * ) listGET_OWNER_OF_HEAD_ENTRY( (&xPendingReadyCoRoutineList) );
     240:	e0 91 98 00 	lds	r30, 0x0098
     244:	f0 91 99 00 	lds	r31, 0x0099
     248:	c6 81       	ldd	r28, Z+6	; 0x06
     24a:	d7 81       	ldd	r29, Z+7	; 0x07
			( void ) uxListRemove( &( pxUnblockedCRCB->xEventListItem ) );
     24c:	ce 01       	movw	r24, r28
     24e:	0c 96       	adiw	r24, 0x0c	; 12
     250:	0e 94 4a 05 	call	0xa94	; 0xa94 <uxListRemove>
		}
		portENABLE_INTERRUPTS();
     254:	78 94       	sei

		( void ) uxListRemove( &( pxUnblockedCRCB->xGenericListItem ) );
     256:	8e 01       	movw	r16, r28
     258:	0e 5f       	subi	r16, 0xFE	; 254
     25a:	1f 4f       	sbci	r17, 0xFF	; 255
     25c:	c8 01       	movw	r24, r16
     25e:	0e 94 4a 05 	call	0xa94	; 0xa94 <uxListRemove>
		prvAddCoRoutineToReadyQueue( pxUnblockedCRCB );
     262:	8e 89       	ldd	r24, Y+22	; 0x16
     264:	90 91 6e 00 	lds	r25, 0x006E
     268:	98 17       	cp	r25, r24
     26a:	10 f4       	brcc	.+4      	; 0x270 <vCoRoutineSchedule+0x52>
     26c:	80 93 6e 00 	sts	0x006E, r24
     270:	90 e0       	ldi	r25, 0x00	; 0
     272:	9c 01       	movw	r18, r24
     274:	22 0f       	add	r18, r18
     276:	33 1f       	adc	r19, r19
     278:	22 0f       	add	r18, r18
     27a:	33 1f       	adc	r19, r19
     27c:	22 0f       	add	r18, r18
     27e:	33 1f       	adc	r19, r19
     280:	82 0f       	add	r24, r18
     282:	93 1f       	adc	r25, r19
     284:	81 59       	subi	r24, 0x91	; 145
     286:	9f 4f       	sbci	r25, 0xFF	; 255
     288:	b8 01       	movw	r22, r16
     28a:	0e 94 f9 04 	call	0x9f2	; 0x9f2 <vListInsertEnd>
static void prvCheckPendingReadyList( void )
{
	/* Are there any co-routines waiting to get moved to the ready list?  These
	are co-routines that have been readied by an ISR.  The ISR cannot access
	the	ready lists itself. */
	while( listLIST_IS_EMPTY( &xPendingReadyCoRoutineList ) == pdFALSE )
     28e:	f7 01       	movw	r30, r14
     290:	80 81       	ld	r24, Z
     292:	88 23       	and	r24, r24
     294:	a1 f6       	brne	.-88     	; 0x23e <vCoRoutineSchedule+0x20>

static void prvCheckDelayedList( void )
{
CRCB_t *pxCRCB;

	xPassedTicks = xTaskGetTickCount() - xLastTickCount;
     296:	0e 94 c4 0e 	call	0x1d88	; 0x1d88 <xTaskGetTickCount>
     29a:	20 91 a2 00 	lds	r18, 0x00A2
     29e:	30 91 a3 00 	lds	r19, 0x00A3
     2a2:	82 1b       	sub	r24, r18
     2a4:	93 0b       	sbc	r25, r19
     2a6:	90 93 a5 00 	sts	0x00A5, r25
     2aa:	80 93 a4 00 	sts	0x00A4, r24
     2ae:	74 c0       	rjmp	.+232    	; 0x398 <vCoRoutineSchedule+0x17a>
	while( xPassedTicks )
	{
		xCoRoutineTickCount++;
     2b0:	20 91 a0 00 	lds	r18, 0x00A0
     2b4:	30 91 a1 00 	lds	r19, 0x00A1
     2b8:	2f 5f       	subi	r18, 0xFF	; 255
     2ba:	3f 4f       	sbci	r19, 0xFF	; 255
     2bc:	30 93 a1 00 	sts	0x00A1, r19
     2c0:	20 93 a0 00 	sts	0x00A0, r18
		xPassedTicks--;
     2c4:	01 97       	sbiw	r24, 0x01	; 1
     2c6:	90 93 a5 00 	sts	0x00A5, r25
     2ca:	80 93 a4 00 	sts	0x00A4, r24

		/* If the tick count has overflowed we need to swap the ready lists. */
		if( xCoRoutineTickCount == 0 )
     2ce:	21 15       	cp	r18, r1
     2d0:	31 05       	cpc	r19, r1
     2d2:	81 f4       	brne	.+32     	; 0x2f4 <vCoRoutineSchedule+0xd6>
		{
			List_t * pxTemp;

			/* Tick count has overflowed so we need to swap the delay lists.  If there are
			any items in pxDelayedCoRoutineList here then there is an error! */
			pxTemp = pxDelayedCoRoutineList;
     2d4:	80 91 9c 00 	lds	r24, 0x009C
     2d8:	90 91 9d 00 	lds	r25, 0x009D
			pxDelayedCoRoutineList = pxOverflowDelayedCoRoutineList;
     2dc:	20 91 9e 00 	lds	r18, 0x009E
     2e0:	30 91 9f 00 	lds	r19, 0x009F
     2e4:	30 93 9d 00 	sts	0x009D, r19
     2e8:	20 93 9c 00 	sts	0x009C, r18
			pxOverflowDelayedCoRoutineList = pxTemp;
     2ec:	90 93 9f 00 	sts	0x009F, r25
     2f0:	80 93 9e 00 	sts	0x009E, r24
		}

		/* See if this tick has made a timeout expire. */
		while( listLIST_IS_EMPTY( pxDelayedCoRoutineList ) == pdFALSE )
     2f4:	e0 91 9c 00 	lds	r30, 0x009C
     2f8:	f0 91 9d 00 	lds	r31, 0x009D
     2fc:	80 81       	ld	r24, Z
     2fe:	88 23       	and	r24, r24
     300:	09 f4       	brne	.+2      	; 0x304 <vCoRoutineSchedule+0xe6>
     302:	4a c0       	rjmp	.+148    	; 0x398 <vCoRoutineSchedule+0x17a>
		{
			pxCRCB = ( CRCB_t * ) listGET_OWNER_OF_HEAD_ENTRY( pxDelayedCoRoutineList );
     304:	05 80       	ldd	r0, Z+5	; 0x05
     306:	f6 81       	ldd	r31, Z+6	; 0x06
     308:	e0 2d       	mov	r30, r0
     30a:	c6 81       	ldd	r28, Z+6	; 0x06
     30c:	d7 81       	ldd	r29, Z+7	; 0x07

			if( xCoRoutineTickCount < listGET_LIST_ITEM_VALUE( &( pxCRCB->xGenericListItem ) ) )
     30e:	2a 81       	ldd	r18, Y+2	; 0x02
     310:	3b 81       	ldd	r19, Y+3	; 0x03
     312:	80 91 a0 00 	lds	r24, 0x00A0
     316:	90 91 a1 00 	lds	r25, 0x00A1
     31a:	82 17       	cp	r24, r18
     31c:	93 07       	cpc	r25, r19
     31e:	78 f4       	brcc	.+30     	; 0x33e <vCoRoutineSchedule+0x120>
     320:	3b c0       	rjmp	.+118    	; 0x398 <vCoRoutineSchedule+0x17a>
		}

		/* See if this tick has made a timeout expire. */
		while( listLIST_IS_EMPTY( pxDelayedCoRoutineList ) == pdFALSE )
		{
			pxCRCB = ( CRCB_t * ) listGET_OWNER_OF_HEAD_ENTRY( pxDelayedCoRoutineList );
     322:	05 80       	ldd	r0, Z+5	; 0x05
     324:	f6 81       	ldd	r31, Z+6	; 0x06
     326:	e0 2d       	mov	r30, r0
     328:	c6 81       	ldd	r28, Z+6	; 0x06
     32a:	d7 81       	ldd	r29, Z+7	; 0x07

			if( xCoRoutineTickCount < listGET_LIST_ITEM_VALUE( &( pxCRCB->xGenericListItem ) ) )
     32c:	2a 81       	ldd	r18, Y+2	; 0x02
     32e:	3b 81       	ldd	r19, Y+3	; 0x03
     330:	80 91 a0 00 	lds	r24, 0x00A0
     334:	90 91 a1 00 	lds	r25, 0x00A1
     338:	82 17       	cp	r24, r18
     33a:	93 07       	cpc	r25, r19
     33c:	68 f1       	brcs	.+90     	; 0x398 <vCoRoutineSchedule+0x17a>
			{
				/* Timeout not yet expired. */
				break;
			}

			portDISABLE_INTERRUPTS();
     33e:	f8 94       	cli
				/* The event could have occurred just before this critical
				section.  If this is the case then the generic list item will
				have been moved to the pending ready list and the following
				line is still valid.  Also the pvContainer parameter will have
				been set to NULL so the following lines are also valid. */
				( void ) uxListRemove( &( pxCRCB->xGenericListItem ) );
     340:	8e 01       	movw	r16, r28
     342:	0e 5f       	subi	r16, 0xFE	; 254
     344:	1f 4f       	sbci	r17, 0xFF	; 255
     346:	c8 01       	movw	r24, r16
     348:	0e 94 4a 05 	call	0xa94	; 0xa94 <uxListRemove>

				/* Is the co-routine waiting on an event also? */
				if( pxCRCB->xEventListItem.pxContainer )
     34c:	8c 89       	ldd	r24, Y+20	; 0x14
     34e:	9d 89       	ldd	r25, Y+21	; 0x15
     350:	00 97       	sbiw	r24, 0x00	; 0
     352:	21 f0       	breq	.+8      	; 0x35c <vCoRoutineSchedule+0x13e>
				{
					( void ) uxListRemove( &( pxCRCB->xEventListItem ) );
     354:	ce 01       	movw	r24, r28
     356:	0c 96       	adiw	r24, 0x0c	; 12
     358:	0e 94 4a 05 	call	0xa94	; 0xa94 <uxListRemove>
				}
			}
			portENABLE_INTERRUPTS();
     35c:	78 94       	sei

			prvAddCoRoutineToReadyQueue( pxCRCB );
     35e:	8e 89       	ldd	r24, Y+22	; 0x16
     360:	90 91 6e 00 	lds	r25, 0x006E
     364:	98 17       	cp	r25, r24
     366:	10 f4       	brcc	.+4      	; 0x36c <vCoRoutineSchedule+0x14e>
     368:	80 93 6e 00 	sts	0x006E, r24
     36c:	90 e0       	ldi	r25, 0x00	; 0
     36e:	9c 01       	movw	r18, r24
     370:	22 0f       	add	r18, r18
     372:	33 1f       	adc	r19, r19
     374:	22 0f       	add	r18, r18
     376:	33 1f       	adc	r19, r19
     378:	22 0f       	add	r18, r18
     37a:	33 1f       	adc	r19, r19
     37c:	82 0f       	add	r24, r18
     37e:	93 1f       	adc	r25, r19
     380:	81 59       	subi	r24, 0x91	; 145
     382:	9f 4f       	sbci	r25, 0xFF	; 255
     384:	b8 01       	movw	r22, r16
     386:	0e 94 f9 04 	call	0x9f2	; 0x9f2 <vListInsertEnd>
			pxDelayedCoRoutineList = pxOverflowDelayedCoRoutineList;
			pxOverflowDelayedCoRoutineList = pxTemp;
		}

		/* See if this tick has made a timeout expire. */
		while( listLIST_IS_EMPTY( pxDelayedCoRoutineList ) == pdFALSE )
     38a:	e0 91 9c 00 	lds	r30, 0x009C
     38e:	f0 91 9d 00 	lds	r31, 0x009D
     392:	80 81       	ld	r24, Z
     394:	88 23       	and	r24, r24
     396:	29 f6       	brne	.-118    	; 0x322 <vCoRoutineSchedule+0x104>
static void prvCheckDelayedList( void )
{
CRCB_t *pxCRCB;

	xPassedTicks = xTaskGetTickCount() - xLastTickCount;
	while( xPassedTicks )
     398:	80 91 a4 00 	lds	r24, 0x00A4
     39c:	90 91 a5 00 	lds	r25, 0x00A5
     3a0:	00 97       	sbiw	r24, 0x00	; 0
     3a2:	09 f0       	breq	.+2      	; 0x3a6 <vCoRoutineSchedule+0x188>
     3a4:	85 cf       	rjmp	.-246    	; 0x2b0 <vCoRoutineSchedule+0x92>

			prvAddCoRoutineToReadyQueue( pxCRCB );
		}
	}

	xLastTickCount = xCoRoutineTickCount;
     3a6:	80 91 a0 00 	lds	r24, 0x00A0
     3aa:	90 91 a1 00 	lds	r25, 0x00A1
     3ae:	90 93 a3 00 	sts	0x00A3, r25
     3b2:	80 93 a2 00 	sts	0x00A2, r24

	/* See if any delayed co-routines have timed out. */
	prvCheckDelayedList();

	/* Find the highest priority queue that contains ready co-routines. */
	while( listLIST_IS_EMPTY( &( pxReadyCoRoutineLists[ uxTopCoRoutineReadyPriority ] ) ) )
     3b6:	20 91 6e 00 	lds	r18, 0x006E
     3ba:	82 2f       	mov	r24, r18
     3bc:	90 e0       	ldi	r25, 0x00	; 0
     3be:	fc 01       	movw	r30, r24
     3c0:	ee 0f       	add	r30, r30
     3c2:	ff 1f       	adc	r31, r31
     3c4:	ee 0f       	add	r30, r30
     3c6:	ff 1f       	adc	r31, r31
     3c8:	ee 0f       	add	r30, r30
     3ca:	ff 1f       	adc	r31, r31
     3cc:	e8 0f       	add	r30, r24
     3ce:	f9 1f       	adc	r31, r25
     3d0:	e1 59       	subi	r30, 0x91	; 145
     3d2:	ff 4f       	sbci	r31, 0xFF	; 255
     3d4:	30 81       	ld	r19, Z
     3d6:	33 23       	and	r19, r19
     3d8:	d9 f4       	brne	.+54     	; 0x410 <vCoRoutineSchedule+0x1f2>
	{
		if( uxTopCoRoutineReadyPriority == 0 )
     3da:	22 23       	and	r18, r18
     3dc:	31 f4       	brne	.+12     	; 0x3ea <vCoRoutineSchedule+0x1cc>
     3de:	47 c0       	rjmp	.+142    	; 0x46e <vCoRoutineSchedule+0x250>
     3e0:	22 23       	and	r18, r18
     3e2:	19 f4       	brne	.+6      	; 0x3ea <vCoRoutineSchedule+0x1cc>
     3e4:	20 93 6e 00 	sts	0x006E, r18
     3e8:	42 c0       	rjmp	.+132    	; 0x46e <vCoRoutineSchedule+0x250>
		{
			/* No more co-routines to check. */
			return;
		}
		--uxTopCoRoutineReadyPriority;
     3ea:	21 50       	subi	r18, 0x01	; 1

	/* See if any delayed co-routines have timed out. */
	prvCheckDelayedList();

	/* Find the highest priority queue that contains ready co-routines. */
	while( listLIST_IS_EMPTY( &( pxReadyCoRoutineLists[ uxTopCoRoutineReadyPriority ] ) ) )
     3ec:	82 2f       	mov	r24, r18
     3ee:	90 e0       	ldi	r25, 0x00	; 0
     3f0:	fc 01       	movw	r30, r24
     3f2:	ee 0f       	add	r30, r30
     3f4:	ff 1f       	adc	r31, r31
     3f6:	ee 0f       	add	r30, r30
     3f8:	ff 1f       	adc	r31, r31
     3fa:	ee 0f       	add	r30, r30
     3fc:	ff 1f       	adc	r31, r31
     3fe:	e8 0f       	add	r30, r24
     400:	f9 1f       	adc	r31, r25
     402:	e1 59       	subi	r30, 0x91	; 145
     404:	ff 4f       	sbci	r31, 0xFF	; 255
     406:	30 81       	ld	r19, Z
     408:	33 23       	and	r19, r19
     40a:	51 f3       	breq	.-44     	; 0x3e0 <vCoRoutineSchedule+0x1c2>
     40c:	20 93 6e 00 	sts	0x006E, r18
		--uxTopCoRoutineReadyPriority;
	}

	/* listGET_OWNER_OF_NEXT_ENTRY walks through the list, so the co-routines
	 of the	same priority get an equal share of the processor time. */
	listGET_OWNER_OF_NEXT_ENTRY( pxCurrentCoRoutine, &( pxReadyCoRoutineLists[ uxTopCoRoutineReadyPriority ] ) );
     410:	fc 01       	movw	r30, r24
     412:	ee 0f       	add	r30, r30
     414:	ff 1f       	adc	r31, r31
     416:	ee 0f       	add	r30, r30
     418:	ff 1f       	adc	r31, r31
     41a:	ee 0f       	add	r30, r30
     41c:	ff 1f       	adc	r31, r31
     41e:	8e 0f       	add	r24, r30
     420:	9f 1f       	adc	r25, r31
     422:	fc 01       	movw	r30, r24
     424:	e1 59       	subi	r30, 0x91	; 145
     426:	ff 4f       	sbci	r31, 0xFF	; 255
     428:	a1 81       	ldd	r26, Z+1	; 0x01
     42a:	b2 81       	ldd	r27, Z+2	; 0x02
     42c:	12 96       	adiw	r26, 0x02	; 2
     42e:	0d 90       	ld	r0, X+
     430:	bc 91       	ld	r27, X
     432:	a0 2d       	mov	r26, r0
     434:	b2 83       	std	Z+2, r27	; 0x02
     436:	a1 83       	std	Z+1, r26	; 0x01
     438:	cf 01       	movw	r24, r30
     43a:	03 96       	adiw	r24, 0x03	; 3
     43c:	a8 17       	cp	r26, r24
     43e:	b9 07       	cpc	r27, r25
     440:	31 f4       	brne	.+12     	; 0x44e <vCoRoutineSchedule+0x230>
     442:	12 96       	adiw	r26, 0x02	; 2
     444:	8d 91       	ld	r24, X+
     446:	9c 91       	ld	r25, X
     448:	13 97       	sbiw	r26, 0x03	; 3
     44a:	92 83       	std	Z+2, r25	; 0x02
     44c:	81 83       	std	Z+1, r24	; 0x01
     44e:	01 80       	ldd	r0, Z+1	; 0x01
     450:	f2 81       	ldd	r31, Z+2	; 0x02
     452:	e0 2d       	mov	r30, r0
     454:	a6 81       	ldd	r26, Z+6	; 0x06
     456:	b7 81       	ldd	r27, Z+7	; 0x07
     458:	b0 93 6d 00 	sts	0x006D, r27
     45c:	a0 93 6c 00 	sts	0x006C, r26

	/* Call the co-routine. */
	( pxCurrentCoRoutine->pxCoRoutineFunction )( pxCurrentCoRoutine, pxCurrentCoRoutine->uxIndex );
     460:	ed 91       	ld	r30, X+
     462:	fc 91       	ld	r31, X
     464:	11 97       	sbiw	r26, 0x01	; 1
     466:	cd 01       	movw	r24, r26
     468:	57 96       	adiw	r26, 0x17	; 23
     46a:	6c 91       	ld	r22, X
     46c:	09 95       	icall

	return;
}
     46e:	df 91       	pop	r29
     470:	cf 91       	pop	r28
     472:	1f 91       	pop	r17
     474:	0f 91       	pop	r16
     476:	ff 90       	pop	r15
     478:	ef 90       	pop	r14
     47a:	08 95       	ret

0000047c <xCoRoutineRemoveFromEventList>:
	pxOverflowDelayedCoRoutineList = &xDelayedCoRoutineList2;
}
/*-----------------------------------------------------------*/

BaseType_t xCoRoutineRemoveFromEventList( const List_t *pxEventList )
{
     47c:	0f 93       	push	r16
     47e:	1f 93       	push	r17
     480:	cf 93       	push	r28
     482:	df 93       	push	r29
BaseType_t xReturn;

	/* This function is called from within an interrupt.  It can only access
	event lists and the pending ready list.  This function assumes that a
	check has already been made to ensure pxEventList is not empty. */
	pxUnblockedCRCB = ( CRCB_t * ) listGET_OWNER_OF_HEAD_ENTRY( pxEventList );
     484:	dc 01       	movw	r26, r24
     486:	15 96       	adiw	r26, 0x05	; 5
     488:	ed 91       	ld	r30, X+
     48a:	fc 91       	ld	r31, X
     48c:	16 97       	sbiw	r26, 0x06	; 6
     48e:	06 81       	ldd	r16, Z+6	; 0x06
     490:	17 81       	ldd	r17, Z+7	; 0x07
	( void ) uxListRemove( &( pxUnblockedCRCB->xEventListItem ) );
     492:	e8 01       	movw	r28, r16
     494:	2c 96       	adiw	r28, 0x0c	; 12
     496:	ce 01       	movw	r24, r28
     498:	0e 94 4a 05 	call	0xa94	; 0xa94 <uxListRemove>
	vListInsertEnd( ( List_t * ) &( xPendingReadyCoRoutineList ), &( pxUnblockedCRCB->xEventListItem ) );
     49c:	83 e9       	ldi	r24, 0x93	; 147
     49e:	90 e0       	ldi	r25, 0x00	; 0
     4a0:	be 01       	movw	r22, r28
     4a2:	0e 94 f9 04 	call	0x9f2	; 0x9f2 <vListInsertEnd>

	if( pxUnblockedCRCB->uxPriority >= pxCurrentCoRoutine->uxPriority )
     4a6:	e0 91 6c 00 	lds	r30, 0x006C
     4aa:	f0 91 6d 00 	lds	r31, 0x006D
	{
		xReturn = pdTRUE;
     4ae:	81 e0       	ldi	r24, 0x01	; 1
     4b0:	d8 01       	movw	r26, r16
     4b2:	56 96       	adiw	r26, 0x16	; 22
     4b4:	2c 91       	ld	r18, X
     4b6:	56 97       	sbiw	r26, 0x16	; 22
     4b8:	96 89       	ldd	r25, Z+22	; 0x16
     4ba:	29 17       	cp	r18, r25
     4bc:	08 f4       	brcc	.+2      	; 0x4c0 <xCoRoutineRemoveFromEventList+0x44>
     4be:	80 e0       	ldi	r24, 0x00	; 0
	{
		xReturn = pdFALSE;
	}

	return xReturn;
}
     4c0:	df 91       	pop	r29
     4c2:	cf 91       	pop	r28
     4c4:	1f 91       	pop	r17
     4c6:	0f 91       	pop	r16
     4c8:	08 95       	ret

000004ca <prvTestWaitCondition>:

static BaseType_t prvTestWaitCondition( const EventBits_t uxCurrentEventBits, const EventBits_t uxBitsToWaitFor, const BaseType_t xWaitForAllBits )
{
BaseType_t xWaitConditionMet = pdFALSE;

	if( xWaitForAllBits == pdFALSE )
     4ca:	44 23       	and	r20, r20
     4cc:	41 f4       	brne	.+16     	; 0x4de <prvTestWaitCondition+0x14>
	{
		/* Task only has to wait for one bit within uxBitsToWaitFor to be
		set.  Is one already set? */
		if( ( uxCurrentEventBits & uxBitsToWaitFor ) != ( EventBits_t ) 0 )
     4ce:	68 23       	and	r22, r24
     4d0:	79 23       	and	r23, r25
		{
			xWaitConditionMet = pdTRUE;
     4d2:	81 e0       	ldi	r24, 0x01	; 1
     4d4:	61 15       	cp	r22, r1
     4d6:	71 05       	cpc	r23, r1
     4d8:	51 f4       	brne	.+20     	; 0x4ee <prvTestWaitCondition+0x24>
     4da:	80 e0       	ldi	r24, 0x00	; 0
     4dc:	08 95       	ret
	}
	else
	{
		/* Task has to wait for all the bits in uxBitsToWaitFor to be set.
		Are they set already? */
		if( ( uxCurrentEventBits & uxBitsToWaitFor ) == uxBitsToWaitFor )
     4de:	9b 01       	movw	r18, r22
     4e0:	28 23       	and	r18, r24
     4e2:	39 23       	and	r19, r25
	{
		/* Task only has to wait for one bit within uxBitsToWaitFor to be
		set.  Is one already set? */
		if( ( uxCurrentEventBits & uxBitsToWaitFor ) != ( EventBits_t ) 0 )
		{
			xWaitConditionMet = pdTRUE;
     4e4:	81 e0       	ldi	r24, 0x01	; 1
     4e6:	62 17       	cp	r22, r18
     4e8:	73 07       	cpc	r23, r19
     4ea:	09 f0       	breq	.+2      	; 0x4ee <prvTestWaitCondition+0x24>
     4ec:	80 e0       	ldi	r24, 0x00	; 0
			mtCOVERAGE_TEST_MARKER();
		}
	}

	return xWaitConditionMet;
}
     4ee:	08 95       	ret

000004f0 <xEventGroupCreate>:
/*-----------------------------------------------------------*/

#if( configSUPPORT_DYNAMIC_ALLOCATION == 1 )

	EventGroupHandle_t xEventGroupCreate( void )
	{
     4f0:	cf 93       	push	r28
     4f2:	df 93       	push	r29
		TickType_t alignment requirements the cast is safe.  In other cases,
		where the natural word size of the architecture is less than
		sizeof( TickType_t ), the TickType_t variables will be accessed in two
		or more reads operations, and the alignment requirements is only that
		of each individual read. */
		pxEventBits = ( EventGroup_t * ) pvPortMalloc( sizeof( EventGroup_t ) ); /*lint !e9087 !e9079 see comment above. */
     4f4:	8b e0       	ldi	r24, 0x0B	; 11
     4f6:	90 e0       	ldi	r25, 0x00	; 0
     4f8:	0e 94 0e 04 	call	0x81c	; 0x81c <pvPortMalloc>
     4fc:	ec 01       	movw	r28, r24

		if( pxEventBits != NULL )
     4fe:	00 97       	sbiw	r24, 0x00	; 0
     500:	31 f0       	breq	.+12     	; 0x50e <xEventGroupCreate+0x1e>
		{
			pxEventBits->uxEventBits = 0;
     502:	fc 01       	movw	r30, r24
     504:	11 92       	st	Z+, r1
     506:	11 92       	st	Z+, r1
     508:	cf 01       	movw	r24, r30
			vListInitialise( &( pxEventBits->xTasksWaitingForBits ) );
     50a:	0e 94 e7 04 	call	0x9ce	; 0x9ce <vListInitialise>
		{
			traceEVENT_GROUP_CREATE_FAILED(); /*lint !e9063 Else branch only exists to allow tracing and does not generate code if trace macros are not defined. */
		}

		return pxEventBits;
	}
     50e:	8c 2f       	mov	r24, r28
     510:	9d 2f       	mov	r25, r29
     512:	df 91       	pop	r29
     514:	cf 91       	pop	r28
     516:	08 95       	ret

00000518 <xEventGroupWaitBits>:
	return uxReturn;
}
/*-----------------------------------------------------------*/

EventBits_t xEventGroupWaitBits( EventGroupHandle_t xEventGroup, const EventBits_t uxBitsToWaitFor, const BaseType_t xClearOnExit, const BaseType_t xWaitForAllBits, TickType_t xTicksToWait )
{
     518:	af 92       	push	r10
     51a:	bf 92       	push	r11
     51c:	cf 92       	push	r12
     51e:	df 92       	push	r13
     520:	ef 92       	push	r14
     522:	ff 92       	push	r15
     524:	0f 93       	push	r16
     526:	1f 93       	push	r17
     528:	cf 93       	push	r28
     52a:	df 93       	push	r29
     52c:	5c 01       	movw	r10, r24
     52e:	6b 01       	movw	r12, r22
     530:	e4 2e       	mov	r14, r20
     532:	f2 2e       	mov	r15, r18
	{
		configASSERT( !( ( xTaskGetSchedulerState() == taskSCHEDULER_SUSPENDED ) && ( xTicksToWait != 0 ) ) );
	}
	#endif

	vTaskSuspendAll();
     534:	0e 94 be 0e 	call	0x1d7c	; 0x1d7c <vTaskSuspendAll>
	{
		const EventBits_t uxCurrentEventBits = pxEventBits->uxEventBits;
     538:	f5 01       	movw	r30, r10
     53a:	c0 81       	ld	r28, Z
     53c:	d1 81       	ldd	r29, Z+1	; 0x01

		/* Check to see if the wait condition is already met or not. */
		xWaitConditionMet = prvTestWaitCondition( uxCurrentEventBits, uxBitsToWaitFor, xWaitForAllBits );
     53e:	ce 01       	movw	r24, r28
     540:	b6 01       	movw	r22, r12
     542:	4f 2d       	mov	r20, r15
     544:	0e 94 65 02 	call	0x4ca	; 0x4ca <prvTestWaitCondition>

		if( xWaitConditionMet != pdFALSE )
     548:	88 23       	and	r24, r24
     54a:	51 f0       	breq	.+20     	; 0x560 <xEventGroupWaitBits+0x48>
			block. */
			uxReturn = uxCurrentEventBits;
			xTicksToWait = ( TickType_t ) 0;

			/* Clear the wait bits if requested to do so. */
			if( xClearOnExit != pdFALSE )
     54c:	ee 20       	and	r14, r14
     54e:	01 f1       	breq	.+64     	; 0x590 <xEventGroupWaitBits+0x78>
			{
				pxEventBits->uxEventBits &= ~uxBitsToWaitFor;
     550:	c0 94       	com	r12
     552:	d0 94       	com	r13
     554:	cc 22       	and	r12, r28
     556:	dd 22       	and	r13, r29
     558:	f5 01       	movw	r30, r10
     55a:	d1 82       	std	Z+1, r13	; 0x01
     55c:	c0 82       	st	Z, r12
     55e:	18 c0       	rjmp	.+48     	; 0x590 <xEventGroupWaitBits+0x78>
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}
		}
		else if( xTicksToWait == ( TickType_t ) 0 )
     560:	01 15       	cp	r16, r1
     562:	11 05       	cpc	r17, r1
     564:	a9 f0       	breq	.+42     	; 0x590 <xEventGroupWaitBits+0x78>
		{
			/* The task is going to block to wait for its required bits to be
			set.  uxControlBits are used to remember the specified behaviour of
			this call to xEventGroupWaitBits() - for use when the event bits
			unblock the task. */
			if( xClearOnExit != pdFALSE )
     566:	ee 20       	and	r14, r14
     568:	19 f4       	brne	.+6      	; 0x570 <xEventGroupWaitBits+0x58>
/*-----------------------------------------------------------*/

EventBits_t xEventGroupWaitBits( EventGroupHandle_t xEventGroup, const EventBits_t uxBitsToWaitFor, const BaseType_t xClearOnExit, const BaseType_t xWaitForAllBits, TickType_t xTicksToWait )
{
EventGroup_t *pxEventBits = xEventGroup;
EventBits_t uxReturn, uxControlBits = 0;
     56a:	60 e0       	ldi	r22, 0x00	; 0
     56c:	70 e0       	ldi	r23, 0x00	; 0
     56e:	02 c0       	rjmp	.+4      	; 0x574 <xEventGroupWaitBits+0x5c>
			set.  uxControlBits are used to remember the specified behaviour of
			this call to xEventGroupWaitBits() - for use when the event bits
			unblock the task. */
			if( xClearOnExit != pdFALSE )
			{
				uxControlBits |= eventCLEAR_EVENTS_ON_EXIT_BIT;
     570:	60 e0       	ldi	r22, 0x00	; 0
     572:	71 e0       	ldi	r23, 0x01	; 1
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}

			if( xWaitForAllBits != pdFALSE )
     574:	f1 10       	cpse	r15, r1
			{
				uxControlBits |= eventWAIT_FOR_ALL_BITS;
     576:	74 60       	ori	r23, 0x04	; 4
			}

			/* Store the bits that the calling task is waiting for in the
			task's event list item so the kernel knows when a match is
			found.  Then enter the blocked state. */
			vTaskPlaceOnUnorderedEventList( &( pxEventBits->xTasksWaitingForBits ), ( uxBitsToWaitFor | uxControlBits ), xTicksToWait );
     578:	6c 29       	or	r22, r12
     57a:	7d 29       	or	r23, r13
     57c:	c5 01       	movw	r24, r10
     57e:	02 96       	adiw	r24, 0x02	; 2
     580:	a8 01       	movw	r20, r16
     582:	0e 94 dd 10 	call	0x21ba	; 0x21ba <vTaskPlaceOnUnorderedEventList>
			uxReturn = 0;

			traceEVENT_GROUP_WAIT_BITS_BLOCK( xEventGroup, uxBitsToWaitFor );
		}
	}
	xAlreadyYielded = xTaskResumeAll();
     586:	0e 94 9c 0f 	call	0x1f38	; 0x1f38 <xTaskResumeAll>

	if( xTicksToWait != ( TickType_t ) 0 )
	{
		if( xAlreadyYielded == pdFALSE )
     58a:	88 23       	and	r24, r24
     58c:	39 f4       	brne	.+14     	; 0x59c <xEventGroupWaitBits+0x84>
     58e:	04 c0       	rjmp	.+8      	; 0x598 <xEventGroupWaitBits+0x80>
			uxReturn = 0;

			traceEVENT_GROUP_WAIT_BITS_BLOCK( xEventGroup, uxBitsToWaitFor );
		}
	}
	xAlreadyYielded = xTaskResumeAll();
     590:	0e 94 9c 0f 	call	0x1f38	; 0x1f38 <xTaskResumeAll>
     594:	ce 01       	movw	r24, r28
     596:	21 c0       	rjmp	.+66     	; 0x5da <xEventGroupWaitBits+0xc2>

	if( xTicksToWait != ( TickType_t ) 0 )
	{
		if( xAlreadyYielded == pdFALSE )
		{
			portYIELD_WITHIN_API();
     598:	0e 94 39 06 	call	0xc72	; 0xc72 <vPortYield>

		/* The task blocked to wait for its required bits to be set - at this
		point either the required bits were set or the block time expired.  If
		the required bits were set they will have been stored in the task's
		event list item, and they should now be retrieved then cleared. */
		uxReturn = uxTaskResetEventItemValue();
     59c:	0e 94 c5 11 	call	0x238a	; 0x238a <uxTaskResetEventItemValue>
     5a0:	ec 01       	movw	r28, r24

		if( ( uxReturn & eventUNBLOCKED_DUE_TO_BIT_SET ) == ( EventBits_t ) 0 )
     5a2:	91 fd       	sbrc	r25, 1
     5a4:	18 c0       	rjmp	.+48     	; 0x5d6 <xEventGroupWaitBits+0xbe>
		{
			taskENTER_CRITICAL();
     5a6:	0f b6       	in	r0, 0x3f	; 63
     5a8:	f8 94       	cli
     5aa:	0f 92       	push	r0
			{
				/* The task timed out, just return the current event bit value. */
				uxReturn = pxEventBits->uxEventBits;
     5ac:	f5 01       	movw	r30, r10
     5ae:	c0 81       	ld	r28, Z
     5b0:	d1 81       	ldd	r29, Z+1	; 0x01

				/* It is possible that the event bits were updated between this
				task leaving the Blocked state and running again. */
				if( prvTestWaitCondition( uxReturn, uxBitsToWaitFor, xWaitForAllBits ) != pdFALSE )
     5b2:	ce 01       	movw	r24, r28
     5b4:	b6 01       	movw	r22, r12
     5b6:	4f 2d       	mov	r20, r15
     5b8:	0e 94 65 02 	call	0x4ca	; 0x4ca <prvTestWaitCondition>
     5bc:	88 23       	and	r24, r24
     5be:	49 f0       	breq	.+18     	; 0x5d2 <xEventGroupWaitBits+0xba>
				{
					if( xClearOnExit != pdFALSE )
     5c0:	ee 20       	and	r14, r14
     5c2:	39 f0       	breq	.+14     	; 0x5d2 <xEventGroupWaitBits+0xba>
					{
						pxEventBits->uxEventBits &= ~uxBitsToWaitFor;
     5c4:	c0 94       	com	r12
     5c6:	d0 94       	com	r13
     5c8:	cc 22       	and	r12, r28
     5ca:	dd 22       	and	r13, r29
     5cc:	f5 01       	movw	r30, r10
     5ce:	d1 82       	std	Z+1, r13	; 0x01
     5d0:	c0 82       	st	Z, r12
				{
					mtCOVERAGE_TEST_MARKER();
				}
				xTimeoutOccurred = pdTRUE;
			}
			taskEXIT_CRITICAL();
     5d2:	0f 90       	pop	r0
     5d4:	0f be       	out	0x3f, r0	; 63
		{
			/* The task unblocked because the bits were set. */
		}

		/* The task blocked so control bits may have been set. */
		uxReturn &= ~eventEVENT_BITS_CONTROL_BYTES;
     5d6:	ce 01       	movw	r24, r28
     5d8:	90 70       	andi	r25, 0x00	; 0

	/* Prevent compiler warnings when trace macros are not used. */
	( void ) xTimeoutOccurred;

	return uxReturn;
}
     5da:	df 91       	pop	r29
     5dc:	cf 91       	pop	r28
     5de:	1f 91       	pop	r17
     5e0:	0f 91       	pop	r16
     5e2:	ff 90       	pop	r15
     5e4:	ef 90       	pop	r14
     5e6:	df 90       	pop	r13
     5e8:	cf 90       	pop	r12
     5ea:	bf 90       	pop	r11
     5ec:	af 90       	pop	r10
     5ee:	08 95       	ret

000005f0 <xEventGroupClearBits>:
/*-----------------------------------------------------------*/

EventBits_t xEventGroupClearBits( EventGroupHandle_t xEventGroup, const EventBits_t uxBitsToClear )
{
     5f0:	fc 01       	movw	r30, r24
	/* Check the user is not attempting to clear the bits used by the kernel
	itself. */
	configASSERT( xEventGroup );
	configASSERT( ( uxBitsToClear & eventEVENT_BITS_CONTROL_BYTES ) == 0 );

	taskENTER_CRITICAL();
     5f2:	0f b6       	in	r0, 0x3f	; 63
     5f4:	f8 94       	cli
     5f6:	0f 92       	push	r0
	{
		traceEVENT_GROUP_CLEAR_BITS( xEventGroup, uxBitsToClear );

		/* The value returned is the event group value prior to the bits being
		cleared. */
		uxReturn = pxEventBits->uxEventBits;
     5f8:	80 81       	ld	r24, Z
     5fa:	91 81       	ldd	r25, Z+1	; 0x01

		/* Clear the bits. */
		pxEventBits->uxEventBits &= ~uxBitsToClear;
     5fc:	60 95       	com	r22
     5fe:	70 95       	com	r23
     600:	68 23       	and	r22, r24
     602:	79 23       	and	r23, r25
     604:	71 83       	std	Z+1, r23	; 0x01
     606:	60 83       	st	Z, r22
	}
	taskEXIT_CRITICAL();
     608:	0f 90       	pop	r0
     60a:	0f be       	out	0x3f, r0	; 63

	return uxReturn;
}
     60c:	08 95       	ret

0000060e <xEventGroupGetBitsFromISR>:

#endif
/*-----------------------------------------------------------*/

EventBits_t xEventGroupGetBitsFromISR( EventGroupHandle_t xEventGroup )
{
     60e:	fc 01       	movw	r30, r24
		uxReturn = pxEventBits->uxEventBits;
	}
	portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );

	return uxReturn;
} /*lint !e818 EventGroupHandle_t is a typedef used in other functions to so can't be pointer to const. */
     610:	80 81       	ld	r24, Z
     612:	91 81       	ldd	r25, Z+1	; 0x01
     614:	08 95       	ret

00000616 <xEventGroupSetBits>:
/*-----------------------------------------------------------*/

EventBits_t xEventGroupSetBits( EventGroupHandle_t xEventGroup, const EventBits_t uxBitsToSet )
{
     616:	af 92       	push	r10
     618:	bf 92       	push	r11
     61a:	cf 92       	push	r12
     61c:	df 92       	push	r13
     61e:	ef 92       	push	r14
     620:	ff 92       	push	r15
     622:	0f 93       	push	r16
     624:	1f 93       	push	r17
     626:	cf 93       	push	r28
     628:	df 93       	push	r29
     62a:	8c 01       	movw	r16, r24
     62c:	eb 01       	movw	r28, r22
	itself. */
	configASSERT( xEventGroup );
	configASSERT( ( uxBitsToSet & eventEVENT_BITS_CONTROL_BYTES ) == 0 );

	pxList = &( pxEventBits->xTasksWaitingForBits );
	pxListEnd = listGET_END_MARKER( pxList ); /*lint !e826 !e740 !e9087 The mini list structure is used as the list end to save RAM.  This is checked and valid. */
     62e:	0f 2e       	mov	r0, r31
     630:	f5 e0       	ldi	r31, 0x05	; 5
     632:	cf 2e       	mov	r12, r31
     634:	dd 24       	eor	r13, r13
     636:	f0 2d       	mov	r31, r0
     638:	c8 0e       	add	r12, r24
     63a:	d9 1e       	adc	r13, r25
	vTaskSuspendAll();
     63c:	0e 94 be 0e 	call	0x1d7c	; 0x1d7c <vTaskSuspendAll>
	{
		traceEVENT_GROUP_SET_BITS( xEventGroup, uxBitsToSet );

		pxListItem = listGET_HEAD_ENTRY( pxList );
     640:	d8 01       	movw	r26, r16
     642:	17 96       	adiw	r26, 0x07	; 7
     644:	ed 91       	ld	r30, X+
     646:	fc 91       	ld	r31, X
     648:	18 97       	sbiw	r26, 0x08	; 8

		/* Set the bits. */
		pxEventBits->uxEventBits |= uxBitsToSet;
     64a:	8d 91       	ld	r24, X+
     64c:	9c 91       	ld	r25, X
     64e:	11 97       	sbiw	r26, 0x01	; 1
     650:	8c 2b       	or	r24, r28
     652:	9d 2b       	or	r25, r29
     654:	11 96       	adiw	r26, 0x01	; 1
     656:	9c 93       	st	X, r25
     658:	8e 93       	st	-X, r24

		/* See if the new bit value should unblock any tasks. */
		while( pxListItem != pxListEnd )
     65a:	ce 16       	cp	r12, r30
     65c:	df 06       	cpc	r13, r31
     65e:	c1 f1       	breq	.+112    	; 0x6d0 <xEventGroupSetBits+0xba>
EventBits_t xEventGroupSetBits( EventGroupHandle_t xEventGroup, const EventBits_t uxBitsToSet )
{
ListItem_t *pxListItem, *pxNext;
ListItem_t const *pxListEnd;
List_t const * pxList;
EventBits_t uxBitsToClear = 0, uxBitsWaitedFor, uxControlBits;
     660:	aa 24       	eor	r10, r10
     662:	bb 24       	eor	r11, r11
			if( ( uxControlBits & eventWAIT_FOR_ALL_BITS ) == ( EventBits_t ) 0 )
			{
				/* Just looking for single bit being set. */
				if( ( uxBitsWaitedFor & pxEventBits->uxEventBits ) != ( EventBits_t ) 0 )
				{
					xMatchFound = pdTRUE;
     664:	ff 24       	eor	r15, r15
     666:	f3 94       	inc	r15
     668:	ee 24       	eor	r14, r14
     66a:	01 c0       	rjmp	.+2      	; 0x66e <xEventGroupSetBits+0x58>

		/* Set the bits. */
		pxEventBits->uxEventBits |= uxBitsToSet;

		/* See if the new bit value should unblock any tasks. */
		while( pxListItem != pxListEnd )
     66c:	fe 01       	movw	r30, r28
		{
			pxNext = listGET_NEXT( pxListItem );
     66e:	c2 81       	ldd	r28, Z+2	; 0x02
     670:	d3 81       	ldd	r29, Z+3	; 0x03
			uxBitsWaitedFor = listGET_LIST_ITEM_VALUE( pxListItem );
     672:	80 81       	ld	r24, Z
     674:	91 81       	ldd	r25, Z+1	; 0x01
			xMatchFound = pdFALSE;

			/* Split the bits waited for from the control bits. */
			uxControlBits = uxBitsWaitedFor & eventEVENT_BITS_CONTROL_BYTES;
     676:	bc 01       	movw	r22, r24
     678:	60 70       	andi	r22, 0x00	; 0
			uxBitsWaitedFor &= ~eventEVENT_BITS_CONTROL_BYTES;
     67a:	9c 01       	movw	r18, r24
     67c:	30 70       	andi	r19, 0x00	; 0

			if( ( uxControlBits & eventWAIT_FOR_ALL_BITS ) == ( EventBits_t ) 0 )
     67e:	92 fd       	sbrc	r25, 2
     680:	0b c0       	rjmp	.+22     	; 0x698 <xEventGroupSetBits+0x82>
			{
				/* Just looking for single bit being set. */
				if( ( uxBitsWaitedFor & pxEventBits->uxEventBits ) != ( EventBits_t ) 0 )
     682:	d8 01       	movw	r26, r16
     684:	8d 91       	ld	r24, X+
     686:	9c 91       	ld	r25, X
     688:	11 97       	sbiw	r26, 0x01	; 1
     68a:	82 23       	and	r24, r18
     68c:	93 23       	and	r25, r19
				{
					xMatchFound = pdTRUE;
     68e:	4f 2d       	mov	r20, r15
     690:	00 97       	sbiw	r24, 0x00	; 0
     692:	69 f4       	brne	.+26     	; 0x6ae <xEventGroupSetBits+0x98>
     694:	4e 2d       	mov	r20, r14
     696:	0b c0       	rjmp	.+22     	; 0x6ae <xEventGroupSetBits+0x98>
				else
				{
					mtCOVERAGE_TEST_MARKER();
				}
			}
			else if( ( uxBitsWaitedFor & pxEventBits->uxEventBits ) == uxBitsWaitedFor )
     698:	d8 01       	movw	r26, r16
     69a:	8d 91       	ld	r24, X+
     69c:	9c 91       	ld	r25, X
     69e:	11 97       	sbiw	r26, 0x01	; 1
     6a0:	82 23       	and	r24, r18
     6a2:	93 23       	and	r25, r19
			if( ( uxControlBits & eventWAIT_FOR_ALL_BITS ) == ( EventBits_t ) 0 )
			{
				/* Just looking for single bit being set. */
				if( ( uxBitsWaitedFor & pxEventBits->uxEventBits ) != ( EventBits_t ) 0 )
				{
					xMatchFound = pdTRUE;
     6a4:	4f 2d       	mov	r20, r15
     6a6:	28 17       	cp	r18, r24
     6a8:	39 07       	cpc	r19, r25
     6aa:	09 f0       	breq	.+2      	; 0x6ae <xEventGroupSetBits+0x98>
     6ac:	4e 2d       	mov	r20, r14
			else
			{
				/* Need all bits to be set, but not all the bits were set. */
			}

			if( xMatchFound != pdFALSE )
     6ae:	44 23       	and	r20, r20
     6b0:	59 f0       	breq	.+22     	; 0x6c8 <xEventGroupSetBits+0xb2>
			{
				/* The bits match.  Should the bits be cleared on exit? */
				if( ( uxControlBits & eventCLEAR_EVENTS_ON_EXIT_BIT ) != ( EventBits_t ) 0 )
     6b2:	70 ff       	sbrs	r23, 0
     6b4:	02 c0       	rjmp	.+4      	; 0x6ba <xEventGroupSetBits+0xa4>
				{
					uxBitsToClear |= uxBitsWaitedFor;
     6b6:	a2 2a       	or	r10, r18
     6b8:	b3 2a       	or	r11, r19
				/* Store the actual event flag value in the task's event list
				item before removing the task from the event list.  The
				eventUNBLOCKED_DUE_TO_BIT_SET bit is set so the task knows
				that is was unblocked due to its required bits matching, rather
				than because it timed out. */
				vTaskRemoveFromUnorderedEventList( pxListItem, pxEventBits->uxEventBits | eventUNBLOCKED_DUE_TO_BIT_SET );
     6ba:	d8 01       	movw	r26, r16
     6bc:	6d 91       	ld	r22, X+
     6be:	7c 91       	ld	r23, X
     6c0:	72 60       	ori	r23, 0x02	; 2
     6c2:	cf 01       	movw	r24, r30
     6c4:	0e 94 41 11 	call	0x2282	; 0x2282 <vTaskRemoveFromUnorderedEventList>

		/* Set the bits. */
		pxEventBits->uxEventBits |= uxBitsToSet;

		/* See if the new bit value should unblock any tasks. */
		while( pxListItem != pxListEnd )
     6c8:	cc 16       	cp	r12, r28
     6ca:	dd 06       	cpc	r13, r29
     6cc:	79 f6       	brne	.-98     	; 0x66c <xEventGroupSetBits+0x56>
     6ce:	02 c0       	rjmp	.+4      	; 0x6d4 <xEventGroupSetBits+0xbe>
EventBits_t xEventGroupSetBits( EventGroupHandle_t xEventGroup, const EventBits_t uxBitsToSet )
{
ListItem_t *pxListItem, *pxNext;
ListItem_t const *pxListEnd;
List_t const * pxList;
EventBits_t uxBitsToClear = 0, uxBitsWaitedFor, uxControlBits;
     6d0:	aa 24       	eor	r10, r10
     6d2:	bb 24       	eor	r11, r11
			pxListItem = pxNext;
		}

		/* Clear any bits that matched when the eventCLEAR_EVENTS_ON_EXIT_BIT
		bit was set in the control word. */
		pxEventBits->uxEventBits &= ~uxBitsToClear;
     6d4:	c5 01       	movw	r24, r10
     6d6:	80 95       	com	r24
     6d8:	90 95       	com	r25
     6da:	f8 01       	movw	r30, r16
     6dc:	a0 80       	ld	r10, Z
     6de:	b1 80       	ldd	r11, Z+1	; 0x01
     6e0:	a8 22       	and	r10, r24
     6e2:	b9 22       	and	r11, r25
     6e4:	b1 82       	std	Z+1, r11	; 0x01
     6e6:	a0 82       	st	Z, r10
	}
	( void ) xTaskResumeAll();
     6e8:	0e 94 9c 0f 	call	0x1f38	; 0x1f38 <xTaskResumeAll>

	return pxEventBits->uxEventBits;
}
     6ec:	d8 01       	movw	r26, r16
     6ee:	8c 91       	ld	r24, X
     6f0:	11 96       	adiw	r26, 0x01	; 1
     6f2:	9c 91       	ld	r25, X
     6f4:	11 97       	sbiw	r26, 0x01	; 1
     6f6:	df 91       	pop	r29
     6f8:	cf 91       	pop	r28
     6fa:	1f 91       	pop	r17
     6fc:	0f 91       	pop	r16
     6fe:	ff 90       	pop	r15
     700:	ef 90       	pop	r14
     702:	df 90       	pop	r13
     704:	cf 90       	pop	r12
     706:	bf 90       	pop	r11
     708:	af 90       	pop	r10
     70a:	08 95       	ret

0000070c <xEventGroupSync>:

#endif /* configSUPPORT_DYNAMIC_ALLOCATION */
/*-----------------------------------------------------------*/

EventBits_t xEventGroupSync( EventGroupHandle_t xEventGroup, const EventBits_t uxBitsToSet, const EventBits_t uxBitsToWaitFor, TickType_t xTicksToWait )
{
     70c:	af 92       	push	r10
     70e:	bf 92       	push	r11
     710:	cf 92       	push	r12
     712:	df 92       	push	r13
     714:	ef 92       	push	r14
     716:	ff 92       	push	r15
     718:	0f 93       	push	r16
     71a:	1f 93       	push	r17
     71c:	cf 93       	push	r28
     71e:	df 93       	push	r29
     720:	6c 01       	movw	r12, r24
     722:	eb 01       	movw	r28, r22
     724:	7a 01       	movw	r14, r20
     726:	59 01       	movw	r10, r18
	{
		configASSERT( !( ( xTaskGetSchedulerState() == taskSCHEDULER_SUSPENDED ) && ( xTicksToWait != 0 ) ) );
	}
	#endif

	vTaskSuspendAll();
     728:	0e 94 be 0e 	call	0x1d7c	; 0x1d7c <vTaskSuspendAll>
	{
		uxOriginalBitValue = pxEventBits->uxEventBits;
     72c:	f6 01       	movw	r30, r12
     72e:	00 81       	ld	r16, Z
     730:	11 81       	ldd	r17, Z+1	; 0x01

		( void ) xEventGroupSetBits( xEventGroup, uxBitsToSet );
     732:	c6 01       	movw	r24, r12
     734:	be 01       	movw	r22, r28
     736:	0e 94 0b 03 	call	0x616	; 0x616 <xEventGroupSetBits>

		if( ( ( uxOriginalBitValue | uxBitsToSet ) & uxBitsToWaitFor ) == uxBitsToWaitFor )
     73a:	c0 2b       	or	r28, r16
     73c:	d1 2b       	or	r29, r17
     73e:	c7 01       	movw	r24, r14
     740:	8c 23       	and	r24, r28
     742:	9d 23       	and	r25, r29
     744:	8e 15       	cp	r24, r14
     746:	9f 05       	cpc	r25, r15
     748:	51 f4       	brne	.+20     	; 0x75e <xEventGroupSync+0x52>
			/* All the rendezvous bits are now set - no need to block. */
			uxReturn = ( uxOriginalBitValue | uxBitsToSet );

			/* Rendezvous always clear the bits.  They will have been cleared
			already unless this is the only task in the rendezvous. */
			pxEventBits->uxEventBits &= ~uxBitsToWaitFor;
     74a:	80 95       	com	r24
     74c:	90 95       	com	r25
     74e:	f6 01       	movw	r30, r12
     750:	20 81       	ld	r18, Z
     752:	31 81       	ldd	r19, Z+1	; 0x01
     754:	82 23       	and	r24, r18
     756:	93 23       	and	r25, r19
     758:	91 83       	std	Z+1, r25	; 0x01
     75a:	80 83       	st	Z, r24
     75c:	12 c0       	rjmp	.+36     	; 0x782 <xEventGroupSync+0x76>

			xTicksToWait = 0;
		}
		else
		{
			if( xTicksToWait != ( TickType_t ) 0 )
     75e:	a1 14       	cp	r10, r1
     760:	b1 04       	cpc	r11, r1
     762:	61 f0       	breq	.+24     	; 0x77c <xEventGroupSync+0x70>
				traceEVENT_GROUP_SYNC_BLOCK( xEventGroup, uxBitsToSet, uxBitsToWaitFor );

				/* Store the bits that the calling task is waiting for in the
				task's event list item so the kernel knows when a match is
				found.  Then enter the blocked state. */
				vTaskPlaceOnUnorderedEventList( &( pxEventBits->xTasksWaitingForBits ), ( uxBitsToWaitFor | eventCLEAR_EVENTS_ON_EXIT_BIT | eventWAIT_FOR_ALL_BITS ), xTicksToWait );
     764:	b7 01       	movw	r22, r14
     766:	75 60       	ori	r23, 0x05	; 5
     768:	c6 01       	movw	r24, r12
     76a:	02 96       	adiw	r24, 0x02	; 2
     76c:	a5 01       	movw	r20, r10
     76e:	0e 94 dd 10 	call	0x21ba	; 0x21ba <vTaskPlaceOnUnorderedEventList>
				uxReturn = pxEventBits->uxEventBits;
				xTimeoutOccurred = pdTRUE;
			}
		}
	}
	xAlreadyYielded = xTaskResumeAll();
     772:	0e 94 9c 0f 	call	0x1f38	; 0x1f38 <xTaskResumeAll>

	if( xTicksToWait != ( TickType_t ) 0 )
	{
		if( xAlreadyYielded == pdFALSE )
     776:	88 23       	and	r24, r24
     778:	49 f4       	brne	.+18     	; 0x78c <xEventGroupSync+0x80>
     77a:	06 c0       	rjmp	.+12     	; 0x788 <xEventGroupSync+0x7c>
			}
			else
			{
				/* The rendezvous bits were not set, but no block time was
				specified - just return the current event bit value. */
				uxReturn = pxEventBits->uxEventBits;
     77c:	f6 01       	movw	r30, r12
     77e:	c0 81       	ld	r28, Z
     780:	d1 81       	ldd	r29, Z+1	; 0x01
				xTimeoutOccurred = pdTRUE;
			}
		}
	}
	xAlreadyYielded = xTaskResumeAll();
     782:	0e 94 9c 0f 	call	0x1f38	; 0x1f38 <xTaskResumeAll>
     786:	1c c0       	rjmp	.+56     	; 0x7c0 <xEventGroupSync+0xb4>

	if( xTicksToWait != ( TickType_t ) 0 )
	{
		if( xAlreadyYielded == pdFALSE )
		{
			portYIELD_WITHIN_API();
     788:	0e 94 39 06 	call	0xc72	; 0xc72 <vPortYield>

		/* The task blocked to wait for its required bits to be set - at this
		point either the required bits were set or the block time expired.  If
		the required bits were set they will have been stored in the task's
		event list item, and they should now be retrieved then cleared. */
		uxReturn = uxTaskResetEventItemValue();
     78c:	0e 94 c5 11 	call	0x238a	; 0x238a <uxTaskResetEventItemValue>

		if( ( uxReturn & eventUNBLOCKED_DUE_TO_BIT_SET ) == ( EventBits_t ) 0 )
     790:	91 fd       	sbrc	r25, 1
     792:	14 c0       	rjmp	.+40     	; 0x7bc <xEventGroupSync+0xb0>
		{
			/* The task timed out, just return the current event bit value. */
			taskENTER_CRITICAL();
     794:	0f b6       	in	r0, 0x3f	; 63
     796:	f8 94       	cli
     798:	0f 92       	push	r0
			{
				uxReturn = pxEventBits->uxEventBits;
     79a:	f6 01       	movw	r30, r12
     79c:	80 81       	ld	r24, Z
     79e:	91 81       	ldd	r25, Z+1	; 0x01

				/* Although the task got here because it timed out before the
				bits it was waiting for were set, it is possible that since it
				unblocked another task has set the bits.  If this is the case
				then it needs to clear the bits before exiting. */
				if( ( uxReturn & uxBitsToWaitFor ) == uxBitsToWaitFor )
     7a0:	97 01       	movw	r18, r14
     7a2:	28 23       	and	r18, r24
     7a4:	39 23       	and	r19, r25
     7a6:	2e 15       	cp	r18, r14
     7a8:	3f 05       	cpc	r19, r15
     7aa:	31 f4       	brne	.+12     	; 0x7b8 <xEventGroupSync+0xac>
				{
					pxEventBits->uxEventBits &= ~uxBitsToWaitFor;
     7ac:	20 95       	com	r18
     7ae:	30 95       	com	r19
     7b0:	28 23       	and	r18, r24
     7b2:	39 23       	and	r19, r25
     7b4:	31 83       	std	Z+1, r19	; 0x01
     7b6:	20 83       	st	Z, r18
				else
				{
					mtCOVERAGE_TEST_MARKER();
				}
			}
			taskEXIT_CRITICAL();
     7b8:	0f 90       	pop	r0
     7ba:	0f be       	out	0x3f, r0	; 63
			/* The task unblocked because the bits were set. */
		}

		/* Control bits might be set as the task had blocked should not be
		returned. */
		uxReturn &= ~eventEVENT_BITS_CONTROL_BYTES;
     7bc:	ec 01       	movw	r28, r24
     7be:	d0 70       	andi	r29, 0x00	; 0

	/* Prevent compiler warnings when trace macros are not used. */
	( void ) xTimeoutOccurred;

	return uxReturn;
}
     7c0:	8c 2f       	mov	r24, r28
     7c2:	9d 2f       	mov	r25, r29
     7c4:	df 91       	pop	r29
     7c6:	cf 91       	pop	r28
     7c8:	1f 91       	pop	r17
     7ca:	0f 91       	pop	r16
     7cc:	ff 90       	pop	r15
     7ce:	ef 90       	pop	r14
     7d0:	df 90       	pop	r13
     7d2:	cf 90       	pop	r12
     7d4:	bf 90       	pop	r11
     7d6:	af 90       	pop	r10
     7d8:	08 95       	ret

000007da <vEventGroupDelete>:
	return pxEventBits->uxEventBits;
}
/*-----------------------------------------------------------*/

void vEventGroupDelete( EventGroupHandle_t xEventGroup )
{
     7da:	cf 93       	push	r28
     7dc:	df 93       	push	r29
     7de:	ec 01       	movw	r28, r24
EventGroup_t *pxEventBits = xEventGroup;
const List_t *pxTasksWaitingForBits = &( pxEventBits->xTasksWaitingForBits );

	vTaskSuspendAll();
     7e0:	0e 94 be 0e 	call	0x1d7c	; 0x1d7c <vTaskSuspendAll>
	{
		traceEVENT_GROUP_DELETE( xEventGroup );

		while( listCURRENT_LIST_LENGTH( pxTasksWaitingForBits ) > ( UBaseType_t ) 0 )
     7e4:	8a 81       	ldd	r24, Y+2	; 0x02
     7e6:	88 23       	and	r24, r24
     7e8:	49 f0       	breq	.+18     	; 0x7fc <vEventGroupDelete+0x22>
		{
			/* Unblock the task, returning 0 as the event list is being deleted
			and cannot therefore have any bits set. */
			configASSERT( pxTasksWaitingForBits->xListEnd.pxNext != ( const ListItem_t * ) &( pxTasksWaitingForBits->xListEnd ) );
			vTaskRemoveFromUnorderedEventList( pxTasksWaitingForBits->xListEnd.pxNext, eventUNBLOCKED_DUE_TO_BIT_SET );
     7ea:	8f 81       	ldd	r24, Y+7	; 0x07
     7ec:	98 85       	ldd	r25, Y+8	; 0x08
     7ee:	60 e0       	ldi	r22, 0x00	; 0
     7f0:	72 e0       	ldi	r23, 0x02	; 2
     7f2:	0e 94 41 11 	call	0x2282	; 0x2282 <vTaskRemoveFromUnorderedEventList>

	vTaskSuspendAll();
	{
		traceEVENT_GROUP_DELETE( xEventGroup );

		while( listCURRENT_LIST_LENGTH( pxTasksWaitingForBits ) > ( UBaseType_t ) 0 )
     7f6:	8a 81       	ldd	r24, Y+2	; 0x02
     7f8:	88 23       	and	r24, r24
     7fa:	b9 f7       	brne	.-18     	; 0x7ea <vEventGroupDelete+0x10>

		#if( ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) && ( configSUPPORT_STATIC_ALLOCATION == 0 ) )
		{
			/* The event group can only have been allocated dynamically - free
			it again. */
			vPortFree( pxEventBits );
     7fc:	ce 01       	movw	r24, r28
     7fe:	0e 94 ae 04 	call	0x95c	; 0x95c <vPortFree>
				mtCOVERAGE_TEST_MARKER();
			}
		}
		#endif /* configSUPPORT_DYNAMIC_ALLOCATION */
	}
	( void ) xTaskResumeAll();
     802:	0e 94 9c 0f 	call	0x1f38	; 0x1f38 <xTaskResumeAll>
}
     806:	df 91       	pop	r29
     808:	cf 91       	pop	r28
     80a:	08 95       	ret

0000080c <vEventGroupSetBitsCallback>:

/* For internal use only - execute a 'set bits' command that was pended from
an interrupt. */
void vEventGroupSetBitsCallback( void *pvEventGroup, const uint32_t ulBitsToSet )
{
	( void ) xEventGroupSetBits( pvEventGroup, ( EventBits_t ) ulBitsToSet ); /*lint !e9079 Can't avoid cast to void* as a generic timer callback prototype. Callback casts back to original type so safe. */
     80c:	ba 01       	movw	r22, r20
     80e:	0e 94 0b 03 	call	0x616	; 0x616 <xEventGroupSetBits>
}
     812:	08 95       	ret

00000814 <vEventGroupClearBitsCallback>:

/* For internal use only - execute a 'clear bits' command that was pended from
an interrupt. */
void vEventGroupClearBitsCallback( void *pvEventGroup, const uint32_t ulBitsToClear )
{
	( void ) xEventGroupClearBits( pvEventGroup, ( EventBits_t ) ulBitsToClear ); /*lint !e9079 Can't avoid cast to void* as a generic timer callback prototype. Callback casts back to original type so safe. */
     814:	ba 01       	movw	r22, r20
     816:	0e 94 f8 02 	call	0x5f0	; 0x5f0 <xEventGroupClearBits>
}
     81a:	08 95       	ret

0000081c <pvPortMalloc>:
	pxIterator->pxNextFreeBlock = pxBlockToInsert;									\
}
/*-----------------------------------------------------------*/

void *pvPortMalloc( size_t xWantedSize )
{
     81c:	0f 93       	push	r16
     81e:	1f 93       	push	r17
     820:	cf 93       	push	r28
     822:	df 93       	push	r29
     824:	ec 01       	movw	r28, r24
BlockLink_t *pxBlock, *pxPreviousBlock, *pxNewBlockLink;
static BaseType_t xHeapHasBeenInitialised = pdFALSE;
void *pvReturn = NULL;

	vTaskSuspendAll();
     826:	0e 94 be 0e 	call	0x1d7c	; 0x1d7c <vTaskSuspendAll>
	{
		/* If this is the first call to malloc then the heap will require
		initialisation to setup the list of free blocks. */
		if( xHeapHasBeenInitialised == pdFALSE )
     82a:	80 91 a6 00 	lds	r24, 0x00A6
     82e:	88 23       	and	r24, r24
     830:	f9 f4       	brne	.+62     	; 0x870 <__stack+0x11>
	/* Ensure the heap starts on a correctly aligned boundary. */
	pucAlignedHeap = ( uint8_t * ) ( ( ( portPOINTER_SIZE_TYPE ) &ucHeap[ portBYTE_ALIGNMENT ] ) & ( ~( ( portPOINTER_SIZE_TYPE ) portBYTE_ALIGNMENT_MASK ) ) );

	/* xStart is used to hold a pointer to the first item in the list of free
	blocks.  The void cast is used to prevent compiler warnings. */
	xStart.pxNextFreeBlock = ( void * ) pucAlignedHeap;
     832:	80 eb       	ldi	r24, 0xB0	; 176
     834:	90 e0       	ldi	r25, 0x00	; 0
     836:	90 93 a8 00 	sts	0x00A8, r25
     83a:	80 93 a7 00 	sts	0x00A7, r24
	xStart.xBlockSize = ( size_t ) 0;
     83e:	10 92 aa 00 	sts	0x00AA, r1
     842:	10 92 a9 00 	sts	0x00A9, r1

	/* xEnd is used to mark the end of the list of free blocks. */
	xEnd.xBlockSize = configADJUSTED_HEAP_SIZE;
     846:	8b ed       	ldi	r24, 0xDB	; 219
     848:	95 e0       	ldi	r25, 0x05	; 5
     84a:	90 93 ae 00 	sts	0x00AE, r25
     84e:	80 93 ad 00 	sts	0x00AD, r24
	xEnd.pxNextFreeBlock = NULL;
     852:	ed ea       	ldi	r30, 0xAD	; 173
     854:	f0 e0       	ldi	r31, 0x00	; 0
     856:	12 92       	st	-Z, r1
     858:	12 92       	st	-Z, r1

	/* To start with there is a single free block that is sized to take up the
	entire heap space. */
	pxFirstFreeBlock = ( void * ) pucAlignedHeap;
	pxFirstFreeBlock->xBlockSize = configADJUSTED_HEAP_SIZE;
     85a:	90 93 b3 00 	sts	0x00B3, r25
     85e:	80 93 b2 00 	sts	0x00B2, r24
	pxFirstFreeBlock->pxNextFreeBlock = &xEnd;
     862:	f0 93 b1 00 	sts	0x00B1, r31
     866:	e0 93 b0 00 	sts	0x00B0, r30
		/* If this is the first call to malloc then the heap will require
		initialisation to setup the list of free blocks. */
		if( xHeapHasBeenInitialised == pdFALSE )
		{
			prvHeapInit();
			xHeapHasBeenInitialised = pdTRUE;
     86a:	81 e0       	ldi	r24, 0x01	; 1
     86c:	80 93 a6 00 	sts	0x00A6, r24
		}

		/* The wanted size is increased so it can contain a BlockLink_t
		structure in addition to the requested amount of bytes. */
		if( xWantedSize > 0 )
     870:	20 97       	sbiw	r28, 0x00	; 0
     872:	09 f4       	brne	.+2      	; 0x876 <__stack+0x17>
     874:	62 c0       	rjmp	.+196    	; 0x93a <__stack+0xdb>
		{
			xWantedSize += heapSTRUCT_SIZE;
     876:	9e 01       	movw	r18, r28
     878:	2c 5f       	subi	r18, 0xFC	; 252
     87a:	3f 4f       	sbci	r19, 0xFF	; 255
				/* Byte alignment required. */
				xWantedSize += ( portBYTE_ALIGNMENT - ( xWantedSize & portBYTE_ALIGNMENT_MASK ) );
			}
		}

		if( ( xWantedSize > 0 ) && ( xWantedSize < configADJUSTED_HEAP_SIZE ) )
     87c:	23 96       	adiw	r28, 0x03	; 3
     87e:	85 e0       	ldi	r24, 0x05	; 5
     880:	ca 3d       	cpi	r28, 0xDA	; 218
     882:	d8 07       	cpc	r29, r24
     884:	08 f0       	brcs	.+2      	; 0x888 <__stack+0x29>
     886:	5c c0       	rjmp	.+184    	; 0x940 <__stack+0xe1>
		{
			/* Blocks are stored in byte order - traverse the list from the start
			(smallest) block until one of adequate size is found. */
			pxPreviousBlock = &xStart;
			pxBlock = xStart.pxNextFreeBlock;
     888:	e0 91 a7 00 	lds	r30, 0x00A7
     88c:	f0 91 a8 00 	lds	r31, 0x00A8

		if( ( xWantedSize > 0 ) && ( xWantedSize < configADJUSTED_HEAP_SIZE ) )
		{
			/* Blocks are stored in byte order - traverse the list from the start
			(smallest) block until one of adequate size is found. */
			pxPreviousBlock = &xStart;
     890:	a7 ea       	ldi	r26, 0xA7	; 167
     892:	b0 e0       	ldi	r27, 0x00	; 0
			pxBlock = xStart.pxNextFreeBlock;
			while( ( pxBlock->xBlockSize < xWantedSize ) && ( pxBlock->pxNextFreeBlock != NULL ) )
     894:	02 c0       	rjmp	.+4      	; 0x89a <__stack+0x3b>
     896:	df 01       	movw	r26, r30
			{
				pxPreviousBlock = pxBlock;
				pxBlock = pxBlock->pxNextFreeBlock;
     898:	fc 01       	movw	r30, r24
		{
			/* Blocks are stored in byte order - traverse the list from the start
			(smallest) block until one of adequate size is found. */
			pxPreviousBlock = &xStart;
			pxBlock = xStart.pxNextFreeBlock;
			while( ( pxBlock->xBlockSize < xWantedSize ) && ( pxBlock->pxNextFreeBlock != NULL ) )
     89a:	82 81       	ldd	r24, Z+2	; 0x02
     89c:	93 81       	ldd	r25, Z+3	; 0x03
     89e:	82 17       	cp	r24, r18
     8a0:	93 07       	cpc	r25, r19
     8a2:	20 f4       	brcc	.+8      	; 0x8ac <__stack+0x4d>
     8a4:	80 81       	ld	r24, Z
     8a6:	91 81       	ldd	r25, Z+1	; 0x01
     8a8:	00 97       	sbiw	r24, 0x00	; 0
     8aa:	a9 f7       	brne	.-22     	; 0x896 <__stack+0x37>
				pxPreviousBlock = pxBlock;
				pxBlock = pxBlock->pxNextFreeBlock;
			}

			/* If we found the end marker then a block of adequate size was not found. */
			if( pxBlock != &xEnd )
     8ac:	c0 e0       	ldi	r28, 0x00	; 0
     8ae:	eb 3a       	cpi	r30, 0xAB	; 171
     8b0:	fc 07       	cpc	r31, r28
     8b2:	09 f4       	brne	.+2      	; 0x8b6 <__stack+0x57>
     8b4:	48 c0       	rjmp	.+144    	; 0x946 <__stack+0xe7>
			{
				/* Return the memory space - jumping over the BlockLink_t structure
				at its start. */
				pvReturn = ( void * ) ( ( ( uint8_t * ) pxPreviousBlock->pxNextFreeBlock ) + heapSTRUCT_SIZE );
     8b6:	8d 91       	ld	r24, X+
     8b8:	9c 91       	ld	r25, X
     8ba:	11 97       	sbiw	r26, 0x01	; 1
     8bc:	8c 01       	movw	r16, r24
     8be:	0c 5f       	subi	r16, 0xFC	; 252
     8c0:	1f 4f       	sbci	r17, 0xFF	; 255

				/* This block is being returned for use so must be taken out of the
				list of free blocks. */
				pxPreviousBlock->pxNextFreeBlock = pxBlock->pxNextFreeBlock;
     8c2:	80 81       	ld	r24, Z
     8c4:	91 81       	ldd	r25, Z+1	; 0x01
     8c6:	11 96       	adiw	r26, 0x01	; 1
     8c8:	9c 93       	st	X, r25
     8ca:	8e 93       	st	-X, r24

				/* If the block is larger than required it can be split into two. */
				if( ( pxBlock->xBlockSize - xWantedSize ) > heapMINIMUM_BLOCK_SIZE )
     8cc:	82 81       	ldd	r24, Z+2	; 0x02
     8ce:	93 81       	ldd	r25, Z+3	; 0x03
     8d0:	82 1b       	sub	r24, r18
     8d2:	93 0b       	sbc	r25, r19
     8d4:	89 30       	cpi	r24, 0x09	; 9
     8d6:	91 05       	cpc	r25, r1
     8d8:	18 f1       	brcs	.+70     	; 0x920 <__stack+0xc1>
				{
					/* This block is to be split into two.  Create a new block
					following the number of bytes requested. The void cast is
					used to prevent byte alignment warnings from the compiler. */
					pxNewBlockLink = ( void * ) ( ( ( uint8_t * ) pxBlock ) + xWantedSize );
     8da:	af 01       	movw	r20, r30
     8dc:	42 0f       	add	r20, r18
     8de:	53 1f       	adc	r21, r19

					/* Calculate the sizes of two blocks split from the single
					block. */
					pxNewBlockLink->xBlockSize = pxBlock->xBlockSize - xWantedSize;
     8e0:	da 01       	movw	r26, r20
     8e2:	13 96       	adiw	r26, 0x03	; 3
     8e4:	9c 93       	st	X, r25
     8e6:	8e 93       	st	-X, r24
     8e8:	12 97       	sbiw	r26, 0x02	; 2
					pxBlock->xBlockSize = xWantedSize;
     8ea:	33 83       	std	Z+3, r19	; 0x03
     8ec:	22 83       	std	Z+2, r18	; 0x02

					/* Insert the new block into the list of free blocks. */
					prvInsertBlockIntoFreeList( ( pxNewBlockLink ) );
     8ee:	12 96       	adiw	r26, 0x02	; 2
     8f0:	2d 91       	ld	r18, X+
     8f2:	3c 91       	ld	r19, X
     8f4:	13 97       	sbiw	r26, 0x03	; 3
     8f6:	67 ea       	ldi	r22, 0xA7	; 167
     8f8:	70 e0       	ldi	r23, 0x00	; 0
     8fa:	01 c0       	rjmp	.+2      	; 0x8fe <__stack+0x9f>
     8fc:	bd 01       	movw	r22, r26
     8fe:	eb 01       	movw	r28, r22
     900:	a8 81       	ld	r26, Y
     902:	b9 81       	ldd	r27, Y+1	; 0x01
     904:	12 96       	adiw	r26, 0x02	; 2
     906:	8d 91       	ld	r24, X+
     908:	9c 91       	ld	r25, X
     90a:	13 97       	sbiw	r26, 0x03	; 3
     90c:	82 17       	cp	r24, r18
     90e:	93 07       	cpc	r25, r19
     910:	a8 f3       	brcs	.-22     	; 0x8fc <__stack+0x9d>
     912:	ea 01       	movw	r28, r20
     914:	b9 83       	std	Y+1, r27	; 0x01
     916:	a8 83       	st	Y, r26
     918:	db 01       	movw	r26, r22
     91a:	11 96       	adiw	r26, 0x01	; 1
     91c:	5c 93       	st	X, r21
     91e:	4e 93       	st	-X, r20
				}

				xFreeBytesRemaining -= pxBlock->xBlockSize;
     920:	80 91 60 00 	lds	r24, 0x0060
     924:	90 91 61 00 	lds	r25, 0x0061
     928:	22 81       	ldd	r18, Z+2	; 0x02
     92a:	33 81       	ldd	r19, Z+3	; 0x03
     92c:	82 1b       	sub	r24, r18
     92e:	93 0b       	sbc	r25, r19
     930:	90 93 61 00 	sts	0x0061, r25
     934:	80 93 60 00 	sts	0x0060, r24
     938:	08 c0       	rjmp	.+16     	; 0x94a <__stack+0xeb>

void *pvPortMalloc( size_t xWantedSize )
{
BlockLink_t *pxBlock, *pxPreviousBlock, *pxNewBlockLink;
static BaseType_t xHeapHasBeenInitialised = pdFALSE;
void *pvReturn = NULL;
     93a:	00 e0       	ldi	r16, 0x00	; 0
     93c:	10 e0       	ldi	r17, 0x00	; 0
     93e:	05 c0       	rjmp	.+10     	; 0x94a <__stack+0xeb>
     940:	00 e0       	ldi	r16, 0x00	; 0
     942:	10 e0       	ldi	r17, 0x00	; 0
     944:	02 c0       	rjmp	.+4      	; 0x94a <__stack+0xeb>
     946:	00 e0       	ldi	r16, 0x00	; 0
     948:	10 e0       	ldi	r17, 0x00	; 0
			}
		}

		traceMALLOC( pvReturn, xWantedSize );
	}
	( void ) xTaskResumeAll();
     94a:	0e 94 9c 0f 	call	0x1f38	; 0x1f38 <xTaskResumeAll>
		}
	}
	#endif

	return pvReturn;
}
     94e:	80 2f       	mov	r24, r16
     950:	91 2f       	mov	r25, r17
     952:	df 91       	pop	r29
     954:	cf 91       	pop	r28
     956:	1f 91       	pop	r17
     958:	0f 91       	pop	r16
     95a:	08 95       	ret

0000095c <vPortFree>:
/*-----------------------------------------------------------*/

void vPortFree( void *pv )
{
     95c:	0f 93       	push	r16
     95e:	1f 93       	push	r17
     960:	cf 93       	push	r28
     962:	df 93       	push	r29
     964:	ec 01       	movw	r28, r24
uint8_t *puc = ( uint8_t * ) pv;
BlockLink_t *pxLink;

	if( pv != NULL )
     966:	00 97       	sbiw	r24, 0x00	; 0
     968:	39 f1       	breq	.+78     	; 0x9b8 <vPortFree+0x5c>
		before it. */
		puc -= heapSTRUCT_SIZE;

		/* This unexpected casting is to keep some compilers from issuing
		byte alignment warnings. */
		pxLink = ( void * ) puc;
     96a:	8c 01       	movw	r16, r24
     96c:	04 50       	subi	r16, 0x04	; 4
     96e:	10 40       	sbci	r17, 0x00	; 0

		vTaskSuspendAll();
     970:	0e 94 be 0e 	call	0x1d7c	; 0x1d7c <vTaskSuspendAll>
		{
			/* Add this block to the list of free blocks. */
			prvInsertBlockIntoFreeList( ( ( BlockLink_t * ) pxLink ) );
     974:	f8 01       	movw	r30, r16
     976:	22 81       	ldd	r18, Z+2	; 0x02
     978:	33 81       	ldd	r19, Z+3	; 0x03
     97a:	a7 ea       	ldi	r26, 0xA7	; 167
     97c:	b0 e0       	ldi	r27, 0x00	; 0
     97e:	01 c0       	rjmp	.+2      	; 0x982 <vPortFree+0x26>
     980:	df 01       	movw	r26, r30
     982:	ed 91       	ld	r30, X+
     984:	fc 91       	ld	r31, X
     986:	11 97       	sbiw	r26, 0x01	; 1
     988:	82 81       	ldd	r24, Z+2	; 0x02
     98a:	93 81       	ldd	r25, Z+3	; 0x03
     98c:	82 17       	cp	r24, r18
     98e:	93 07       	cpc	r25, r19
     990:	b8 f3       	brcs	.-18     	; 0x980 <vPortFree+0x24>
     992:	24 97       	sbiw	r28, 0x04	; 4
     994:	f9 83       	std	Y+1, r31	; 0x01
     996:	e8 83       	st	Y, r30
     998:	0d 93       	st	X+, r16
     99a:	1c 93       	st	X, r17
			xFreeBytesRemaining += pxLink->xBlockSize;
     99c:	80 91 60 00 	lds	r24, 0x0060
     9a0:	90 91 61 00 	lds	r25, 0x0061
     9a4:	2a 81       	ldd	r18, Y+2	; 0x02
     9a6:	3b 81       	ldd	r19, Y+3	; 0x03
     9a8:	82 0f       	add	r24, r18
     9aa:	93 1f       	adc	r25, r19
     9ac:	90 93 61 00 	sts	0x0061, r25
     9b0:	80 93 60 00 	sts	0x0060, r24
			traceFREE( pv, pxLink->xBlockSize );
		}
		( void ) xTaskResumeAll();
     9b4:	0e 94 9c 0f 	call	0x1f38	; 0x1f38 <xTaskResumeAll>
	}
}
     9b8:	df 91       	pop	r29
     9ba:	cf 91       	pop	r28
     9bc:	1f 91       	pop	r17
     9be:	0f 91       	pop	r16
     9c0:	08 95       	ret

000009c2 <xPortGetFreeHeapSize>:
/*-----------------------------------------------------------*/

size_t xPortGetFreeHeapSize( void )
{
	return xFreeBytesRemaining;
}
     9c2:	80 91 60 00 	lds	r24, 0x0060
     9c6:	90 91 61 00 	lds	r25, 0x0061
     9ca:	08 95       	ret

000009cc <vPortInitialiseBlocks>:
/*-----------------------------------------------------------*/

void vPortInitialiseBlocks( void )
{
	/* This just exists to keep the linker quiet. */
}
     9cc:	08 95       	ret

000009ce <vListInitialise>:
/*-----------------------------------------------------------
 * PUBLIC LIST API documented in list.h
 *----------------------------------------------------------*/

void vListInitialise( List_t * const pxList )
{
     9ce:	fc 01       	movw	r30, r24
	/* The list structure contains a list item which is used to mark the
	end of the list.  To initialise the list the list end is inserted
	as the only list entry. */
	pxList->pxIndex = ( ListItem_t * ) &( pxList->xListEnd );			/*lint !e826 !e740 !e9087 The mini list structure is used as the list end to save RAM.  This is checked and valid. */
     9d0:	03 96       	adiw	r24, 0x03	; 3
     9d2:	92 83       	std	Z+2, r25	; 0x02
     9d4:	81 83       	std	Z+1, r24	; 0x01

	/* The list end value is the highest possible value in the list to
	ensure it remains at the end of the list. */
	pxList->xListEnd.xItemValue = portMAX_DELAY;
     9d6:	2f ef       	ldi	r18, 0xFF	; 255
     9d8:	3f ef       	ldi	r19, 0xFF	; 255
     9da:	34 83       	std	Z+4, r19	; 0x04
     9dc:	23 83       	std	Z+3, r18	; 0x03

	/* The list end next and previous pointers point to itself so we know
	when the list is empty. */
	pxList->xListEnd.pxNext = ( ListItem_t * ) &( pxList->xListEnd );	/*lint !e826 !e740 !e9087 The mini list structure is used as the list end to save RAM.  This is checked and valid. */
     9de:	96 83       	std	Z+6, r25	; 0x06
     9e0:	85 83       	std	Z+5, r24	; 0x05
	pxList->xListEnd.pxPrevious = ( ListItem_t * ) &( pxList->xListEnd );/*lint !e826 !e740 !e9087 The mini list structure is used as the list end to save RAM.  This is checked and valid. */
     9e2:	90 87       	std	Z+8, r25	; 0x08
     9e4:	87 83       	std	Z+7, r24	; 0x07

	pxList->uxNumberOfItems = ( UBaseType_t ) 0U;
     9e6:	10 82       	st	Z, r1

	/* Write known values into the list if
	configUSE_LIST_DATA_INTEGRITY_CHECK_BYTES is set to 1. */
	listSET_LIST_INTEGRITY_CHECK_1_VALUE( pxList );
	listSET_LIST_INTEGRITY_CHECK_2_VALUE( pxList );
}
     9e8:	08 95       	ret

000009ea <vListInitialiseItem>:
/*-----------------------------------------------------------*/

void vListInitialiseItem( ListItem_t * const pxItem )
{
	/* Make sure the list item is not recorded as being on a list. */
	pxItem->pxContainer = NULL;
     9ea:	fc 01       	movw	r30, r24
     9ec:	11 86       	std	Z+9, r1	; 0x09
     9ee:	10 86       	std	Z+8, r1	; 0x08

	/* Write known values into the list item if
	configUSE_LIST_DATA_INTEGRITY_CHECK_BYTES is set to 1. */
	listSET_FIRST_LIST_ITEM_INTEGRITY_CHECK_VALUE( pxItem );
	listSET_SECOND_LIST_ITEM_INTEGRITY_CHECK_VALUE( pxItem );
}
     9f0:	08 95       	ret

000009f2 <vListInsertEnd>:
/*-----------------------------------------------------------*/

void vListInsertEnd( List_t * const pxList, ListItem_t * const pxNewListItem )
{
     9f2:	cf 93       	push	r28
     9f4:	df 93       	push	r29
     9f6:	fb 01       	movw	r30, r22
ListItem_t * const pxIndex = pxList->pxIndex;
     9f8:	dc 01       	movw	r26, r24
     9fa:	11 96       	adiw	r26, 0x01	; 1
     9fc:	cd 91       	ld	r28, X+
     9fe:	dc 91       	ld	r29, X
     a00:	12 97       	sbiw	r26, 0x02	; 2
	listTEST_LIST_ITEM_INTEGRITY( pxNewListItem );

	/* Insert a new list item into pxList, but rather than sort the list,
	makes the new list item the last item to be removed by a call to
	listGET_OWNER_OF_NEXT_ENTRY(). */
	pxNewListItem->pxNext = pxIndex;
     a02:	d3 83       	std	Z+3, r29	; 0x03
     a04:	c2 83       	std	Z+2, r28	; 0x02
	pxNewListItem->pxPrevious = pxIndex->pxPrevious;
     a06:	2c 81       	ldd	r18, Y+4	; 0x04
     a08:	3d 81       	ldd	r19, Y+5	; 0x05
     a0a:	35 83       	std	Z+5, r19	; 0x05
     a0c:	24 83       	std	Z+4, r18	; 0x04

	/* Only used during decision coverage testing. */
	mtCOVERAGE_TEST_DELAY();

	pxIndex->pxPrevious->pxNext = pxNewListItem;
     a0e:	ac 81       	ldd	r26, Y+4	; 0x04
     a10:	bd 81       	ldd	r27, Y+5	; 0x05
     a12:	13 96       	adiw	r26, 0x03	; 3
     a14:	7c 93       	st	X, r23
     a16:	6e 93       	st	-X, r22
     a18:	12 97       	sbiw	r26, 0x02	; 2
	pxIndex->pxPrevious = pxNewListItem;
     a1a:	7d 83       	std	Y+5, r23	; 0x05
     a1c:	6c 83       	std	Y+4, r22	; 0x04

	/* Remember which list the item is in. */
	pxNewListItem->pxContainer = pxList;
     a1e:	91 87       	std	Z+9, r25	; 0x09
     a20:	80 87       	std	Z+8, r24	; 0x08

	( pxList->uxNumberOfItems )++;
     a22:	fc 01       	movw	r30, r24
     a24:	20 81       	ld	r18, Z
     a26:	2f 5f       	subi	r18, 0xFF	; 255
     a28:	20 83       	st	Z, r18
}
     a2a:	df 91       	pop	r29
     a2c:	cf 91       	pop	r28
     a2e:	08 95       	ret

00000a30 <vListInsert>:
/*-----------------------------------------------------------*/

void vListInsert( List_t * const pxList, ListItem_t * const pxNewListItem )
{
     a30:	cf 93       	push	r28
     a32:	df 93       	push	r29
     a34:	ac 01       	movw	r20, r24
     a36:	eb 01       	movw	r28, r22
ListItem_t *pxIterator;
const TickType_t xValueOfInsertion = pxNewListItem->xItemValue;
     a38:	28 81       	ld	r18, Y
     a3a:	39 81       	ldd	r19, Y+1	; 0x01
	new list item should be placed after it.  This ensures that TCBs which are
	stored in ready lists (all of which have the same xItemValue value) get a
	share of the CPU.  However, if the xItemValue is the same as the back marker
	the iteration loop below will not end.  Therefore the value is checked
	first, and the algorithm slightly modified if necessary. */
	if( xValueOfInsertion == portMAX_DELAY )
     a3c:	8f ef       	ldi	r24, 0xFF	; 255
     a3e:	2f 3f       	cpi	r18, 0xFF	; 255
     a40:	38 07       	cpc	r19, r24
     a42:	21 f4       	brne	.+8      	; 0xa4c <vListInsert+0x1c>
	{
		pxIterator = pxList->xListEnd.pxPrevious;
     a44:	fa 01       	movw	r30, r20
     a46:	a7 81       	ldd	r26, Z+7	; 0x07
     a48:	b0 85       	ldd	r27, Z+8	; 0x08
     a4a:	0d c0       	rjmp	.+26     	; 0xa66 <vListInsert+0x36>
			4) Using a queue or semaphore before it has been initialised or
			   before the scheduler has been started (are interrupts firing
			   before vTaskStartScheduler() has been called?).
		**********************************************************************/

		for( pxIterator = ( ListItem_t * ) &( pxList->xListEnd ); pxIterator->pxNext->xItemValue <= xValueOfInsertion; pxIterator = pxIterator->pxNext ) /*lint !e826 !e740 !e9087 The mini list structure is used as the list end to save RAM.  This is checked and valid. *//*lint !e440 The iterator moves to a different value, not xValueOfInsertion. */
     a4c:	da 01       	movw	r26, r20
     a4e:	13 96       	adiw	r26, 0x03	; 3
     a50:	01 c0       	rjmp	.+2      	; 0xa54 <vListInsert+0x24>
     a52:	df 01       	movw	r26, r30
     a54:	12 96       	adiw	r26, 0x02	; 2
     a56:	ed 91       	ld	r30, X+
     a58:	fc 91       	ld	r31, X
     a5a:	13 97       	sbiw	r26, 0x03	; 3
     a5c:	80 81       	ld	r24, Z
     a5e:	91 81       	ldd	r25, Z+1	; 0x01
     a60:	28 17       	cp	r18, r24
     a62:	39 07       	cpc	r19, r25
     a64:	b0 f7       	brcc	.-20     	; 0xa52 <vListInsert+0x22>
			/* There is nothing to do here, just iterating to the wanted
			insertion position. */
		}
	}

	pxNewListItem->pxNext = pxIterator->pxNext;
     a66:	12 96       	adiw	r26, 0x02	; 2
     a68:	ed 91       	ld	r30, X+
     a6a:	fc 91       	ld	r31, X
     a6c:	13 97       	sbiw	r26, 0x03	; 3
     a6e:	fb 83       	std	Y+3, r31	; 0x03
     a70:	ea 83       	std	Y+2, r30	; 0x02
	pxNewListItem->pxNext->pxPrevious = pxNewListItem;
     a72:	d5 83       	std	Z+5, r29	; 0x05
     a74:	c4 83       	std	Z+4, r28	; 0x04
	pxNewListItem->pxPrevious = pxIterator;
     a76:	bd 83       	std	Y+5, r27	; 0x05
     a78:	ac 83       	std	Y+4, r26	; 0x04
	pxIterator->pxNext = pxNewListItem;
     a7a:	13 96       	adiw	r26, 0x03	; 3
     a7c:	dc 93       	st	X, r29
     a7e:	ce 93       	st	-X, r28
     a80:	12 97       	sbiw	r26, 0x02	; 2

	/* Remember which list the item is in.  This allows fast removal of the
	item later. */
	pxNewListItem->pxContainer = pxList;
     a82:	59 87       	std	Y+9, r21	; 0x09
     a84:	48 87       	std	Y+8, r20	; 0x08

	( pxList->uxNumberOfItems )++;
     a86:	fa 01       	movw	r30, r20
     a88:	80 81       	ld	r24, Z
     a8a:	8f 5f       	subi	r24, 0xFF	; 255
     a8c:	80 83       	st	Z, r24
}
     a8e:	df 91       	pop	r29
     a90:	cf 91       	pop	r28
     a92:	08 95       	ret

00000a94 <uxListRemove>:
/*-----------------------------------------------------------*/

UBaseType_t uxListRemove( ListItem_t * const pxItemToRemove )
{
     a94:	cf 93       	push	r28
     a96:	df 93       	push	r29
     a98:	fc 01       	movw	r30, r24
/* The list item knows which list it is in.  Obtain the list from the list
item. */
List_t * const pxList = pxItemToRemove->pxContainer;
     a9a:	c0 85       	ldd	r28, Z+8	; 0x08
     a9c:	d1 85       	ldd	r29, Z+9	; 0x09

	pxItemToRemove->pxNext->pxPrevious = pxItemToRemove->pxPrevious;
     a9e:	a2 81       	ldd	r26, Z+2	; 0x02
     aa0:	b3 81       	ldd	r27, Z+3	; 0x03
     aa2:	84 81       	ldd	r24, Z+4	; 0x04
     aa4:	95 81       	ldd	r25, Z+5	; 0x05
     aa6:	15 96       	adiw	r26, 0x05	; 5
     aa8:	9c 93       	st	X, r25
     aaa:	8e 93       	st	-X, r24
     aac:	14 97       	sbiw	r26, 0x04	; 4
	pxItemToRemove->pxPrevious->pxNext = pxItemToRemove->pxNext;
     aae:	a4 81       	ldd	r26, Z+4	; 0x04
     ab0:	b5 81       	ldd	r27, Z+5	; 0x05
     ab2:	82 81       	ldd	r24, Z+2	; 0x02
     ab4:	93 81       	ldd	r25, Z+3	; 0x03
     ab6:	13 96       	adiw	r26, 0x03	; 3
     ab8:	9c 93       	st	X, r25
     aba:	8e 93       	st	-X, r24
     abc:	12 97       	sbiw	r26, 0x02	; 2

	/* Only used during decision coverage testing. */
	mtCOVERAGE_TEST_DELAY();

	/* Make sure the index is left pointing to a valid item. */
	if( pxList->pxIndex == pxItemToRemove )
     abe:	a9 81       	ldd	r26, Y+1	; 0x01
     ac0:	ba 81       	ldd	r27, Y+2	; 0x02
     ac2:	ae 17       	cp	r26, r30
     ac4:	bf 07       	cpc	r27, r31
     ac6:	31 f4       	brne	.+12     	; 0xad4 <uxListRemove+0x40>
	{
		pxList->pxIndex = pxItemToRemove->pxPrevious;
     ac8:	14 96       	adiw	r26, 0x04	; 4
     aca:	8d 91       	ld	r24, X+
     acc:	9c 91       	ld	r25, X
     ace:	15 97       	sbiw	r26, 0x05	; 5
     ad0:	9a 83       	std	Y+2, r25	; 0x02
     ad2:	89 83       	std	Y+1, r24	; 0x01
	else
	{
		mtCOVERAGE_TEST_MARKER();
	}

	pxItemToRemove->pxContainer = NULL;
     ad4:	11 86       	std	Z+9, r1	; 0x09
     ad6:	10 86       	std	Z+8, r1	; 0x08
	( pxList->uxNumberOfItems )--;
     ad8:	88 81       	ld	r24, Y
     ada:	81 50       	subi	r24, 0x01	; 1
     adc:	88 83       	st	Y, r24

	return pxList->uxNumberOfItems;
     ade:	88 81       	ld	r24, Y
}
     ae0:	df 91       	pop	r29
     ae2:	cf 91       	pop	r28
     ae4:	08 95       	ret

00000ae6 <pxPortInitialiseStack>:
uint16_t usAddress;

	/* Place a few bytes of known values on the bottom of the stack. 
	This is just useful for debugging. */

	*pxTopOfStack = 0x11;
     ae6:	21 e1       	ldi	r18, 0x11	; 17
     ae8:	fc 01       	movw	r30, r24
     aea:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = 0x22;
     aec:	31 97       	sbiw	r30, 0x01	; 1
     aee:	32 e2       	ldi	r19, 0x22	; 34
     af0:	30 83       	st	Z, r19
	pxTopOfStack--;
	*pxTopOfStack = 0x33;
     af2:	fc 01       	movw	r30, r24
     af4:	32 97       	sbiw	r30, 0x02	; 2
     af6:	a3 e3       	ldi	r26, 0x33	; 51
     af8:	a0 83       	st	Z, r26
	/*lint -e950 -e611 -e923 Lint doesn't like this much - but nothing I can do about it. */

	/* The start of the task code will be popped off the stack last, so place
	it on first. */
	usAddress = ( uint16_t ) pxCode;
	*pxTopOfStack = ( StackType_t ) ( usAddress & ( uint16_t ) 0x00ff );
     afa:	fc 01       	movw	r30, r24
     afc:	33 97       	sbiw	r30, 0x03	; 3
     afe:	60 83       	st	Z, r22
	pxTopOfStack--;

	usAddress >>= 8;
	*pxTopOfStack = ( StackType_t ) ( usAddress & ( uint16_t ) 0x00ff );
     b00:	fc 01       	movw	r30, r24
     b02:	34 97       	sbiw	r30, 0x04	; 4
     b04:	70 83       	st	Z, r23

	/* Next simulate the stack as if after a call to portSAVE_CONTEXT().  
	portSAVE_CONTEXT places the flags on the stack immediately after r0
	to ensure the interrupts get disabled as soon as possible, and so ensuring
	the stack use is minimal should a context switch interrupt occur. */
	*pxTopOfStack = ( StackType_t ) 0x00;	/* R0 */
     b06:	fc 01       	movw	r30, r24
     b08:	35 97       	sbiw	r30, 0x05	; 5
     b0a:	10 82       	st	Z, r1
	pxTopOfStack--;
	*pxTopOfStack = portFLAGS_INT_ENABLED;
     b0c:	fc 01       	movw	r30, r24
     b0e:	36 97       	sbiw	r30, 0x06	; 6
     b10:	60 e8       	ldi	r22, 0x80	; 128
     b12:	60 83       	st	Z, r22
	pxTopOfStack--;


	/* Now the remaining registers.   The compiler expects R1 to be 0. */
	*pxTopOfStack = ( StackType_t ) 0x00;	/* R1 */
     b14:	fc 01       	movw	r30, r24
     b16:	37 97       	sbiw	r30, 0x07	; 7
     b18:	10 82       	st	Z, r1
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x02;	/* R2 */
     b1a:	fc 01       	movw	r30, r24
     b1c:	38 97       	sbiw	r30, 0x08	; 8
     b1e:	62 e0       	ldi	r22, 0x02	; 2
     b20:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x03;	/* R3 */
     b22:	fc 01       	movw	r30, r24
     b24:	39 97       	sbiw	r30, 0x09	; 9
     b26:	63 e0       	ldi	r22, 0x03	; 3
     b28:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x04;	/* R4 */
     b2a:	fc 01       	movw	r30, r24
     b2c:	3a 97       	sbiw	r30, 0x0a	; 10
     b2e:	64 e0       	ldi	r22, 0x04	; 4
     b30:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x05;	/* R5 */
     b32:	fc 01       	movw	r30, r24
     b34:	3b 97       	sbiw	r30, 0x0b	; 11
     b36:	65 e0       	ldi	r22, 0x05	; 5
     b38:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x06;	/* R6 */
     b3a:	fc 01       	movw	r30, r24
     b3c:	3c 97       	sbiw	r30, 0x0c	; 12
     b3e:	66 e0       	ldi	r22, 0x06	; 6
     b40:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x07;	/* R7 */
     b42:	fc 01       	movw	r30, r24
     b44:	3d 97       	sbiw	r30, 0x0d	; 13
     b46:	67 e0       	ldi	r22, 0x07	; 7
     b48:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x08;	/* R8 */
     b4a:	fc 01       	movw	r30, r24
     b4c:	3e 97       	sbiw	r30, 0x0e	; 14
     b4e:	68 e0       	ldi	r22, 0x08	; 8
     b50:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x09;	/* R9 */
     b52:	fc 01       	movw	r30, r24
     b54:	3f 97       	sbiw	r30, 0x0f	; 15
     b56:	69 e0       	ldi	r22, 0x09	; 9
     b58:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x10;	/* R10 */
     b5a:	fc 01       	movw	r30, r24
     b5c:	70 97       	sbiw	r30, 0x10	; 16
     b5e:	60 e1       	ldi	r22, 0x10	; 16
     b60:	60 83       	st	Z, r22
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x11;	/* R11 */
     b62:	fc 01       	movw	r30, r24
     b64:	71 97       	sbiw	r30, 0x11	; 17
     b66:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x12;	/* R12 */
     b68:	fc 01       	movw	r30, r24
     b6a:	72 97       	sbiw	r30, 0x12	; 18
     b6c:	22 e1       	ldi	r18, 0x12	; 18
     b6e:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x13;	/* R13 */
     b70:	fc 01       	movw	r30, r24
     b72:	73 97       	sbiw	r30, 0x13	; 19
     b74:	23 e1       	ldi	r18, 0x13	; 19
     b76:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x14;	/* R14 */
     b78:	fc 01       	movw	r30, r24
     b7a:	74 97       	sbiw	r30, 0x14	; 20
     b7c:	24 e1       	ldi	r18, 0x14	; 20
     b7e:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x15;	/* R15 */
     b80:	fc 01       	movw	r30, r24
     b82:	75 97       	sbiw	r30, 0x15	; 21
     b84:	25 e1       	ldi	r18, 0x15	; 21
     b86:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x16;	/* R16 */
     b88:	fc 01       	movw	r30, r24
     b8a:	76 97       	sbiw	r30, 0x16	; 22
     b8c:	26 e1       	ldi	r18, 0x16	; 22
     b8e:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x17;	/* R17 */
     b90:	fc 01       	movw	r30, r24
     b92:	77 97       	sbiw	r30, 0x17	; 23
     b94:	27 e1       	ldi	r18, 0x17	; 23
     b96:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x18;	/* R18 */
     b98:	fc 01       	movw	r30, r24
     b9a:	78 97       	sbiw	r30, 0x18	; 24
     b9c:	28 e1       	ldi	r18, 0x18	; 24
     b9e:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x19;	/* R19 */
     ba0:	fc 01       	movw	r30, r24
     ba2:	79 97       	sbiw	r30, 0x19	; 25
     ba4:	29 e1       	ldi	r18, 0x19	; 25
     ba6:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x20;	/* R20 */
     ba8:	fc 01       	movw	r30, r24
     baa:	7a 97       	sbiw	r30, 0x1a	; 26
     bac:	20 e2       	ldi	r18, 0x20	; 32
     bae:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x21;	/* R21 */
     bb0:	fc 01       	movw	r30, r24
     bb2:	7b 97       	sbiw	r30, 0x1b	; 27
     bb4:	21 e2       	ldi	r18, 0x21	; 33
     bb6:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x22;	/* R22 */
     bb8:	fc 01       	movw	r30, r24
     bba:	7c 97       	sbiw	r30, 0x1c	; 28
     bbc:	30 83       	st	Z, r19
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x23;	/* R23 */
     bbe:	fc 01       	movw	r30, r24
     bc0:	7d 97       	sbiw	r30, 0x1d	; 29
     bc2:	23 e2       	ldi	r18, 0x23	; 35
     bc4:	20 83       	st	Z, r18
	pxTopOfStack--;

	/* Place the parameter on the stack in the expected location. */
	usAddress = ( uint16_t ) pvParameters;
	*pxTopOfStack = ( StackType_t ) ( usAddress & ( uint16_t ) 0x00ff );
     bc6:	fc 01       	movw	r30, r24
     bc8:	7e 97       	sbiw	r30, 0x1e	; 30
     bca:	40 83       	st	Z, r20
	pxTopOfStack--;

	usAddress >>= 8;
	*pxTopOfStack = ( StackType_t ) ( usAddress & ( uint16_t ) 0x00ff );
     bcc:	fc 01       	movw	r30, r24
     bce:	7f 97       	sbiw	r30, 0x1f	; 31
     bd0:	50 83       	st	Z, r21
	pxTopOfStack--;

	*pxTopOfStack = ( StackType_t ) 0x26;	/* R26 X */
     bd2:	fc 01       	movw	r30, r24
     bd4:	b0 97       	sbiw	r30, 0x20	; 32
     bd6:	26 e2       	ldi	r18, 0x26	; 38
     bd8:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x27;	/* R27 */
     bda:	fc 01       	movw	r30, r24
     bdc:	b1 97       	sbiw	r30, 0x21	; 33
     bde:	27 e2       	ldi	r18, 0x27	; 39
     be0:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x28;	/* R28 Y */
     be2:	fc 01       	movw	r30, r24
     be4:	b2 97       	sbiw	r30, 0x22	; 34
     be6:	28 e2       	ldi	r18, 0x28	; 40
     be8:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x29;	/* R29 */
     bea:	fc 01       	movw	r30, r24
     bec:	b3 97       	sbiw	r30, 0x23	; 35
     bee:	29 e2       	ldi	r18, 0x29	; 41
     bf0:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x30;	/* R30 Z */
     bf2:	fc 01       	movw	r30, r24
     bf4:	b4 97       	sbiw	r30, 0x24	; 36
     bf6:	20 e3       	ldi	r18, 0x30	; 48
     bf8:	20 83       	st	Z, r18
	pxTopOfStack--;
	*pxTopOfStack = ( StackType_t ) 0x031;	/* R31 */
     bfa:	fc 01       	movw	r30, r24
     bfc:	b5 97       	sbiw	r30, 0x25	; 37
     bfe:	21 e3       	ldi	r18, 0x31	; 49
     c00:	20 83       	st	Z, r18
	pxTopOfStack--;

	/*lint +e950 +e611 +e923 */

	return pxTopOfStack;
     c02:	86 97       	sbiw	r24, 0x26	; 38
}
     c04:	08 95       	ret

00000c06 <xPortStartScheduler>:
	/* Setup compare match value for compare match A.  Interrupts are disabled 
	before this is called so we need not worry here. */
	ucLowByte = ( uint8_t ) ( ulCompareMatch & ( uint32_t ) 0xff );
	ulCompareMatch >>= 8;
	ucHighByte = ( uint8_t ) ( ulCompareMatch & ( uint32_t ) 0xff );
	OCR1AH = ucHighByte;
     c06:	1b bc       	out	0x2b, r1	; 43
	OCR1AL = ucLowByte;
     c08:	89 ef       	ldi	r24, 0xF9	; 249
     c0a:	8a bd       	out	0x2a, r24	; 42

	/* Setup clock source and compare match behaviour. */
	ucLowByte = portCLEAR_COUNTER_ON_MATCH | portPRESCALE_64;
	TCCR1B = ucLowByte;
     c0c:	8b e0       	ldi	r24, 0x0B	; 11
     c0e:	8e bd       	out	0x2e, r24	; 46

	/* Enable the interrupt - this is okay as interrupt are currently globally
	disabled. */
	ucLowByte = TIMSK;
     c10:	89 b7       	in	r24, 0x39	; 57
	ucLowByte |= portCOMPARE_MATCH_A_INTERRUPT_ENABLE;
     c12:	80 61       	ori	r24, 0x10	; 16
	TIMSK = ucLowByte;
     c14:	89 bf       	out	0x39, r24	; 57
{
	/* Setup the hardware to generate the tick. */
	prvSetupTimerInterrupt();

	/* Restore the context of the first task that is going to run. */
	portRESTORE_CONTEXT();
     c16:	a0 91 8b 06 	lds	r26, 0x068B
     c1a:	b0 91 8c 06 	lds	r27, 0x068C
     c1e:	cd 91       	ld	r28, X+
     c20:	cd bf       	out	0x3d, r28	; 61
     c22:	dd 91       	ld	r29, X+
     c24:	de bf       	out	0x3e, r29	; 62
     c26:	ff 91       	pop	r31
     c28:	ef 91       	pop	r30
     c2a:	df 91       	pop	r29
     c2c:	cf 91       	pop	r28
     c2e:	bf 91       	pop	r27
     c30:	af 91       	pop	r26
     c32:	9f 91       	pop	r25
     c34:	8f 91       	pop	r24
     c36:	7f 91       	pop	r23
     c38:	6f 91       	pop	r22
     c3a:	5f 91       	pop	r21
     c3c:	4f 91       	pop	r20
     c3e:	3f 91       	pop	r19
     c40:	2f 91       	pop	r18
     c42:	1f 91       	pop	r17
     c44:	0f 91       	pop	r16
     c46:	ff 90       	pop	r15
     c48:	ef 90       	pop	r14
     c4a:	df 90       	pop	r13
     c4c:	cf 90       	pop	r12
     c4e:	bf 90       	pop	r11
     c50:	af 90       	pop	r10
     c52:	9f 90       	pop	r9
     c54:	8f 90       	pop	r8
     c56:	7f 90       	pop	r7
     c58:	6f 90       	pop	r6
     c5a:	5f 90       	pop	r5
     c5c:	4f 90       	pop	r4
     c5e:	3f 90       	pop	r3
     c60:	2f 90       	pop	r2
     c62:	1f 90       	pop	r1
     c64:	0f 90       	pop	r0
     c66:	0f be       	out	0x3f, r0	; 63
     c68:	0f 90       	pop	r0

	/* Simulate a function call end as generated by the compiler.  We will now
	jump to the start of the task the context of which we have just restored. */
	asm volatile ( "ret" );
     c6a:	08 95       	ret

	/* Should not get here. */
	return pdTRUE;
}
     c6c:	81 e0       	ldi	r24, 0x01	; 1
     c6e:	08 95       	ret

00000c70 <vPortEndScheduler>:

void vPortEndScheduler( void )
{
	/* It is unlikely that the AVR port will get stopped.  If required simply
	disable the tick interrupt here. */
}
     c70:	08 95       	ret

00000c72 <vPortYield>:
 * can use a naked attribute.
 */
void vPortYield( void ) __attribute__ ( ( naked ) );
void vPortYield( void )
{
	portSAVE_CONTEXT();
     c72:	0f 92       	push	r0
     c74:	0f b6       	in	r0, 0x3f	; 63
     c76:	f8 94       	cli
     c78:	0f 92       	push	r0
     c7a:	1f 92       	push	r1
     c7c:	11 24       	eor	r1, r1
     c7e:	2f 92       	push	r2
     c80:	3f 92       	push	r3
     c82:	4f 92       	push	r4
     c84:	5f 92       	push	r5
     c86:	6f 92       	push	r6
     c88:	7f 92       	push	r7
     c8a:	8f 92       	push	r8
     c8c:	9f 92       	push	r9
     c8e:	af 92       	push	r10
     c90:	bf 92       	push	r11
     c92:	cf 92       	push	r12
     c94:	df 92       	push	r13
     c96:	ef 92       	push	r14
     c98:	ff 92       	push	r15
     c9a:	0f 93       	push	r16
     c9c:	1f 93       	push	r17
     c9e:	2f 93       	push	r18
     ca0:	3f 93       	push	r19
     ca2:	4f 93       	push	r20
     ca4:	5f 93       	push	r21
     ca6:	6f 93       	push	r22
     ca8:	7f 93       	push	r23
     caa:	8f 93       	push	r24
     cac:	9f 93       	push	r25
     cae:	af 93       	push	r26
     cb0:	bf 93       	push	r27
     cb2:	cf 93       	push	r28
     cb4:	df 93       	push	r29
     cb6:	ef 93       	push	r30
     cb8:	ff 93       	push	r31
     cba:	a0 91 8b 06 	lds	r26, 0x068B
     cbe:	b0 91 8c 06 	lds	r27, 0x068C
     cc2:	0d b6       	in	r0, 0x3d	; 61
     cc4:	0d 92       	st	X+, r0
     cc6:	0e b6       	in	r0, 0x3e	; 62
     cc8:	0d 92       	st	X+, r0
	vTaskSwitchContext();
     cca:	0e 94 6f 10 	call	0x20de	; 0x20de <vTaskSwitchContext>
	portRESTORE_CONTEXT();
     cce:	a0 91 8b 06 	lds	r26, 0x068B
     cd2:	b0 91 8c 06 	lds	r27, 0x068C
     cd6:	cd 91       	ld	r28, X+
     cd8:	cd bf       	out	0x3d, r28	; 61
     cda:	dd 91       	ld	r29, X+
     cdc:	de bf       	out	0x3e, r29	; 62
     cde:	ff 91       	pop	r31
     ce0:	ef 91       	pop	r30
     ce2:	df 91       	pop	r29
     ce4:	cf 91       	pop	r28
     ce6:	bf 91       	pop	r27
     ce8:	af 91       	pop	r26
     cea:	9f 91       	pop	r25
     cec:	8f 91       	pop	r24
     cee:	7f 91       	pop	r23
     cf0:	6f 91       	pop	r22
     cf2:	5f 91       	pop	r21
     cf4:	4f 91       	pop	r20
     cf6:	3f 91       	pop	r19
     cf8:	2f 91       	pop	r18
     cfa:	1f 91       	pop	r17
     cfc:	0f 91       	pop	r16
     cfe:	ff 90       	pop	r15
     d00:	ef 90       	pop	r14
     d02:	df 90       	pop	r13
     d04:	cf 90       	pop	r12
     d06:	bf 90       	pop	r11
     d08:	af 90       	pop	r10
     d0a:	9f 90       	pop	r9
     d0c:	8f 90       	pop	r8
     d0e:	7f 90       	pop	r7
     d10:	6f 90       	pop	r6
     d12:	5f 90       	pop	r5
     d14:	4f 90       	pop	r4
     d16:	3f 90       	pop	r3
     d18:	2f 90       	pop	r2
     d1a:	1f 90       	pop	r1
     d1c:	0f 90       	pop	r0
     d1e:	0f be       	out	0x3f, r0	; 63
     d20:	0f 90       	pop	r0

	asm volatile ( "ret" );
     d22:	08 95       	ret

00000d24 <vPortYieldFromTick>:
 * call comes from the tick ISR.
 */
void vPortYieldFromTick( void ) __attribute__ ( ( naked ) );
void vPortYieldFromTick( void )
{
	portSAVE_CONTEXT();
     d24:	0f 92       	push	r0
     d26:	0f b6       	in	r0, 0x3f	; 63
     d28:	f8 94       	cli
     d2a:	0f 92       	push	r0
     d2c:	1f 92       	push	r1
     d2e:	11 24       	eor	r1, r1
     d30:	2f 92       	push	r2
     d32:	3f 92       	push	r3
     d34:	4f 92       	push	r4
     d36:	5f 92       	push	r5
     d38:	6f 92       	push	r6
     d3a:	7f 92       	push	r7
     d3c:	8f 92       	push	r8
     d3e:	9f 92       	push	r9
     d40:	af 92       	push	r10
     d42:	bf 92       	push	r11
     d44:	cf 92       	push	r12
     d46:	df 92       	push	r13
     d48:	ef 92       	push	r14
     d4a:	ff 92       	push	r15
     d4c:	0f 93       	push	r16
     d4e:	1f 93       	push	r17
     d50:	2f 93       	push	r18
     d52:	3f 93       	push	r19
     d54:	4f 93       	push	r20
     d56:	5f 93       	push	r21
     d58:	6f 93       	push	r22
     d5a:	7f 93       	push	r23
     d5c:	8f 93       	push	r24
     d5e:	9f 93       	push	r25
     d60:	af 93       	push	r26
     d62:	bf 93       	push	r27
     d64:	cf 93       	push	r28
     d66:	df 93       	push	r29
     d68:	ef 93       	push	r30
     d6a:	ff 93       	push	r31
     d6c:	a0 91 8b 06 	lds	r26, 0x068B
     d70:	b0 91 8c 06 	lds	r27, 0x068C
     d74:	0d b6       	in	r0, 0x3d	; 61
     d76:	0d 92       	st	X+, r0
     d78:	0e b6       	in	r0, 0x3e	; 62
     d7a:	0d 92       	st	X+, r0
	if( xTaskIncrementTick() != pdFALSE )
     d7c:	0e 94 de 0e 	call	0x1dbc	; 0x1dbc <xTaskIncrementTick>
     d80:	88 23       	and	r24, r24
     d82:	11 f0       	breq	.+4      	; 0xd88 <vPortYieldFromTick+0x64>
	{
		vTaskSwitchContext();
     d84:	0e 94 6f 10 	call	0x20de	; 0x20de <vTaskSwitchContext>
	}
	portRESTORE_CONTEXT();
     d88:	a0 91 8b 06 	lds	r26, 0x068B
     d8c:	b0 91 8c 06 	lds	r27, 0x068C
     d90:	cd 91       	ld	r28, X+
     d92:	cd bf       	out	0x3d, r28	; 61
     d94:	dd 91       	ld	r29, X+
     d96:	de bf       	out	0x3e, r29	; 62
     d98:	ff 91       	pop	r31
     d9a:	ef 91       	pop	r30
     d9c:	df 91       	pop	r29
     d9e:	cf 91       	pop	r28
     da0:	bf 91       	pop	r27
     da2:	af 91       	pop	r26
     da4:	9f 91       	pop	r25
     da6:	8f 91       	pop	r24
     da8:	7f 91       	pop	r23
     daa:	6f 91       	pop	r22
     dac:	5f 91       	pop	r21
     dae:	4f 91       	pop	r20
     db0:	3f 91       	pop	r19
     db2:	2f 91       	pop	r18
     db4:	1f 91       	pop	r17
     db6:	0f 91       	pop	r16
     db8:	ff 90       	pop	r15
     dba:	ef 90       	pop	r14
     dbc:	df 90       	pop	r13
     dbe:	cf 90       	pop	r12
     dc0:	bf 90       	pop	r11
     dc2:	af 90       	pop	r10
     dc4:	9f 90       	pop	r9
     dc6:	8f 90       	pop	r8
     dc8:	7f 90       	pop	r7
     dca:	6f 90       	pop	r6
     dcc:	5f 90       	pop	r5
     dce:	4f 90       	pop	r4
     dd0:	3f 90       	pop	r3
     dd2:	2f 90       	pop	r2
     dd4:	1f 90       	pop	r1
     dd6:	0f 90       	pop	r0
     dd8:	0f be       	out	0x3f, r0	; 63
     dda:	0f 90       	pop	r0

	asm volatile ( "ret" );
     ddc:	08 95       	ret

00000dde <__vector_11>:
	 * count is incremented after the context is saved.
	 */
	void TIMER0_OVF_vect( void ) __attribute__ ( ( signal, naked ) );
	void TIMER0_OVF_vect( void )
	{
		vPortYieldFromTick();
     dde:	0e 94 92 06 	call	0xd24	; 0xd24 <vPortYieldFromTick>
		asm volatile ( "reti" );
     de2:	18 95       	reti

00000de4 <prvIsQueueEmpty>:

static BaseType_t prvIsQueueEmpty( const Queue_t *pxQueue )
{
BaseType_t xReturn;

	taskENTER_CRITICAL();
     de4:	0f b6       	in	r0, 0x3f	; 63
     de6:	f8 94       	cli
     de8:	0f 92       	push	r0
	{
		if( pxQueue->uxMessagesWaiting == ( UBaseType_t )  0 )
     dea:	fc 01       	movw	r30, r24
     dec:	92 8d       	ldd	r25, Z+26	; 0x1a
		else
		{
			xReturn = pdFALSE;
		}
	}
	taskEXIT_CRITICAL();
     dee:	0f 90       	pop	r0
     df0:	0f be       	out	0x3f, r0	; 63

	taskENTER_CRITICAL();
	{
		if( pxQueue->uxMessagesWaiting == ( UBaseType_t )  0 )
		{
			xReturn = pdTRUE;
     df2:	81 e0       	ldi	r24, 0x01	; 1
     df4:	91 11       	cpse	r25, r1
     df6:	80 e0       	ldi	r24, 0x00	; 0
		}
	}
	taskEXIT_CRITICAL();

	return xReturn;
}
     df8:	08 95       	ret

00000dfa <prvIsQueueFull>:
	return xReturn;
} /*lint !e818 xQueue could not be pointer to const because it is a typedef. */
/*-----------------------------------------------------------*/

static BaseType_t prvIsQueueFull( const Queue_t *pxQueue )
{
     dfa:	fc 01       	movw	r30, r24
BaseType_t xReturn;

	taskENTER_CRITICAL();
     dfc:	0f b6       	in	r0, 0x3f	; 63
     dfe:	f8 94       	cli
     e00:	0f 92       	push	r0
	{
		if( pxQueue->uxMessagesWaiting == pxQueue->uxLength )
     e02:	22 8d       	ldd	r18, Z+26	; 0x1a
		else
		{
			xReturn = pdFALSE;
		}
	}
	taskEXIT_CRITICAL();
     e04:	0f 90       	pop	r0
     e06:	0f be       	out	0x3f, r0	; 63

	taskENTER_CRITICAL();
	{
		if( pxQueue->uxMessagesWaiting == pxQueue->uxLength )
		{
			xReturn = pdTRUE;
     e08:	81 e0       	ldi	r24, 0x01	; 1
     e0a:	93 8d       	ldd	r25, Z+27	; 0x1b
     e0c:	29 13       	cpse	r18, r25
     e0e:	80 e0       	ldi	r24, 0x00	; 0
		}
	}
	taskEXIT_CRITICAL();

	return xReturn;
}
     e10:	08 95       	ret

00000e12 <prvCopyDataToQueue>:

#endif /* configUSE_MUTEXES */
/*-----------------------------------------------------------*/

static BaseType_t prvCopyDataToQueue( Queue_t * const pxQueue, const void *pvItemToQueue, const BaseType_t xPosition )
{
     e12:	0f 93       	push	r16
     e14:	1f 93       	push	r17
     e16:	cf 93       	push	r28
     e18:	df 93       	push	r29
     e1a:	ec 01       	movw	r28, r24
     e1c:	14 2f       	mov	r17, r20
BaseType_t xReturn = pdFALSE;
UBaseType_t uxMessagesWaiting;

	/* This function is called from a critical section. */

	uxMessagesWaiting = pxQueue->uxMessagesWaiting;
     e1e:	0a 8d       	ldd	r16, Y+26	; 0x1a

	if( pxQueue->uxItemSize == ( UBaseType_t ) 0 )
     e20:	4c 8d       	ldd	r20, Y+28	; 0x1c
     e22:	44 23       	and	r20, r20
     e24:	b9 f1       	breq	.+110    	; 0xe94 <prvCopyDataToQueue+0x82>
				mtCOVERAGE_TEST_MARKER();
			}
		}
		#endif /* configUSE_MUTEXES */
	}
	else if( xPosition == queueSEND_TO_BACK )
     e26:	11 23       	and	r17, r17
     e28:	b1 f4       	brne	.+44     	; 0xe56 <prvCopyDataToQueue+0x44>
	{
		( void ) memcpy( ( void * ) pxQueue->pcWriteTo, pvItemToQueue, ( size_t ) pxQueue->uxItemSize ); /*lint !e961 !e418 !e9087 MISRA exception as the casts are only redundant for some ports, plus previous logic ensures a null pointer can only be passed to memcpy() if the copy size is 0.  Cast to void required by function signature and safe as no alignment requirement and copy length specified in bytes. */
     e2a:	8a 81       	ldd	r24, Y+2	; 0x02
     e2c:	9b 81       	ldd	r25, Y+3	; 0x03
     e2e:	50 e0       	ldi	r21, 0x00	; 0
     e30:	0e 94 30 14 	call	0x2860	; 0x2860 <memcpy>
		pxQueue->pcWriteTo += pxQueue->uxItemSize; /*lint !e9016 Pointer arithmetic on char types ok, especially in this use case where it is the clearest way of conveying intent. */
     e34:	2c 8d       	ldd	r18, Y+28	; 0x1c
     e36:	8a 81       	ldd	r24, Y+2	; 0x02
     e38:	9b 81       	ldd	r25, Y+3	; 0x03
     e3a:	82 0f       	add	r24, r18
     e3c:	91 1d       	adc	r25, r1
     e3e:	9b 83       	std	Y+3, r25	; 0x03
     e40:	8a 83       	std	Y+2, r24	; 0x02
		if( pxQueue->pcWriteTo >= pxQueue->u.xQueue.pcTail ) /*lint !e946 MISRA exception justified as comparison of pointers is the cleanest solution. */
     e42:	2c 81       	ldd	r18, Y+4	; 0x04
     e44:	3d 81       	ldd	r19, Y+5	; 0x05
     e46:	82 17       	cp	r24, r18
     e48:	93 07       	cpc	r25, r19
     e4a:	20 f1       	brcs	.+72     	; 0xe94 <prvCopyDataToQueue+0x82>
		{
			pxQueue->pcWriteTo = pxQueue->pcHead;
     e4c:	88 81       	ld	r24, Y
     e4e:	99 81       	ldd	r25, Y+1	; 0x01
     e50:	9b 83       	std	Y+3, r25	; 0x03
     e52:	8a 83       	std	Y+2, r24	; 0x02
     e54:	1f c0       	rjmp	.+62     	; 0xe94 <prvCopyDataToQueue+0x82>
			mtCOVERAGE_TEST_MARKER();
		}
	}
	else
	{
		( void ) memcpy( ( void * ) pxQueue->u.xQueue.pcReadFrom, pvItemToQueue, ( size_t ) pxQueue->uxItemSize ); /*lint !e961 !e9087 !e418 MISRA exception as the casts are only redundant for some ports.  Cast to void required by function signature and safe as no alignment requirement and copy length specified in bytes.  Assert checks null pointer only used when length is 0. */
     e56:	8e 81       	ldd	r24, Y+6	; 0x06
     e58:	9f 81       	ldd	r25, Y+7	; 0x07
     e5a:	50 e0       	ldi	r21, 0x00	; 0
     e5c:	0e 94 30 14 	call	0x2860	; 0x2860 <memcpy>
		pxQueue->u.xQueue.pcReadFrom -= pxQueue->uxItemSize;
     e60:	4c 8d       	ldd	r20, Y+28	; 0x1c
     e62:	50 e0       	ldi	r21, 0x00	; 0
     e64:	50 95       	com	r21
     e66:	41 95       	neg	r20
     e68:	5f 4f       	sbci	r21, 0xFF	; 255
     e6a:	8e 81       	ldd	r24, Y+6	; 0x06
     e6c:	9f 81       	ldd	r25, Y+7	; 0x07
     e6e:	84 0f       	add	r24, r20
     e70:	95 1f       	adc	r25, r21
     e72:	9f 83       	std	Y+7, r25	; 0x07
     e74:	8e 83       	std	Y+6, r24	; 0x06
		if( pxQueue->u.xQueue.pcReadFrom < pxQueue->pcHead ) /*lint !e946 MISRA exception justified as comparison of pointers is the cleanest solution. */
     e76:	28 81       	ld	r18, Y
     e78:	39 81       	ldd	r19, Y+1	; 0x01
     e7a:	82 17       	cp	r24, r18
     e7c:	93 07       	cpc	r25, r19
     e7e:	30 f4       	brcc	.+12     	; 0xe8c <prvCopyDataToQueue+0x7a>
		{
			pxQueue->u.xQueue.pcReadFrom = ( pxQueue->u.xQueue.pcTail - pxQueue->uxItemSize );
     e80:	8c 81       	ldd	r24, Y+4	; 0x04
     e82:	9d 81       	ldd	r25, Y+5	; 0x05
     e84:	84 0f       	add	r24, r20
     e86:	95 1f       	adc	r25, r21
     e88:	9f 83       	std	Y+7, r25	; 0x07
     e8a:	8e 83       	std	Y+6, r24	; 0x06
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}

		if( xPosition == queueOVERWRITE )
     e8c:	12 30       	cpi	r17, 0x02	; 2
     e8e:	11 f4       	brne	.+4      	; 0xe94 <prvCopyDataToQueue+0x82>
		{
			if( uxMessagesWaiting > ( UBaseType_t ) 0 )
     e90:	01 11       	cpse	r16, r1
			{
				/* An item is not being added but overwritten, so subtract
				one from the recorded number of items in the queue so when
				one is added again below the number of recorded items remains
				correct. */
				--uxMessagesWaiting;
     e92:	01 50       	subi	r16, 0x01	; 1
		{
			mtCOVERAGE_TEST_MARKER();
		}
	}

	pxQueue->uxMessagesWaiting = uxMessagesWaiting + ( UBaseType_t ) 1;
     e94:	0f 5f       	subi	r16, 0xFF	; 255
     e96:	0a 8f       	std	Y+26, r16	; 0x1a

	return xReturn;
}
     e98:	80 e0       	ldi	r24, 0x00	; 0
     e9a:	df 91       	pop	r29
     e9c:	cf 91       	pop	r28
     e9e:	1f 91       	pop	r17
     ea0:	0f 91       	pop	r16
     ea2:	08 95       	ret

00000ea4 <prvCopyDataFromQueue>:
/*-----------------------------------------------------------*/

static void prvCopyDataFromQueue( Queue_t * const pxQueue, void * const pvBuffer )
{
     ea4:	fc 01       	movw	r30, r24
	if( pxQueue->uxItemSize != ( UBaseType_t ) 0 )
     ea6:	44 8d       	ldd	r20, Z+28	; 0x1c
     ea8:	44 23       	and	r20, r20
     eaa:	c1 f0       	breq	.+48     	; 0xedc <prvCopyDataFromQueue+0x38>
	{
		pxQueue->u.xQueue.pcReadFrom += pxQueue->uxItemSize; /*lint !e9016 Pointer arithmetic on char types ok, especially in this use case where it is the clearest way of conveying intent. */
     eac:	26 81       	ldd	r18, Z+6	; 0x06
     eae:	37 81       	ldd	r19, Z+7	; 0x07
     eb0:	24 0f       	add	r18, r20
     eb2:	31 1d       	adc	r19, r1
     eb4:	37 83       	std	Z+7, r19	; 0x07
     eb6:	26 83       	std	Z+6, r18	; 0x06
		if( pxQueue->u.xQueue.pcReadFrom >= pxQueue->u.xQueue.pcTail ) /*lint !e946 MISRA exception justified as use of the relational operator is the cleanest solutions. */
     eb8:	a4 81       	ldd	r26, Z+4	; 0x04
     eba:	b5 81       	ldd	r27, Z+5	; 0x05
     ebc:	2a 17       	cp	r18, r26
     ebe:	3b 07       	cpc	r19, r27
     ec0:	20 f0       	brcs	.+8      	; 0xeca <prvCopyDataFromQueue+0x26>
		{
			pxQueue->u.xQueue.pcReadFrom = pxQueue->pcHead;
     ec2:	20 81       	ld	r18, Z
     ec4:	31 81       	ldd	r19, Z+1	; 0x01
     ec6:	37 83       	std	Z+7, r19	; 0x07
     ec8:	26 83       	std	Z+6, r18	; 0x06
		}
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}
		( void ) memcpy( ( void * ) pvBuffer, ( void * ) pxQueue->u.xQueue.pcReadFrom, ( size_t ) pxQueue->uxItemSize ); /*lint !e961 !e418 !e9087 MISRA exception as the casts are only redundant for some ports.  Also previous logic ensures a null pointer can only be passed to memcpy() when the count is 0.  Cast to void required by function signature and safe as no alignment requirement and copy length specified in bytes. */
     eca:	36 81       	ldd	r19, Z+6	; 0x06
     ecc:	27 81       	ldd	r18, Z+7	; 0x07
     ece:	86 2f       	mov	r24, r22
     ed0:	97 2f       	mov	r25, r23
     ed2:	63 2f       	mov	r22, r19
     ed4:	72 2f       	mov	r23, r18
     ed6:	50 e0       	ldi	r21, 0x00	; 0
     ed8:	0e 94 30 14 	call	0x2860	; 0x2860 <memcpy>
     edc:	08 95       	ret

00000ede <prvUnlockQueue>:
	}
}
/*-----------------------------------------------------------*/

static void prvUnlockQueue( Queue_t * const pxQueue )
{
     ede:	ef 92       	push	r14
     ee0:	ff 92       	push	r15
     ee2:	0f 93       	push	r16
     ee4:	1f 93       	push	r17
     ee6:	cf 93       	push	r28
     ee8:	8c 01       	movw	r16, r24

	/* The lock counts contains the number of extra data items placed or
	removed from the queue while the queue was locked.  When a queue is
	locked items can be added or removed, but the event lists cannot be
	updated. */
	taskENTER_CRITICAL();
     eea:	0f b6       	in	r0, 0x3f	; 63
     eec:	f8 94       	cli
     eee:	0f 92       	push	r0
	{
		int8_t cTxLock = pxQueue->cTxLock;
     ef0:	fc 01       	movw	r30, r24
     ef2:	c6 8d       	ldd	r28, Z+30	; 0x1e

		/* See if data was added to the queue while it was locked. */
		while( cTxLock > queueLOCKED_UNMODIFIED )
     ef4:	1c 16       	cp	r1, r28
     ef6:	cc f4       	brge	.+50     	; 0xf2a <prvUnlockQueue+0x4c>
			}
			#else /* configUSE_QUEUE_SETS */
			{
				/* Tasks that are removed from the event list will get added to
				the pending ready list as the scheduler is still suspended. */
				if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
     ef8:	81 89       	ldd	r24, Z+17	; 0x11
     efa:	88 23       	and	r24, r24
     efc:	31 f4       	brne	.+12     	; 0xf0a <prvUnlockQueue+0x2c>
     efe:	15 c0       	rjmp	.+42     	; 0xf2a <prvUnlockQueue+0x4c>
     f00:	f8 01       	movw	r30, r16
     f02:	81 89       	ldd	r24, Z+17	; 0x11
     f04:	88 23       	and	r24, r24
     f06:	41 f4       	brne	.+16     	; 0xf18 <prvUnlockQueue+0x3a>
     f08:	10 c0       	rjmp	.+32     	; 0xf2a <prvUnlockQueue+0x4c>
				{
					if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
     f0a:	0f 2e       	mov	r0, r31
     f0c:	f1 e1       	ldi	r31, 0x11	; 17
     f0e:	ef 2e       	mov	r14, r31
     f10:	ff 24       	eor	r15, r15
     f12:	f0 2d       	mov	r31, r0
     f14:	e0 0e       	add	r14, r16
     f16:	f1 1e       	adc	r15, r17
     f18:	c7 01       	movw	r24, r14
     f1a:	0e 94 f6 10 	call	0x21ec	; 0x21ec <xTaskRemoveFromEventList>
     f1e:	88 23       	and	r24, r24
     f20:	11 f0       	breq	.+4      	; 0xf26 <prvUnlockQueue+0x48>
					{
						/* The task waiting has a higher priority so record that
						a context switch is required. */
						vTaskMissedYield();
     f22:	0e 94 c1 11 	call	0x2382	; 0x2382 <vTaskMissedYield>
					break;
				}
			}
			#endif /* configUSE_QUEUE_SETS */

			--cTxLock;
     f26:	c1 50       	subi	r28, 0x01	; 1
	taskENTER_CRITICAL();
	{
		int8_t cTxLock = pxQueue->cTxLock;

		/* See if data was added to the queue while it was locked. */
		while( cTxLock > queueLOCKED_UNMODIFIED )
     f28:	59 f7       	brne	.-42     	; 0xf00 <prvUnlockQueue+0x22>
			#endif /* configUSE_QUEUE_SETS */

			--cTxLock;
		}

		pxQueue->cTxLock = queueUNLOCKED;
     f2a:	8f ef       	ldi	r24, 0xFF	; 255
     f2c:	f8 01       	movw	r30, r16
     f2e:	86 8f       	std	Z+30, r24	; 0x1e
	}
	taskEXIT_CRITICAL();
     f30:	0f 90       	pop	r0
     f32:	0f be       	out	0x3f, r0	; 63

	/* Do the same for the Rx lock. */
	taskENTER_CRITICAL();
     f34:	0f b6       	in	r0, 0x3f	; 63
     f36:	f8 94       	cli
     f38:	0f 92       	push	r0
	{
		int8_t cRxLock = pxQueue->cRxLock;
     f3a:	f8 01       	movw	r30, r16
     f3c:	c5 8d       	ldd	r28, Z+29	; 0x1d

		while( cRxLock > queueLOCKED_UNMODIFIED )
     f3e:	1c 16       	cp	r1, r28
     f40:	c4 f4       	brge	.+48     	; 0xf72 <prvUnlockQueue+0x94>
		{
			if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )
     f42:	80 85       	ldd	r24, Z+8	; 0x08
     f44:	88 23       	and	r24, r24
     f46:	31 f4       	brne	.+12     	; 0xf54 <prvUnlockQueue+0x76>
     f48:	14 c0       	rjmp	.+40     	; 0xf72 <prvUnlockQueue+0x94>
     f4a:	f8 01       	movw	r30, r16
     f4c:	80 85       	ldd	r24, Z+8	; 0x08
     f4e:	88 23       	and	r24, r24
     f50:	39 f4       	brne	.+14     	; 0xf60 <prvUnlockQueue+0x82>
     f52:	0f c0       	rjmp	.+30     	; 0xf72 <prvUnlockQueue+0x94>
			{
				if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )
     f54:	ee 24       	eor	r14, r14
     f56:	ff 24       	eor	r15, r15
     f58:	68 94       	set
     f5a:	e3 f8       	bld	r14, 3
     f5c:	e0 0e       	add	r14, r16
     f5e:	f1 1e       	adc	r15, r17
     f60:	c7 01       	movw	r24, r14
     f62:	0e 94 f6 10 	call	0x21ec	; 0x21ec <xTaskRemoveFromEventList>
     f66:	88 23       	and	r24, r24
     f68:	11 f0       	breq	.+4      	; 0xf6e <prvUnlockQueue+0x90>
				{
					vTaskMissedYield();
     f6a:	0e 94 c1 11 	call	0x2382	; 0x2382 <vTaskMissedYield>
				else
				{
					mtCOVERAGE_TEST_MARKER();
				}

				--cRxLock;
     f6e:	c1 50       	subi	r28, 0x01	; 1
	/* Do the same for the Rx lock. */
	taskENTER_CRITICAL();
	{
		int8_t cRxLock = pxQueue->cRxLock;

		while( cRxLock > queueLOCKED_UNMODIFIED )
     f70:	61 f7       	brne	.-40     	; 0xf4a <prvUnlockQueue+0x6c>
			{
				break;
			}
		}

		pxQueue->cRxLock = queueUNLOCKED;
     f72:	8f ef       	ldi	r24, 0xFF	; 255
     f74:	f8 01       	movw	r30, r16
     f76:	85 8f       	std	Z+29, r24	; 0x1d
	}
	taskEXIT_CRITICAL();
     f78:	0f 90       	pop	r0
     f7a:	0f be       	out	0x3f, r0	; 63
}
     f7c:	cf 91       	pop	r28
     f7e:	1f 91       	pop	r17
     f80:	0f 91       	pop	r16
     f82:	ff 90       	pop	r15
     f84:	ef 90       	pop	r14
     f86:	08 95       	ret

00000f88 <xQueueGenericReset>:
	}														\
	taskEXIT_CRITICAL()
/*-----------------------------------------------------------*/

BaseType_t xQueueGenericReset( QueueHandle_t xQueue, BaseType_t xNewQueue )
{
     f88:	cf 93       	push	r28
     f8a:	df 93       	push	r29
     f8c:	ec 01       	movw	r28, r24
Queue_t * const pxQueue = xQueue;

	configASSERT( pxQueue );

	taskENTER_CRITICAL();
     f8e:	0f b6       	in	r0, 0x3f	; 63
     f90:	f8 94       	cli
     f92:	0f 92       	push	r0
	{
		pxQueue->u.xQueue.pcTail = pxQueue->pcHead + ( pxQueue->uxLength * pxQueue->uxItemSize ); /*lint !e9016 Pointer arithmetic allowed on char types, especially when it assists conveying intent. */
     f94:	48 81       	ld	r20, Y
     f96:	59 81       	ldd	r21, Y+1	; 0x01
     f98:	2b 8d       	ldd	r18, Y+27	; 0x1b
     f9a:	ec 8d       	ldd	r30, Y+28	; 0x1c
     f9c:	30 e0       	ldi	r19, 0x00	; 0
     f9e:	f0 e0       	ldi	r31, 0x00	; 0
     fa0:	2e 9f       	mul	r18, r30
     fa2:	c0 01       	movw	r24, r0
     fa4:	2f 9f       	mul	r18, r31
     fa6:	90 0d       	add	r25, r0
     fa8:	3e 9f       	mul	r19, r30
     faa:	90 0d       	add	r25, r0
     fac:	11 24       	eor	r1, r1
     fae:	84 0f       	add	r24, r20
     fb0:	95 1f       	adc	r25, r21
     fb2:	9d 83       	std	Y+5, r25	; 0x05
     fb4:	8c 83       	std	Y+4, r24	; 0x04
		pxQueue->uxMessagesWaiting = ( UBaseType_t ) 0U;
     fb6:	1a 8e       	std	Y+26, r1	; 0x1a
		pxQueue->pcWriteTo = pxQueue->pcHead;
     fb8:	5b 83       	std	Y+3, r21	; 0x03
     fba:	4a 83       	std	Y+2, r20	; 0x02
		pxQueue->u.xQueue.pcReadFrom = pxQueue->pcHead + ( ( pxQueue->uxLength - 1U ) * pxQueue->uxItemSize ); /*lint !e9016 Pointer arithmetic allowed on char types, especially when it assists conveying intent. */
     fbc:	c9 01       	movw	r24, r18
     fbe:	01 97       	sbiw	r24, 0x01	; 1
     fc0:	8e 9f       	mul	r24, r30
     fc2:	90 01       	movw	r18, r0
     fc4:	8f 9f       	mul	r24, r31
     fc6:	30 0d       	add	r19, r0
     fc8:	9e 9f       	mul	r25, r30
     fca:	30 0d       	add	r19, r0
     fcc:	11 24       	eor	r1, r1
     fce:	24 0f       	add	r18, r20
     fd0:	35 1f       	adc	r19, r21
     fd2:	3f 83       	std	Y+7, r19	; 0x07
     fd4:	2e 83       	std	Y+6, r18	; 0x06
		pxQueue->cRxLock = queueUNLOCKED;
     fd6:	8f ef       	ldi	r24, 0xFF	; 255
     fd8:	8d 8f       	std	Y+29, r24	; 0x1d
		pxQueue->cTxLock = queueUNLOCKED;
     fda:	8e 8f       	std	Y+30, r24	; 0x1e

		if( xNewQueue == pdFALSE )
     fdc:	66 23       	and	r22, r22
     fde:	61 f4       	brne	.+24     	; 0xff8 <xQueueGenericReset+0x70>
			/* If there are tasks blocked waiting to read from the queue, then
			the tasks will remain blocked as after this function exits the queue
			will still be empty.  If there are tasks blocked waiting to write to
			the queue, then one should be unblocked as after this function exits
			it will be possible to write to it. */
			if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )
     fe0:	88 85       	ldd	r24, Y+8	; 0x08
     fe2:	88 23       	and	r24, r24
     fe4:	89 f0       	breq	.+34     	; 0x1008 <xQueueGenericReset+0x80>
			{
				if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )
     fe6:	ce 01       	movw	r24, r28
     fe8:	08 96       	adiw	r24, 0x08	; 8
     fea:	0e 94 f6 10 	call	0x21ec	; 0x21ec <xTaskRemoveFromEventList>
     fee:	88 23       	and	r24, r24
     ff0:	59 f0       	breq	.+22     	; 0x1008 <xQueueGenericReset+0x80>
				{
					queueYIELD_IF_USING_PREEMPTION();
     ff2:	0e 94 39 06 	call	0xc72	; 0xc72 <vPortYield>
     ff6:	08 c0       	rjmp	.+16     	; 0x1008 <xQueueGenericReset+0x80>
			}
		}
		else
		{
			/* Ensure the event queues start in the correct state. */
			vListInitialise( &( pxQueue->xTasksWaitingToSend ) );
     ff8:	ce 01       	movw	r24, r28
     ffa:	08 96       	adiw	r24, 0x08	; 8
     ffc:	0e 94 e7 04 	call	0x9ce	; 0x9ce <vListInitialise>
			vListInitialise( &( pxQueue->xTasksWaitingToReceive ) );
    1000:	ce 01       	movw	r24, r28
    1002:	41 96       	adiw	r24, 0x11	; 17
    1004:	0e 94 e7 04 	call	0x9ce	; 0x9ce <vListInitialise>
		}
	}
	taskEXIT_CRITICAL();
    1008:	0f 90       	pop	r0
    100a:	0f be       	out	0x3f, r0	; 63

	/* A value is returned for calling semantic consistency with previous
	versions. */
	return pdPASS;
}
    100c:	81 e0       	ldi	r24, 0x01	; 1
    100e:	df 91       	pop	r29
    1010:	cf 91       	pop	r28
    1012:	08 95       	ret

00001014 <xQueueGenericCreate>:
/*-----------------------------------------------------------*/

#if( configSUPPORT_DYNAMIC_ALLOCATION == 1 )

	QueueHandle_t xQueueGenericCreate( const UBaseType_t uxQueueLength, const UBaseType_t uxItemSize, const uint8_t ucQueueType )
	{
    1014:	0f 93       	push	r16
    1016:	1f 93       	push	r17
    1018:	cf 93       	push	r28
    101a:	df 93       	push	r29
    101c:	08 2f       	mov	r16, r24
    101e:	16 2f       	mov	r17, r22
	size_t xQueueSizeInBytes;
	uint8_t *pucQueueStorage;

		configASSERT( uxQueueLength > ( UBaseType_t ) 0 );

		if( uxItemSize == ( UBaseType_t ) 0 )
    1020:	66 23       	and	r22, r22
    1022:	21 f0       	breq	.+8      	; 0x102c <xQueueGenericCreate+0x18>
		}
		else
		{
			/* Allocate enough space to hold the maximum number of items that
			can be in the queue at any time. */
			xQueueSizeInBytes = ( size_t ) ( uxQueueLength * uxItemSize ); /*lint !e961 MISRA exception as the casts are only redundant for some ports. */
    1024:	68 9f       	mul	r22, r24
    1026:	c0 01       	movw	r24, r0
    1028:	11 24       	eor	r1, r1
    102a:	02 c0       	rjmp	.+4      	; 0x1030 <xQueueGenericCreate+0x1c>
		configASSERT( uxQueueLength > ( UBaseType_t ) 0 );

		if( uxItemSize == ( UBaseType_t ) 0 )
		{
			/* There is not going to be a queue storage area. */
			xQueueSizeInBytes = ( size_t ) 0;
    102c:	80 e0       	ldi	r24, 0x00	; 0
    102e:	90 e0       	ldi	r25, 0x00	; 0
		alignment requirements of the Queue_t structure - which in this case
		is an int8_t *.  Therefore, whenever the stack alignment requirements
		are greater than or equal to the pointer to char requirements the cast
		is safe.  In other cases alignment requirements are not strict (one or
		two bytes). */
		pxNewQueue = ( Queue_t * ) pvPortMalloc( sizeof( Queue_t ) + xQueueSizeInBytes ); /*lint !e9087 !e9079 see comment above. */
    1030:	4f 96       	adiw	r24, 0x1f	; 31
    1032:	0e 94 0e 04 	call	0x81c	; 0x81c <pvPortMalloc>
    1036:	ec 01       	movw	r28, r24

		if( pxNewQueue != NULL )
    1038:	00 97       	sbiw	r24, 0x00	; 0
    103a:	71 f0       	breq	.+28     	; 0x1058 <xQueueGenericCreate+0x44>
{
	/* Remove compiler warnings about unused parameters should
	configUSE_TRACE_FACILITY not be set to 1. */
	( void ) ucQueueType;

	if( uxItemSize == ( UBaseType_t ) 0 )
    103c:	11 23       	and	r17, r17
    103e:	19 f4       	brne	.+6      	; 0x1046 <xQueueGenericCreate+0x32>
	{
		/* No RAM was allocated for the queue storage area, but PC head cannot
		be set to NULL because NULL is used as a key to say the queue is used as
		a mutex.  Therefore just set pcHead to point to the queue as a benign
		value that is known to be within the memory map. */
		pxNewQueue->pcHead = ( int8_t * ) pxNewQueue;
    1040:	99 83       	std	Y+1, r25	; 0x01
    1042:	88 83       	st	Y, r24
    1044:	03 c0       	rjmp	.+6      	; 0x104c <xQueueGenericCreate+0x38>
		if( pxNewQueue != NULL )
		{
			/* Jump past the queue structure to find the location of the queue
			storage area. */
			pucQueueStorage = ( uint8_t * ) pxNewQueue;
			pucQueueStorage += sizeof( Queue_t ); /*lint !e9016 Pointer arithmetic allowed on char types, especially when it assists conveying intent. */
    1046:	4f 96       	adiw	r24, 0x1f	; 31
		pxNewQueue->pcHead = ( int8_t * ) pxNewQueue;
	}
	else
	{
		/* Set the head to the start of the queue storage area. */
		pxNewQueue->pcHead = ( int8_t * ) pucQueueStorage;
    1048:	99 83       	std	Y+1, r25	; 0x01
    104a:	88 83       	st	Y, r24
	}

	/* Initialise the queue members as described where the queue type is
	defined. */
	pxNewQueue->uxLength = uxQueueLength;
    104c:	0b 8f       	std	Y+27, r16	; 0x1b
	pxNewQueue->uxItemSize = uxItemSize;
    104e:	1c 8f       	std	Y+28, r17	; 0x1c
	( void ) xQueueGenericReset( pxNewQueue, pdTRUE );
    1050:	ce 01       	movw	r24, r28
    1052:	61 e0       	ldi	r22, 0x01	; 1
    1054:	0e 94 c4 07 	call	0xf88	; 0xf88 <xQueueGenericReset>
			traceQUEUE_CREATE_FAILED( ucQueueType );
			mtCOVERAGE_TEST_MARKER();
		}

		return pxNewQueue;
	}
    1058:	8c 2f       	mov	r24, r28
    105a:	9d 2f       	mov	r25, r29
    105c:	df 91       	pop	r29
    105e:	cf 91       	pop	r28
    1060:	1f 91       	pop	r17
    1062:	0f 91       	pop	r16
    1064:	08 95       	ret

00001066 <xQueueGenericSend>:

#endif /* ( ( configUSE_COUNTING_SEMAPHORES == 1 ) && ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) ) */
/*-----------------------------------------------------------*/

BaseType_t xQueueGenericSend( QueueHandle_t xQueue, const void * const pvItemToQueue, TickType_t xTicksToWait, const BaseType_t xCopyPosition )
{
    1066:	8f 92       	push	r8
    1068:	9f 92       	push	r9
    106a:	bf 92       	push	r11
    106c:	cf 92       	push	r12
    106e:	df 92       	push	r13
    1070:	ef 92       	push	r14
    1072:	ff 92       	push	r15
    1074:	0f 93       	push	r16
    1076:	1f 93       	push	r17
    1078:	cf 93       	push	r28
    107a:	df 93       	push	r29
    107c:	00 d0       	rcall	.+0      	; 0x107e <xQueueGenericSend+0x18>
    107e:	00 d0       	rcall	.+0      	; 0x1080 <xQueueGenericSend+0x1a>
    1080:	0f 92       	push	r0
    1082:	cd b7       	in	r28, 0x3d	; 61
    1084:	de b7       	in	r29, 0x3e	; 62
    1086:	8c 01       	movw	r16, r24
    1088:	4b 01       	movw	r8, r22
    108a:	5d 83       	std	Y+5, r21	; 0x05
    108c:	4c 83       	std	Y+4, r20	; 0x04
    108e:	e2 2e       	mov	r14, r18
BaseType_t xEntryTimeSet = pdFALSE, xYieldRequired;
    1090:	ff 24       	eor	r15, r15
				else if( xEntryTimeSet == pdFALSE )
				{
					/* The queue was full and a block time was specified so
					configure the timeout structure. */
					vTaskInternalSetTimeOutState( &xTimeOut );
					xEntryTimeSet = pdTRUE;
    1092:	bb 24       	eor	r11, r11
    1094:	b3 94       	inc	r11
		if( xTaskCheckForTimeOut( &xTimeOut, &xTicksToWait ) == pdFALSE )
		{
			if( prvIsQueueFull( pxQueue ) != pdFALSE )
			{
				traceBLOCKING_ON_QUEUE_SEND( pxQueue );
				vTaskPlaceOnEventList( &( pxQueue->xTasksWaitingToSend ), xTicksToWait );
    1096:	cc 24       	eor	r12, r12
    1098:	dd 24       	eor	r13, r13
    109a:	68 94       	set
    109c:	c3 f8       	bld	r12, 3
    109e:	c8 0e       	add	r12, r24
    10a0:	d9 1e       	adc	r13, r25
	/*lint -save -e904 This function relaxes the coding standard somewhat to
	allow return statements within the function itself.  This is done in the
	interest of execution time efficiency. */
	for( ;; )
	{
		taskENTER_CRITICAL();
    10a2:	0f b6       	in	r0, 0x3f	; 63
    10a4:	f8 94       	cli
    10a6:	0f 92       	push	r0
		{
			/* Is there room on the queue now?  The running task must be the
			highest priority task wanting to access the queue.  If the head item
			in the queue is to be overwritten then it does not matter if the
			queue is full. */
			if( ( pxQueue->uxMessagesWaiting < pxQueue->uxLength ) || ( xCopyPosition == queueOVERWRITE ) )
    10a8:	f8 01       	movw	r30, r16
    10aa:	92 8d       	ldd	r25, Z+26	; 0x1a
    10ac:	83 8d       	ldd	r24, Z+27	; 0x1b
    10ae:	98 17       	cp	r25, r24
    10b0:	18 f0       	brcs	.+6      	; 0x10b8 <xQueueGenericSend+0x52>
    10b2:	f2 e0       	ldi	r31, 0x02	; 2
    10b4:	ef 16       	cp	r14, r31
    10b6:	d1 f4       	brne	.+52     	; 0x10ec <xQueueGenericSend+0x86>
						}
					}
				}
				#else /* configUSE_QUEUE_SETS */
				{
					xYieldRequired = prvCopyDataToQueue( pxQueue, pvItemToQueue, xCopyPosition );
    10b8:	c8 01       	movw	r24, r16
    10ba:	b4 01       	movw	r22, r8
    10bc:	4e 2d       	mov	r20, r14
    10be:	0e 94 09 07 	call	0xe12	; 0xe12 <prvCopyDataToQueue>

					/* If there was a task waiting for data to arrive on the
					queue then unblock it now. */
					if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
    10c2:	f8 01       	movw	r30, r16
    10c4:	91 89       	ldd	r25, Z+17	; 0x11
    10c6:	99 23       	and	r25, r25
    10c8:	49 f0       	breq	.+18     	; 0x10dc <xQueueGenericSend+0x76>
					{
						if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
    10ca:	c8 01       	movw	r24, r16
    10cc:	41 96       	adiw	r24, 0x11	; 17
    10ce:	0e 94 f6 10 	call	0x21ec	; 0x21ec <xTaskRemoveFromEventList>
    10d2:	88 23       	and	r24, r24
    10d4:	39 f0       	breq	.+14     	; 0x10e4 <xQueueGenericSend+0x7e>
						{
							/* The unblocked task has a priority higher than
							our own so yield immediately.  Yes it is ok to do
							this from within the critical section - the kernel
							takes care of that. */
							queueYIELD_IF_USING_PREEMPTION();
    10d6:	0e 94 39 06 	call	0xc72	; 0xc72 <vPortYield>
    10da:	04 c0       	rjmp	.+8      	; 0x10e4 <xQueueGenericSend+0x7e>
						else
						{
							mtCOVERAGE_TEST_MARKER();
						}
					}
					else if( xYieldRequired != pdFALSE )
    10dc:	88 23       	and	r24, r24
    10de:	11 f0       	breq	.+4      	; 0x10e4 <xQueueGenericSend+0x7e>
					{
						/* This path is a special case that will only get
						executed if the task was holding multiple mutexes and
						the mutexes were given back in an order that is
						different to that in which they were taken. */
						queueYIELD_IF_USING_PREEMPTION();
    10e0:	0e 94 39 06 	call	0xc72	; 0xc72 <vPortYield>
						mtCOVERAGE_TEST_MARKER();
					}
				}
				#endif /* configUSE_QUEUE_SETS */

				taskEXIT_CRITICAL();
    10e4:	0f 90       	pop	r0
    10e6:	0f be       	out	0x3f, r0	; 63
				return pdPASS;
    10e8:	81 e0       	ldi	r24, 0x01	; 1
    10ea:	4c c0       	rjmp	.+152    	; 0x1184 <xQueueGenericSend+0x11e>
			}
			else
			{
				if( xTicksToWait == ( TickType_t ) 0 )
    10ec:	8c 81       	ldd	r24, Y+4	; 0x04
    10ee:	9d 81       	ldd	r25, Y+5	; 0x05
    10f0:	00 97       	sbiw	r24, 0x00	; 0
    10f2:	21 f4       	brne	.+8      	; 0x10fc <xQueueGenericSend+0x96>
				{
					/* The queue was full and no block time is specified (or
					the block time has expired) so leave now. */
					taskEXIT_CRITICAL();
    10f4:	0f 90       	pop	r0
    10f6:	0f be       	out	0x3f, r0	; 63

					/* Return to the original privilege level before exiting
					the function. */
					traceQUEUE_SEND_FAILED( pxQueue );
					return errQUEUE_FULL;
    10f8:	80 e0       	ldi	r24, 0x00	; 0
    10fa:	44 c0       	rjmp	.+136    	; 0x1184 <xQueueGenericSend+0x11e>
				}
				else if( xEntryTimeSet == pdFALSE )
    10fc:	ff 20       	and	r15, r15
    10fe:	29 f4       	brne	.+10     	; 0x110a <xQueueGenericSend+0xa4>
				{
					/* The queue was full and a block time was specified so
					configure the timeout structure. */
					vTaskInternalSetTimeOutState( &xTimeOut );
    1100:	ce 01       	movw	r24, r28
    1102:	01 96       	adiw	r24, 0x01	; 1
    1104:	0e 94 89 11 	call	0x2312	; 0x2312 <vTaskInternalSetTimeOutState>
					xEntryTimeSet = pdTRUE;
    1108:	fb 2c       	mov	r15, r11
					/* Entry time was already set. */
					mtCOVERAGE_TEST_MARKER();
				}
			}
		}
		taskEXIT_CRITICAL();
    110a:	0f 90       	pop	r0
    110c:	0f be       	out	0x3f, r0	; 63

		/* Interrupts and other tasks can send to and receive from the queue
		now the critical section has been exited. */

		vTaskSuspendAll();
    110e:	0e 94 be 0e 	call	0x1d7c	; 0x1d7c <vTaskSuspendAll>
		prvLockQueue( pxQueue );
    1112:	0f b6       	in	r0, 0x3f	; 63
    1114:	f8 94       	cli
    1116:	0f 92       	push	r0
    1118:	f8 01       	movw	r30, r16
    111a:	85 8d       	ldd	r24, Z+29	; 0x1d
    111c:	8f 3f       	cpi	r24, 0xFF	; 255
    111e:	09 f4       	brne	.+2      	; 0x1122 <xQueueGenericSend+0xbc>
    1120:	15 8e       	std	Z+29, r1	; 0x1d
    1122:	f8 01       	movw	r30, r16
    1124:	86 8d       	ldd	r24, Z+30	; 0x1e
    1126:	8f 3f       	cpi	r24, 0xFF	; 255
    1128:	09 f4       	brne	.+2      	; 0x112c <xQueueGenericSend+0xc6>
    112a:	16 8e       	std	Z+30, r1	; 0x1e
    112c:	0f 90       	pop	r0
    112e:	0f be       	out	0x3f, r0	; 63

		/* Update the timeout state to see if it has expired yet. */
		if( xTaskCheckForTimeOut( &xTimeOut, &xTicksToWait ) == pdFALSE )
    1130:	ce 01       	movw	r24, r28
    1132:	01 96       	adiw	r24, 0x01	; 1
    1134:	be 01       	movw	r22, r28
    1136:	6c 5f       	subi	r22, 0xFC	; 252
    1138:	7f 4f       	sbci	r23, 0xFF	; 255
    113a:	0e 94 94 11 	call	0x2328	; 0x2328 <xTaskCheckForTimeOut>
    113e:	88 23       	and	r24, r24
    1140:	d9 f4       	brne	.+54     	; 0x1178 <xQueueGenericSend+0x112>
		{
			if( prvIsQueueFull( pxQueue ) != pdFALSE )
    1142:	c8 01       	movw	r24, r16
    1144:	0e 94 fd 06 	call	0xdfa	; 0xdfa <prvIsQueueFull>
    1148:	88 23       	and	r24, r24
    114a:	81 f0       	breq	.+32     	; 0x116c <xQueueGenericSend+0x106>
			{
				traceBLOCKING_ON_QUEUE_SEND( pxQueue );
				vTaskPlaceOnEventList( &( pxQueue->xTasksWaitingToSend ), xTicksToWait );
    114c:	6c 81       	ldd	r22, Y+4	; 0x04
    114e:	7d 81       	ldd	r23, Y+5	; 0x05
    1150:	c6 01       	movw	r24, r12
    1152:	0e 94 cb 10 	call	0x2196	; 0x2196 <vTaskPlaceOnEventList>
				/* Unlocking the queue means queue events can effect the
				event list.  It is possible that interrupts occurring now
				remove this task from the event list again - but as the
				scheduler is suspended the task will go onto the pending
				ready last instead of the actual ready list. */
				prvUnlockQueue( pxQueue );
    1156:	c8 01       	movw	r24, r16
    1158:	0e 94 6f 07 	call	0xede	; 0xede <prvUnlockQueue>
				/* Resuming the scheduler will move tasks from the pending
				ready list into the ready list - so it is feasible that this
				task is already in a ready list before it yields - in which
				case the yield will not cause a context switch unless there
				is also a higher priority task in the pending ready list. */
				if( xTaskResumeAll() == pdFALSE )
    115c:	0e 94 9c 0f 	call	0x1f38	; 0x1f38 <xTaskResumeAll>
    1160:	88 23       	and	r24, r24
    1162:	09 f0       	breq	.+2      	; 0x1166 <xQueueGenericSend+0x100>
    1164:	9e cf       	rjmp	.-196    	; 0x10a2 <xQueueGenericSend+0x3c>
				{
					portYIELD_WITHIN_API();
    1166:	0e 94 39 06 	call	0xc72	; 0xc72 <vPortYield>
    116a:	9b cf       	rjmp	.-202    	; 0x10a2 <xQueueGenericSend+0x3c>
				}
			}
			else
			{
				/* Try again. */
				prvUnlockQueue( pxQueue );
    116c:	c8 01       	movw	r24, r16
    116e:	0e 94 6f 07 	call	0xede	; 0xede <prvUnlockQueue>
				( void ) xTaskResumeAll();
    1172:	0e 94 9c 0f 	call	0x1f38	; 0x1f38 <xTaskResumeAll>
    1176:	95 cf       	rjmp	.-214    	; 0x10a2 <xQueueGenericSend+0x3c>
			}
		}
		else
		{
			/* The timeout has expired. */
			prvUnlockQueue( pxQueue );
    1178:	c8 01       	movw	r24, r16
    117a:	0e 94 6f 07 	call	0xede	; 0xede <prvUnlockQueue>
			( void ) xTaskResumeAll();
    117e:	0e 94 9c 0f 	call	0x1f38	; 0x1f38 <xTaskResumeAll>

			traceQUEUE_SEND_FAILED( pxQueue );
			return errQUEUE_FULL;
    1182:	80 e0       	ldi	r24, 0x00	; 0
		}
	} /*lint -restore */
}
    1184:	0f 90       	pop	r0
    1186:	0f 90       	pop	r0
    1188:	0f 90       	pop	r0
    118a:	0f 90       	pop	r0
    118c:	0f 90       	pop	r0
    118e:	df 91       	pop	r29
    1190:	cf 91       	pop	r28
    1192:	1f 91       	pop	r17
    1194:	0f 91       	pop	r16
    1196:	ff 90       	pop	r15
    1198:	ef 90       	pop	r14
    119a:	df 90       	pop	r13
    119c:	cf 90       	pop	r12
    119e:	bf 90       	pop	r11
    11a0:	9f 90       	pop	r9
    11a2:	8f 90       	pop	r8
    11a4:	08 95       	ret

000011a6 <xQueueGenericSendFromISR>:
/*-----------------------------------------------------------*/

BaseType_t xQueueGenericSendFromISR( QueueHandle_t xQueue, const void * const pvItemToQueue, BaseType_t * const pxHigherPriorityTaskWoken, const BaseType_t xCopyPosition )
{
    11a6:	ef 92       	push	r14
    11a8:	ff 92       	push	r15
    11aa:	0f 93       	push	r16
    11ac:	1f 93       	push	r17
    11ae:	cf 93       	push	r28
    11b0:	8c 01       	movw	r16, r24
    11b2:	7a 01       	movw	r14, r20
	read, instead return a flag to say whether a context switch is required or
	not (i.e. has a task with a higher priority than us been woken by this
	post). */
	uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
	{
		if( ( pxQueue->uxMessagesWaiting < pxQueue->uxLength ) || ( xCopyPosition == queueOVERWRITE ) )
    11b4:	fc 01       	movw	r30, r24
    11b6:	92 8d       	ldd	r25, Z+26	; 0x1a
    11b8:	83 8d       	ldd	r24, Z+27	; 0x1b
    11ba:	98 17       	cp	r25, r24
    11bc:	10 f0       	brcs	.+4      	; 0x11c2 <xQueueGenericSendFromISR+0x1c>
    11be:	22 30       	cpi	r18, 0x02	; 2
    11c0:	f1 f4       	brne	.+60     	; 0x11fe <xQueueGenericSendFromISR+0x58>
		{
			const int8_t cTxLock = pxQueue->cTxLock;
    11c2:	f8 01       	movw	r30, r16
    11c4:	c6 8d       	ldd	r28, Z+30	; 0x1e
			/* Semaphores use xQueueGiveFromISR(), so pxQueue will not be a
			semaphore or mutex.  That means prvCopyDataToQueue() cannot result
			in a task disinheriting a priority and prvCopyDataToQueue() can be
			called here even though the disinherit function does not check if
			the scheduler is suspended before accessing the ready lists. */
			( void ) prvCopyDataToQueue( pxQueue, pvItemToQueue, xCopyPosition );
    11c6:	c8 01       	movw	r24, r16
    11c8:	42 2f       	mov	r20, r18
    11ca:	0e 94 09 07 	call	0xe12	; 0xe12 <prvCopyDataToQueue>

			/* The event list is not altered if the queue is locked.  This will
			be done when the queue is unlocked later. */
			if( cTxLock == queueUNLOCKED )
    11ce:	cf 3f       	cpi	r28, 0xFF	; 255
    11d0:	89 f4       	brne	.+34     	; 0x11f4 <xQueueGenericSendFromISR+0x4e>
						}
					}
				}
				#else /* configUSE_QUEUE_SETS */
				{
					if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
    11d2:	f8 01       	movw	r30, r16
    11d4:	81 89       	ldd	r24, Z+17	; 0x11
    11d6:	88 23       	and	r24, r24
    11d8:	a1 f0       	breq	.+40     	; 0x1202 <xQueueGenericSendFromISR+0x5c>
					{
						if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
    11da:	c8 01       	movw	r24, r16
    11dc:	41 96       	adiw	r24, 0x11	; 17
    11de:	0e 94 f6 10 	call	0x21ec	; 0x21ec <xTaskRemoveFromEventList>
    11e2:	88 23       	and	r24, r24
    11e4:	81 f0       	breq	.+32     	; 0x1206 <xQueueGenericSendFromISR+0x60>
						{
							/* The task waiting has a higher priority so record that a
							context	switch is required. */
							if( pxHigherPriorityTaskWoken != NULL )
    11e6:	e1 14       	cp	r14, r1
    11e8:	f1 04       	cpc	r15, r1
    11ea:	79 f0       	breq	.+30     	; 0x120a <xQueueGenericSendFromISR+0x64>
							{
								*pxHigherPriorityTaskWoken = pdTRUE;
    11ec:	81 e0       	ldi	r24, 0x01	; 1
    11ee:	f7 01       	movw	r30, r14
    11f0:	80 83       	st	Z, r24
    11f2:	0c c0       	rjmp	.+24     	; 0x120c <xQueueGenericSendFromISR+0x66>
			}
			else
			{
				/* Increment the lock count so the task that unlocks the queue
				knows that data was posted while it was locked. */
				pxQueue->cTxLock = ( int8_t ) ( cTxLock + 1 );
    11f4:	cf 5f       	subi	r28, 0xFF	; 255
    11f6:	f8 01       	movw	r30, r16
    11f8:	c6 8f       	std	Z+30, r28	; 0x1e
			}

			xReturn = pdPASS;
    11fa:	81 e0       	ldi	r24, 0x01	; 1
    11fc:	07 c0       	rjmp	.+14     	; 0x120c <xQueueGenericSendFromISR+0x66>
		}
		else
		{
			traceQUEUE_SEND_FROM_ISR_FAILED( pxQueue );
			xReturn = errQUEUE_FULL;
    11fe:	80 e0       	ldi	r24, 0x00	; 0
    1200:	05 c0       	rjmp	.+10     	; 0x120c <xQueueGenericSendFromISR+0x66>
				/* Increment the lock count so the task that unlocks the queue
				knows that data was posted while it was locked. */
				pxQueue->cTxLock = ( int8_t ) ( cTxLock + 1 );
			}

			xReturn = pdPASS;
    1202:	81 e0       	ldi	r24, 0x01	; 1
    1204:	03 c0       	rjmp	.+6      	; 0x120c <xQueueGenericSendFromISR+0x66>
    1206:	81 e0       	ldi	r24, 0x01	; 1
    1208:	01 c0       	rjmp	.+2      	; 0x120c <xQueueGenericSendFromISR+0x66>
    120a:	81 e0       	ldi	r24, 0x01	; 1
		}
	}
	portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );

	return xReturn;
}
    120c:	cf 91       	pop	r28
    120e:	1f 91       	pop	r17
    1210:	0f 91       	pop	r16
    1212:	ff 90       	pop	r15
    1214:	ef 90       	pop	r14
    1216:	08 95       	ret

00001218 <xQueueGiveFromISR>:
/*-----------------------------------------------------------*/

BaseType_t xQueueGiveFromISR( QueueHandle_t xQueue, BaseType_t * const pxHigherPriorityTaskWoken )
{
    1218:	cf 93       	push	r28
    121a:	df 93       	push	r29
    121c:	fc 01       	movw	r30, r24
    121e:	eb 01       	movw	r28, r22
	link: http://www.freertos.org/RTOS-Cortex-M3-M4.html */
	portASSERT_IF_INTERRUPT_PRIORITY_INVALID();

	uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
	{
		const UBaseType_t uxMessagesWaiting = pxQueue->uxMessagesWaiting;
    1220:	82 8d       	ldd	r24, Z+26	; 0x1a

		/* When the queue is used to implement a semaphore no data is ever
		moved through the queue but it is still valid to see if the queue 'has
		space'. */
		if( uxMessagesWaiting < pxQueue->uxLength )
    1222:	93 8d       	ldd	r25, Z+27	; 0x1b
    1224:	89 17       	cp	r24, r25
    1226:	b8 f4       	brcc	.+46     	; 0x1256 <xQueueGiveFromISR+0x3e>
		{
			const int8_t cTxLock = pxQueue->cTxLock;
    1228:	96 8d       	ldd	r25, Z+30	; 0x1e
			holder - and if there is a mutex holder then the mutex cannot be
			given from an ISR.  As this is the ISR version of the function it
			can be assumed there is no mutex holder and no need to determine if
			priority disinheritance is needed.  Simply increase the count of
			messages (semaphores) available. */
			pxQueue->uxMessagesWaiting = uxMessagesWaiting + ( UBaseType_t ) 1;
    122a:	8f 5f       	subi	r24, 0xFF	; 255
    122c:	82 8f       	std	Z+26, r24	; 0x1a

			/* The event list is not altered if the queue is locked.  This will
			be done when the queue is unlocked later. */
			if( cTxLock == queueUNLOCKED )
    122e:	9f 3f       	cpi	r25, 0xFF	; 255
    1230:	71 f4       	brne	.+28     	; 0x124e <xQueueGiveFromISR+0x36>
						}
					}
				}
				#else /* configUSE_QUEUE_SETS */
				{
					if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
    1232:	81 89       	ldd	r24, Z+17	; 0x11
    1234:	88 23       	and	r24, r24
    1236:	89 f0       	breq	.+34     	; 0x125a <xQueueGiveFromISR+0x42>
					{
						if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
    1238:	cf 01       	movw	r24, r30
    123a:	41 96       	adiw	r24, 0x11	; 17
    123c:	0e 94 f6 10 	call	0x21ec	; 0x21ec <xTaskRemoveFromEventList>
    1240:	88 23       	and	r24, r24
    1242:	69 f0       	breq	.+26     	; 0x125e <xQueueGiveFromISR+0x46>
						{
							/* The task waiting has a higher priority so record that a
							context	switch is required. */
							if( pxHigherPriorityTaskWoken != NULL )
    1244:	20 97       	sbiw	r28, 0x00	; 0
    1246:	69 f0       	breq	.+26     	; 0x1262 <xQueueGiveFromISR+0x4a>
							{
								*pxHigherPriorityTaskWoken = pdTRUE;
    1248:	81 e0       	ldi	r24, 0x01	; 1
    124a:	88 83       	st	Y, r24
    124c:	0b c0       	rjmp	.+22     	; 0x1264 <xQueueGiveFromISR+0x4c>
			}
			else
			{
				/* Increment the lock count so the task that unlocks the queue
				knows that data was posted while it was locked. */
				pxQueue->cTxLock = ( int8_t ) ( cTxLock + 1 );
    124e:	9f 5f       	subi	r25, 0xFF	; 255
    1250:	96 8f       	std	Z+30, r25	; 0x1e
			}

			xReturn = pdPASS;
    1252:	81 e0       	ldi	r24, 0x01	; 1
    1254:	07 c0       	rjmp	.+14     	; 0x1264 <xQueueGiveFromISR+0x4c>
		}
		else
		{
			traceQUEUE_SEND_FROM_ISR_FAILED( pxQueue );
			xReturn = errQUEUE_FULL;
    1256:	80 e0       	ldi	r24, 0x00	; 0
    1258:	05 c0       	rjmp	.+10     	; 0x1264 <xQueueGiveFromISR+0x4c>
				/* Increment the lock count so the task that unlocks the queue
				knows that data was posted while it was locked. */
				pxQueue->cTxLock = ( int8_t ) ( cTxLock + 1 );
			}

			xReturn = pdPASS;
    125a:	81 e0       	ldi	r24, 0x01	; 1
    125c:	03 c0       	rjmp	.+6      	; 0x1264 <xQueueGiveFromISR+0x4c>
    125e:	81 e0       	ldi	r24, 0x01	; 1
    1260:	01 c0       	rjmp	.+2      	; 0x1264 <xQueueGiveFromISR+0x4c>
    1262:	81 e0       	ldi	r24, 0x01	; 1
		}
	}
	portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );

	return xReturn;
}
    1264:	df 91       	pop	r29
    1266:	cf 91       	pop	r28
    1268:	08 95       	ret

0000126a <xQueueReceive>:
/*-----------------------------------------------------------*/

BaseType_t xQueueReceive( QueueHandle_t xQueue, void * const pvBuffer, TickType_t xTicksToWait )
{
    126a:	8f 92       	push	r8
    126c:	9f 92       	push	r9
    126e:	af 92       	push	r10
    1270:	bf 92       	push	r11
    1272:	df 92       	push	r13
    1274:	ef 92       	push	r14
    1276:	ff 92       	push	r15
    1278:	0f 93       	push	r16
    127a:	1f 93       	push	r17
    127c:	cf 93       	push	r28
    127e:	df 93       	push	r29
    1280:	00 d0       	rcall	.+0      	; 0x1282 <xQueueReceive+0x18>
    1282:	00 d0       	rcall	.+0      	; 0x1284 <xQueueReceive+0x1a>
    1284:	0f 92       	push	r0
    1286:	cd b7       	in	r28, 0x3d	; 61
    1288:	de b7       	in	r29, 0x3e	; 62
    128a:	7c 01       	movw	r14, r24
    128c:	4b 01       	movw	r8, r22
    128e:	5d 83       	std	Y+5, r21	; 0x05
    1290:	4c 83       	std	Y+4, r20	; 0x04
BaseType_t xEntryTimeSet = pdFALSE;
    1292:	00 e0       	ldi	r16, 0x00	; 0
				else if( xEntryTimeSet == pdFALSE )
				{
					/* The queue was empty and a block time was specified so
					configure the timeout structure. */
					vTaskInternalSetTimeOutState( &xTimeOut );
					xEntryTimeSet = pdTRUE;
    1294:	dd 24       	eor	r13, r13
    1296:	d3 94       	inc	r13
			/* The timeout has not expired.  If the queue is still empty place
			the task on the list of tasks waiting to receive from the queue. */
			if( prvIsQueueEmpty( pxQueue ) != pdFALSE )
			{
				traceBLOCKING_ON_QUEUE_RECEIVE( pxQueue );
				vTaskPlaceOnEventList( &( pxQueue->xTasksWaitingToReceive ), xTicksToWait );
    1298:	0f 2e       	mov	r0, r31
    129a:	f1 e1       	ldi	r31, 0x11	; 17
    129c:	af 2e       	mov	r10, r31
    129e:	bb 24       	eor	r11, r11
    12a0:	f0 2d       	mov	r31, r0
    12a2:	a8 0e       	add	r10, r24
    12a4:	b9 1e       	adc	r11, r25
	/*lint -save -e904  This function relaxes the coding standard somewhat to
	allow return statements within the function itself.  This is done in the
	interest of execution time efficiency. */
	for( ;; )
	{
		taskENTER_CRITICAL();
    12a6:	0f b6       	in	r0, 0x3f	; 63
    12a8:	f8 94       	cli
    12aa:	0f 92       	push	r0
		{
			const UBaseType_t uxMessagesWaiting = pxQueue->uxMessagesWaiting;
    12ac:	f7 01       	movw	r30, r14
    12ae:	12 8d       	ldd	r17, Z+26	; 0x1a

			/* Is there data in the queue now?  To be running the calling task
			must be the highest priority task wanting to access the queue. */
			if( uxMessagesWaiting > ( UBaseType_t ) 0 )
    12b0:	11 23       	and	r17, r17
    12b2:	b1 f0       	breq	.+44     	; 0x12e0 <xQueueReceive+0x76>
			{
				/* Data available, remove one item. */
				prvCopyDataFromQueue( pxQueue, pvBuffer );
    12b4:	c7 01       	movw	r24, r14
    12b6:	b4 01       	movw	r22, r8
    12b8:	0e 94 52 07 	call	0xea4	; 0xea4 <prvCopyDataFromQueue>
				traceQUEUE_RECEIVE( pxQueue );
				pxQueue->uxMessagesWaiting = uxMessagesWaiting - ( UBaseType_t ) 1;
    12bc:	11 50       	subi	r17, 0x01	; 1
    12be:	f7 01       	movw	r30, r14
    12c0:	12 8f       	std	Z+26, r17	; 0x1a

				/* There is now space in the queue, were any tasks waiting to
				post to the queue?  If so, unblock the highest priority waiting
				task. */
				if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )
    12c2:	80 85       	ldd	r24, Z+8	; 0x08
    12c4:	88 23       	and	r24, r24
    12c6:	41 f0       	breq	.+16     	; 0x12d8 <xQueueReceive+0x6e>
				{
					if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )
    12c8:	c7 01       	movw	r24, r14
    12ca:	08 96       	adiw	r24, 0x08	; 8
    12cc:	0e 94 f6 10 	call	0x21ec	; 0x21ec <xTaskRemoveFromEventList>
    12d0:	88 23       	and	r24, r24
    12d2:	11 f0       	breq	.+4      	; 0x12d8 <xQueueReceive+0x6e>
					{
						queueYIELD_IF_USING_PREEMPTION();
    12d4:	0e 94 39 06 	call	0xc72	; 0xc72 <vPortYield>
				else
				{
					mtCOVERAGE_TEST_MARKER();
				}

				taskEXIT_CRITICAL();
    12d8:	0f 90       	pop	r0
    12da:	0f be       	out	0x3f, r0	; 63
				return pdPASS;
    12dc:	81 e0       	ldi	r24, 0x01	; 1
    12de:	52 c0       	rjmp	.+164    	; 0x1384 <xQueueReceive+0x11a>
			}
			else
			{
				if( xTicksToWait == ( TickType_t ) 0 )
    12e0:	8c 81       	ldd	r24, Y+4	; 0x04
    12e2:	9d 81       	ldd	r25, Y+5	; 0x05
    12e4:	00 97       	sbiw	r24, 0x00	; 0
    12e6:	21 f4       	brne	.+8      	; 0x12f0 <xQueueReceive+0x86>
				{
					/* The queue was empty and no block time is specified (or
					the block time has expired) so leave now. */
					taskEXIT_CRITICAL();
    12e8:	0f 90       	pop	r0
    12ea:	0f be       	out	0x3f, r0	; 63
					traceQUEUE_RECEIVE_FAILED( pxQueue );
					return errQUEUE_EMPTY;
    12ec:	80 e0       	ldi	r24, 0x00	; 0
    12ee:	4a c0       	rjmp	.+148    	; 0x1384 <xQueueReceive+0x11a>
				}
				else if( xEntryTimeSet == pdFALSE )
    12f0:	00 23       	and	r16, r16
    12f2:	29 f4       	brne	.+10     	; 0x12fe <xQueueReceive+0x94>
				{
					/* The queue was empty and a block time was specified so
					configure the timeout structure. */
					vTaskInternalSetTimeOutState( &xTimeOut );
    12f4:	ce 01       	movw	r24, r28
    12f6:	01 96       	adiw	r24, 0x01	; 1
    12f8:	0e 94 89 11 	call	0x2312	; 0x2312 <vTaskInternalSetTimeOutState>
					xEntryTimeSet = pdTRUE;
    12fc:	0d 2d       	mov	r16, r13
					/* Entry time was already set. */
					mtCOVERAGE_TEST_MARKER();
				}
			}
		}
		taskEXIT_CRITICAL();
    12fe:	0f 90       	pop	r0
    1300:	0f be       	out	0x3f, r0	; 63

		/* Interrupts and other tasks can send to and receive from the queue
		now the critical section has been exited. */

		vTaskSuspendAll();
    1302:	0e 94 be 0e 	call	0x1d7c	; 0x1d7c <vTaskSuspendAll>
		prvLockQueue( pxQueue );
    1306:	0f b6       	in	r0, 0x3f	; 63
    1308:	f8 94       	cli
    130a:	0f 92       	push	r0
    130c:	f7 01       	movw	r30, r14
    130e:	85 8d       	ldd	r24, Z+29	; 0x1d
    1310:	8f 3f       	cpi	r24, 0xFF	; 255
    1312:	09 f4       	brne	.+2      	; 0x1316 <xQueueReceive+0xac>
    1314:	15 8e       	std	Z+29, r1	; 0x1d
    1316:	f7 01       	movw	r30, r14
    1318:	86 8d       	ldd	r24, Z+30	; 0x1e
    131a:	8f 3f       	cpi	r24, 0xFF	; 255
    131c:	09 f4       	brne	.+2      	; 0x1320 <xQueueReceive+0xb6>
    131e:	16 8e       	std	Z+30, r1	; 0x1e
    1320:	0f 90       	pop	r0
    1322:	0f be       	out	0x3f, r0	; 63

		/* Update the timeout state to see if it has expired yet. */
		if( xTaskCheckForTimeOut( &xTimeOut, &xTicksToWait ) == pdFALSE )
    1324:	ce 01       	movw	r24, r28
    1326:	01 96       	adiw	r24, 0x01	; 1
    1328:	be 01       	movw	r22, r28
    132a:	6c 5f       	subi	r22, 0xFC	; 252
    132c:	7f 4f       	sbci	r23, 0xFF	; 255
    132e:	0e 94 94 11 	call	0x2328	; 0x2328 <xTaskCheckForTimeOut>
    1332:	88 23       	and	r24, r24
    1334:	d9 f4       	brne	.+54     	; 0x136c <xQueueReceive+0x102>
		{
			/* The timeout has not expired.  If the queue is still empty place
			the task on the list of tasks waiting to receive from the queue. */
			if( prvIsQueueEmpty( pxQueue ) != pdFALSE )
    1336:	c7 01       	movw	r24, r14
    1338:	0e 94 f2 06 	call	0xde4	; 0xde4 <prvIsQueueEmpty>
    133c:	88 23       	and	r24, r24
    133e:	81 f0       	breq	.+32     	; 0x1360 <xQueueReceive+0xf6>
			{
				traceBLOCKING_ON_QUEUE_RECEIVE( pxQueue );
				vTaskPlaceOnEventList( &( pxQueue->xTasksWaitingToReceive ), xTicksToWait );
    1340:	6c 81       	ldd	r22, Y+4	; 0x04
    1342:	7d 81       	ldd	r23, Y+5	; 0x05
    1344:	c5 01       	movw	r24, r10
    1346:	0e 94 cb 10 	call	0x2196	; 0x2196 <vTaskPlaceOnEventList>
				prvUnlockQueue( pxQueue );
    134a:	c7 01       	movw	r24, r14
    134c:	0e 94 6f 07 	call	0xede	; 0xede <prvUnlockQueue>
				if( xTaskResumeAll() == pdFALSE )
    1350:	0e 94 9c 0f 	call	0x1f38	; 0x1f38 <xTaskResumeAll>
    1354:	88 23       	and	r24, r24
    1356:	09 f0       	breq	.+2      	; 0x135a <xQueueReceive+0xf0>
    1358:	a6 cf       	rjmp	.-180    	; 0x12a6 <xQueueReceive+0x3c>
				{
					portYIELD_WITHIN_API();
    135a:	0e 94 39 06 	call	0xc72	; 0xc72 <vPortYield>
    135e:	a3 cf       	rjmp	.-186    	; 0x12a6 <xQueueReceive+0x3c>
			}
			else
			{
				/* The queue contains data again.  Loop back to try and read the
				data. */
				prvUnlockQueue( pxQueue );
    1360:	c7 01       	movw	r24, r14
    1362:	0e 94 6f 07 	call	0xede	; 0xede <prvUnlockQueue>
				( void ) xTaskResumeAll();
    1366:	0e 94 9c 0f 	call	0x1f38	; 0x1f38 <xTaskResumeAll>
    136a:	9d cf       	rjmp	.-198    	; 0x12a6 <xQueueReceive+0x3c>
		}
		else
		{
			/* Timed out.  If there is no data in the queue exit, otherwise loop
			back and attempt to read the data. */
			prvUnlockQueue( pxQueue );
    136c:	c7 01       	movw	r24, r14
    136e:	0e 94 6f 07 	call	0xede	; 0xede <prvUnlockQueue>
			( void ) xTaskResumeAll();
    1372:	0e 94 9c 0f 	call	0x1f38	; 0x1f38 <xTaskResumeAll>

			if( prvIsQueueEmpty( pxQueue ) != pdFALSE )
    1376:	c7 01       	movw	r24, r14
    1378:	0e 94 f2 06 	call	0xde4	; 0xde4 <prvIsQueueEmpty>
    137c:	88 23       	and	r24, r24
    137e:	09 f4       	brne	.+2      	; 0x1382 <xQueueReceive+0x118>
    1380:	92 cf       	rjmp	.-220    	; 0x12a6 <xQueueReceive+0x3c>
			{
				traceQUEUE_RECEIVE_FAILED( pxQueue );
				return errQUEUE_EMPTY;
    1382:	80 e0       	ldi	r24, 0x00	; 0
			{
				mtCOVERAGE_TEST_MARKER();
			}
		}
	} /*lint -restore */
}
    1384:	0f 90       	pop	r0
    1386:	0f 90       	pop	r0
    1388:	0f 90       	pop	r0
    138a:	0f 90       	pop	r0
    138c:	0f 90       	pop	r0
    138e:	df 91       	pop	r29
    1390:	cf 91       	pop	r28
    1392:	1f 91       	pop	r17
    1394:	0f 91       	pop	r16
    1396:	ff 90       	pop	r15
    1398:	ef 90       	pop	r14
    139a:	df 90       	pop	r13
    139c:	bf 90       	pop	r11
    139e:	af 90       	pop	r10
    13a0:	9f 90       	pop	r9
    13a2:	8f 90       	pop	r8
    13a4:	08 95       	ret

000013a6 <xQueueSemaphoreTake>:
/*-----------------------------------------------------------*/

BaseType_t xQueueSemaphoreTake( QueueHandle_t xQueue, TickType_t xTicksToWait )
{
    13a6:	cf 92       	push	r12
    13a8:	df 92       	push	r13
    13aa:	ef 92       	push	r14
    13ac:	ff 92       	push	r15
    13ae:	0f 93       	push	r16
    13b0:	1f 93       	push	r17
    13b2:	cf 93       	push	r28
    13b4:	df 93       	push	r29
    13b6:	00 d0       	rcall	.+0      	; 0x13b8 <xQueueSemaphoreTake+0x12>
    13b8:	00 d0       	rcall	.+0      	; 0x13ba <xQueueSemaphoreTake+0x14>
    13ba:	0f 92       	push	r0
    13bc:	cd b7       	in	r28, 0x3d	; 61
    13be:	de b7       	in	r29, 0x3e	; 62
    13c0:	8c 01       	movw	r16, r24
    13c2:	7d 83       	std	Y+5, r23	; 0x05
    13c4:	6c 83       	std	Y+4, r22	; 0x04
BaseType_t xEntryTimeSet = pdFALSE;
    13c6:	ff 24       	eor	r15, r15
				else if( xEntryTimeSet == pdFALSE )
				{
					/* The semaphore count was 0 and a block time was specified
					so configure the timeout structure ready to block. */
					vTaskInternalSetTimeOutState( &xTimeOut );
					xEntryTimeSet = pdTRUE;
    13c8:	ee 24       	eor	r14, r14
    13ca:	e3 94       	inc	r14
						mtCOVERAGE_TEST_MARKER();
					}
				}
				#endif

				vTaskPlaceOnEventList( &( pxQueue->xTasksWaitingToReceive ), xTicksToWait );
    13cc:	0f 2e       	mov	r0, r31
    13ce:	f1 e1       	ldi	r31, 0x11	; 17
    13d0:	cf 2e       	mov	r12, r31
    13d2:	dd 24       	eor	r13, r13
    13d4:	f0 2d       	mov	r31, r0
    13d6:	c8 0e       	add	r12, r24
    13d8:	d9 1e       	adc	r13, r25
	/*lint -save -e904 This function relaxes the coding standard somewhat to allow return
	statements within the function itself.  This is done in the interest
	of execution time efficiency. */
	for( ;; )
	{
		taskENTER_CRITICAL();
    13da:	0f b6       	in	r0, 0x3f	; 63
    13dc:	f8 94       	cli
    13de:	0f 92       	push	r0
		{
			/* Semaphores are queues with an item size of 0, and where the
			number of messages in the queue is the semaphore's count value. */
			const UBaseType_t uxSemaphoreCount = pxQueue->uxMessagesWaiting;
    13e0:	f8 01       	movw	r30, r16
    13e2:	82 8d       	ldd	r24, Z+26	; 0x1a

			/* Is there data in the queue now?  To be running the calling task
			must be the highest priority task wanting to access the queue. */
			if( uxSemaphoreCount > ( UBaseType_t ) 0 )
    13e4:	88 23       	and	r24, r24
    13e6:	89 f0       	breq	.+34     	; 0x140a <xQueueSemaphoreTake+0x64>
			{
				traceQUEUE_RECEIVE( pxQueue );

				/* Semaphores are queues with a data size of zero and where the
				messages waiting is the semaphore's count.  Reduce the count. */
				pxQueue->uxMessagesWaiting = uxSemaphoreCount - ( UBaseType_t ) 1;
    13e8:	81 50       	subi	r24, 0x01	; 1
    13ea:	82 8f       	std	Z+26, r24	; 0x1a
				}
				#endif /* configUSE_MUTEXES */

				/* Check to see if other tasks are blocked waiting to give the
				semaphore, and if so, unblock the highest priority such task. */
				if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )
    13ec:	80 85       	ldd	r24, Z+8	; 0x08
    13ee:	88 23       	and	r24, r24
    13f0:	41 f0       	breq	.+16     	; 0x1402 <xQueueSemaphoreTake+0x5c>
				{
					if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )
    13f2:	c8 01       	movw	r24, r16
    13f4:	08 96       	adiw	r24, 0x08	; 8
    13f6:	0e 94 f6 10 	call	0x21ec	; 0x21ec <xTaskRemoveFromEventList>
    13fa:	88 23       	and	r24, r24
    13fc:	11 f0       	breq	.+4      	; 0x1402 <xQueueSemaphoreTake+0x5c>
					{
						queueYIELD_IF_USING_PREEMPTION();
    13fe:	0e 94 39 06 	call	0xc72	; 0xc72 <vPortYield>
				else
				{
					mtCOVERAGE_TEST_MARKER();
				}

				taskEXIT_CRITICAL();
    1402:	0f 90       	pop	r0
    1404:	0f be       	out	0x3f, r0	; 63
				return pdPASS;
    1406:	81 e0       	ldi	r24, 0x01	; 1
    1408:	52 c0       	rjmp	.+164    	; 0x14ae <xQueueSemaphoreTake+0x108>
			}
			else
			{
				if( xTicksToWait == ( TickType_t ) 0 )
    140a:	8c 81       	ldd	r24, Y+4	; 0x04
    140c:	9d 81       	ldd	r25, Y+5	; 0x05
    140e:	00 97       	sbiw	r24, 0x00	; 0
    1410:	21 f4       	brne	.+8      	; 0x141a <xQueueSemaphoreTake+0x74>
					}
					#endif /* configUSE_MUTEXES */

					/* The semaphore count was 0 and no block time is specified
					(or the block time has expired) so exit now. */
					taskEXIT_CRITICAL();
    1412:	0f 90       	pop	r0
    1414:	0f be       	out	0x3f, r0	; 63
					traceQUEUE_RECEIVE_FAILED( pxQueue );
					return errQUEUE_EMPTY;
    1416:	80 e0       	ldi	r24, 0x00	; 0
    1418:	4a c0       	rjmp	.+148    	; 0x14ae <xQueueSemaphoreTake+0x108>
				}
				else if( xEntryTimeSet == pdFALSE )
    141a:	ff 20       	and	r15, r15
    141c:	29 f4       	brne	.+10     	; 0x1428 <xQueueSemaphoreTake+0x82>
				{
					/* The semaphore count was 0 and a block time was specified
					so configure the timeout structure ready to block. */
					vTaskInternalSetTimeOutState( &xTimeOut );
    141e:	ce 01       	movw	r24, r28
    1420:	01 96       	adiw	r24, 0x01	; 1
    1422:	0e 94 89 11 	call	0x2312	; 0x2312 <vTaskInternalSetTimeOutState>
					xEntryTimeSet = pdTRUE;
    1426:	fe 2c       	mov	r15, r14
					/* Entry time was already set. */
					mtCOVERAGE_TEST_MARKER();
				}
			}
		}
		taskEXIT_CRITICAL();
    1428:	0f 90       	pop	r0
    142a:	0f be       	out	0x3f, r0	; 63

		/* Interrupts and other tasks can give to and take from the semaphore
		now the critical section has been exited. */

		vTaskSuspendAll();
    142c:	0e 94 be 0e 	call	0x1d7c	; 0x1d7c <vTaskSuspendAll>
		prvLockQueue( pxQueue );
    1430:	0f b6       	in	r0, 0x3f	; 63
    1432:	f8 94       	cli
    1434:	0f 92       	push	r0
    1436:	f8 01       	movw	r30, r16
    1438:	85 8d       	ldd	r24, Z+29	; 0x1d
    143a:	8f 3f       	cpi	r24, 0xFF	; 255
    143c:	09 f4       	brne	.+2      	; 0x1440 <xQueueSemaphoreTake+0x9a>
    143e:	15 8e       	std	Z+29, r1	; 0x1d
    1440:	f8 01       	movw	r30, r16
    1442:	86 8d       	ldd	r24, Z+30	; 0x1e
    1444:	8f 3f       	cpi	r24, 0xFF	; 255
    1446:	09 f4       	brne	.+2      	; 0x144a <xQueueSemaphoreTake+0xa4>
    1448:	16 8e       	std	Z+30, r1	; 0x1e
    144a:	0f 90       	pop	r0
    144c:	0f be       	out	0x3f, r0	; 63

		/* Update the timeout state to see if it has expired yet. */
		if( xTaskCheckForTimeOut( &xTimeOut, &xTicksToWait ) == pdFALSE )
    144e:	ce 01       	movw	r24, r28
    1450:	01 96       	adiw	r24, 0x01	; 1
    1452:	be 01       	movw	r22, r28
    1454:	6c 5f       	subi	r22, 0xFC	; 252
    1456:	7f 4f       	sbci	r23, 0xFF	; 255
    1458:	0e 94 94 11 	call	0x2328	; 0x2328 <xTaskCheckForTimeOut>
    145c:	88 23       	and	r24, r24
    145e:	d9 f4       	brne	.+54     	; 0x1496 <xQueueSemaphoreTake+0xf0>
		{
			/* A block time is specified and not expired.  If the semaphore
			count is 0 then enter the Blocked state to wait for a semaphore to
			become available.  As semaphores are implemented with queues the
			queue being empty is equivalent to the semaphore count being 0. */
			if( prvIsQueueEmpty( pxQueue ) != pdFALSE )
    1460:	c8 01       	movw	r24, r16
    1462:	0e 94 f2 06 	call	0xde4	; 0xde4 <prvIsQueueEmpty>
    1466:	88 23       	and	r24, r24
    1468:	81 f0       	breq	.+32     	; 0x148a <xQueueSemaphoreTake+0xe4>
						mtCOVERAGE_TEST_MARKER();
					}
				}
				#endif

				vTaskPlaceOnEventList( &( pxQueue->xTasksWaitingToReceive ), xTicksToWait );
    146a:	6c 81       	ldd	r22, Y+4	; 0x04
    146c:	7d 81       	ldd	r23, Y+5	; 0x05
    146e:	c6 01       	movw	r24, r12
    1470:	0e 94 cb 10 	call	0x2196	; 0x2196 <vTaskPlaceOnEventList>
				prvUnlockQueue( pxQueue );
    1474:	c8 01       	movw	r24, r16
    1476:	0e 94 6f 07 	call	0xede	; 0xede <prvUnlockQueue>
				if( xTaskResumeAll() == pdFALSE )
    147a:	0e 94 9c 0f 	call	0x1f38	; 0x1f38 <xTaskResumeAll>
    147e:	88 23       	and	r24, r24
    1480:	09 f0       	breq	.+2      	; 0x1484 <xQueueSemaphoreTake+0xde>
    1482:	ab cf       	rjmp	.-170    	; 0x13da <xQueueSemaphoreTake+0x34>
				{
					portYIELD_WITHIN_API();
    1484:	0e 94 39 06 	call	0xc72	; 0xc72 <vPortYield>
    1488:	a8 cf       	rjmp	.-176    	; 0x13da <xQueueSemaphoreTake+0x34>
			}
			else
			{
				/* There was no timeout and the semaphore count was not 0, so
				attempt to take the semaphore again. */
				prvUnlockQueue( pxQueue );
    148a:	c8 01       	movw	r24, r16
    148c:	0e 94 6f 07 	call	0xede	; 0xede <prvUnlockQueue>
				( void ) xTaskResumeAll();
    1490:	0e 94 9c 0f 	call	0x1f38	; 0x1f38 <xTaskResumeAll>
    1494:	a2 cf       	rjmp	.-188    	; 0x13da <xQueueSemaphoreTake+0x34>
			}
		}
		else
		{
			/* Timed out. */
			prvUnlockQueue( pxQueue );
    1496:	c8 01       	movw	r24, r16
    1498:	0e 94 6f 07 	call	0xede	; 0xede <prvUnlockQueue>
			( void ) xTaskResumeAll();
    149c:	0e 94 9c 0f 	call	0x1f38	; 0x1f38 <xTaskResumeAll>

			/* If the semaphore count is 0 exit now as the timeout has
			expired.  Otherwise return to attempt to take the semaphore that is
			known to be available.  As semaphores are implemented by queues the
			queue being empty is equivalent to the semaphore count being 0. */
			if( prvIsQueueEmpty( pxQueue ) != pdFALSE )
    14a0:	c8 01       	movw	r24, r16
    14a2:	0e 94 f2 06 	call	0xde4	; 0xde4 <prvIsQueueEmpty>
    14a6:	88 23       	and	r24, r24
    14a8:	09 f4       	brne	.+2      	; 0x14ac <xQueueSemaphoreTake+0x106>
    14aa:	97 cf       	rjmp	.-210    	; 0x13da <xQueueSemaphoreTake+0x34>
					}
				}
				#endif /* configUSE_MUTEXES */

				traceQUEUE_RECEIVE_FAILED( pxQueue );
				return errQUEUE_EMPTY;
    14ac:	80 e0       	ldi	r24, 0x00	; 0
			{
				mtCOVERAGE_TEST_MARKER();
			}
		}
	} /*lint -restore */
}
    14ae:	0f 90       	pop	r0
    14b0:	0f 90       	pop	r0
    14b2:	0f 90       	pop	r0
    14b4:	0f 90       	pop	r0
    14b6:	0f 90       	pop	r0
    14b8:	df 91       	pop	r29
    14ba:	cf 91       	pop	r28
    14bc:	1f 91       	pop	r17
    14be:	0f 91       	pop	r16
    14c0:	ff 90       	pop	r15
    14c2:	ef 90       	pop	r14
    14c4:	df 90       	pop	r13
    14c6:	cf 90       	pop	r12
    14c8:	08 95       	ret

000014ca <xQueuePeek>:
/*-----------------------------------------------------------*/

BaseType_t xQueuePeek( QueueHandle_t xQueue, void * const pvBuffer, TickType_t xTicksToWait )
{
    14ca:	af 92       	push	r10
    14cc:	bf 92       	push	r11
    14ce:	cf 92       	push	r12
    14d0:	df 92       	push	r13
    14d2:	ef 92       	push	r14
    14d4:	ff 92       	push	r15
    14d6:	0f 93       	push	r16
    14d8:	1f 93       	push	r17
    14da:	cf 93       	push	r28
    14dc:	df 93       	push	r29
    14de:	00 d0       	rcall	.+0      	; 0x14e0 <xQueuePeek+0x16>
    14e0:	00 d0       	rcall	.+0      	; 0x14e2 <xQueuePeek+0x18>
    14e2:	0f 92       	push	r0
    14e4:	cd b7       	in	r28, 0x3d	; 61
    14e6:	de b7       	in	r29, 0x3e	; 62
    14e8:	8c 01       	movw	r16, r24
    14ea:	5b 01       	movw	r10, r22
    14ec:	5d 83       	std	Y+5, r21	; 0x05
    14ee:	4c 83       	std	Y+4, r20	; 0x04
BaseType_t xEntryTimeSet = pdFALSE;
    14f0:	ff 24       	eor	r15, r15
				{
					/* The queue was empty and a block time was specified so
					configure the timeout structure ready to enter the blocked
					state. */
					vTaskInternalSetTimeOutState( &xTimeOut );
					xEntryTimeSet = pdTRUE;
    14f2:	ee 24       	eor	r14, r14
    14f4:	e3 94       	inc	r14
			/* Timeout has not expired yet, check to see if there is data in the
			queue now, and if not enter the Blocked state to wait for data. */
			if( prvIsQueueEmpty( pxQueue ) != pdFALSE )
			{
				traceBLOCKING_ON_QUEUE_PEEK( pxQueue );
				vTaskPlaceOnEventList( &( pxQueue->xTasksWaitingToReceive ), xTicksToWait );
    14f6:	0f 2e       	mov	r0, r31
    14f8:	f1 e1       	ldi	r31, 0x11	; 17
    14fa:	cf 2e       	mov	r12, r31
    14fc:	dd 24       	eor	r13, r13
    14fe:	f0 2d       	mov	r31, r0
    1500:	c8 0e       	add	r12, r24
    1502:	d9 1e       	adc	r13, r25
	/*lint -save -e904  This function relaxes the coding standard somewhat to
	allow return statements within the function itself.  This is done in the
	interest of execution time efficiency. */
	for( ;; )
	{
		taskENTER_CRITICAL();
    1504:	0f b6       	in	r0, 0x3f	; 63
    1506:	f8 94       	cli
    1508:	0f 92       	push	r0
		{
			const UBaseType_t uxMessagesWaiting = pxQueue->uxMessagesWaiting;
    150a:	f8 01       	movw	r30, r16
    150c:	82 8d       	ldd	r24, Z+26	; 0x1a

			/* Is there data in the queue now?  To be running the calling task
			must be the highest priority task wanting to access the queue. */
			if( uxMessagesWaiting > ( UBaseType_t ) 0 )
    150e:	88 23       	and	r24, r24
    1510:	c1 f0       	breq	.+48     	; 0x1542 <xQueuePeek+0x78>
			{
				/* Remember the read position so it can be reset after the data
				is read from the queue as this function is only peeking the
				data, not removing it. */
				pcOriginalReadPosition = pxQueue->u.xQueue.pcReadFrom;
    1512:	e6 80       	ldd	r14, Z+6	; 0x06
    1514:	f7 80       	ldd	r15, Z+7	; 0x07

				prvCopyDataFromQueue( pxQueue, pvBuffer );
    1516:	c8 01       	movw	r24, r16
    1518:	b5 01       	movw	r22, r10
    151a:	0e 94 52 07 	call	0xea4	; 0xea4 <prvCopyDataFromQueue>
				traceQUEUE_PEEK( pxQueue );

				/* The data is not being removed, so reset the read pointer. */
				pxQueue->u.xQueue.pcReadFrom = pcOriginalReadPosition;
    151e:	f8 01       	movw	r30, r16
    1520:	f7 82       	std	Z+7, r15	; 0x07
    1522:	e6 82       	std	Z+6, r14	; 0x06

				/* The data is being left in the queue, so see if there are
				any other tasks waiting for the data. */
				if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
    1524:	81 89       	ldd	r24, Z+17	; 0x11
    1526:	88 23       	and	r24, r24
    1528:	41 f0       	breq	.+16     	; 0x153a <xQueuePeek+0x70>
				{
					if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
    152a:	c8 01       	movw	r24, r16
    152c:	41 96       	adiw	r24, 0x11	; 17
    152e:	0e 94 f6 10 	call	0x21ec	; 0x21ec <xTaskRemoveFromEventList>
    1532:	88 23       	and	r24, r24
    1534:	11 f0       	breq	.+4      	; 0x153a <xQueuePeek+0x70>
					{
						/* The task waiting has a higher priority than this task. */
						queueYIELD_IF_USING_PREEMPTION();
    1536:	0e 94 39 06 	call	0xc72	; 0xc72 <vPortYield>
				else
				{
					mtCOVERAGE_TEST_MARKER();
				}

				taskEXIT_CRITICAL();
    153a:	0f 90       	pop	r0
    153c:	0f be       	out	0x3f, r0	; 63
				return pdPASS;
    153e:	81 e0       	ldi	r24, 0x01	; 1
    1540:	52 c0       	rjmp	.+164    	; 0x15e6 <xQueuePeek+0x11c>
			}
			else
			{
				if( xTicksToWait == ( TickType_t ) 0 )
    1542:	8c 81       	ldd	r24, Y+4	; 0x04
    1544:	9d 81       	ldd	r25, Y+5	; 0x05
    1546:	00 97       	sbiw	r24, 0x00	; 0
    1548:	21 f4       	brne	.+8      	; 0x1552 <xQueuePeek+0x88>
				{
					/* The queue was empty and no block time is specified (or
					the block time has expired) so leave now. */
					taskEXIT_CRITICAL();
    154a:	0f 90       	pop	r0
    154c:	0f be       	out	0x3f, r0	; 63
					traceQUEUE_PEEK_FAILED( pxQueue );
					return errQUEUE_EMPTY;
    154e:	80 e0       	ldi	r24, 0x00	; 0
    1550:	4a c0       	rjmp	.+148    	; 0x15e6 <xQueuePeek+0x11c>
				}
				else if( xEntryTimeSet == pdFALSE )
    1552:	ff 20       	and	r15, r15
    1554:	29 f4       	brne	.+10     	; 0x1560 <xQueuePeek+0x96>
				{
					/* The queue was empty and a block time was specified so
					configure the timeout structure ready to enter the blocked
					state. */
					vTaskInternalSetTimeOutState( &xTimeOut );
    1556:	ce 01       	movw	r24, r28
    1558:	01 96       	adiw	r24, 0x01	; 1
    155a:	0e 94 89 11 	call	0x2312	; 0x2312 <vTaskInternalSetTimeOutState>
					xEntryTimeSet = pdTRUE;
    155e:	fe 2c       	mov	r15, r14
					/* Entry time was already set. */
					mtCOVERAGE_TEST_MARKER();
				}
			}
		}
		taskEXIT_CRITICAL();
    1560:	0f 90       	pop	r0
    1562:	0f be       	out	0x3f, r0	; 63

		/* Interrupts and other tasks can send to and receive from the queue
		now the critical section has been exited. */

		vTaskSuspendAll();
    1564:	0e 94 be 0e 	call	0x1d7c	; 0x1d7c <vTaskSuspendAll>
		prvLockQueue( pxQueue );
    1568:	0f b6       	in	r0, 0x3f	; 63
    156a:	f8 94       	cli
    156c:	0f 92       	push	r0
    156e:	f8 01       	movw	r30, r16
    1570:	85 8d       	ldd	r24, Z+29	; 0x1d
    1572:	8f 3f       	cpi	r24, 0xFF	; 255
    1574:	09 f4       	brne	.+2      	; 0x1578 <xQueuePeek+0xae>
    1576:	15 8e       	std	Z+29, r1	; 0x1d
    1578:	f8 01       	movw	r30, r16
    157a:	86 8d       	ldd	r24, Z+30	; 0x1e
    157c:	8f 3f       	cpi	r24, 0xFF	; 255
    157e:	09 f4       	brne	.+2      	; 0x1582 <xQueuePeek+0xb8>
    1580:	16 8e       	std	Z+30, r1	; 0x1e
    1582:	0f 90       	pop	r0
    1584:	0f be       	out	0x3f, r0	; 63

		/* Update the timeout state to see if it has expired yet. */
		if( xTaskCheckForTimeOut( &xTimeOut, &xTicksToWait ) == pdFALSE )
    1586:	ce 01       	movw	r24, r28
    1588:	01 96       	adiw	r24, 0x01	; 1
    158a:	be 01       	movw	r22, r28
    158c:	6c 5f       	subi	r22, 0xFC	; 252
    158e:	7f 4f       	sbci	r23, 0xFF	; 255
    1590:	0e 94 94 11 	call	0x2328	; 0x2328 <xTaskCheckForTimeOut>
    1594:	88 23       	and	r24, r24
    1596:	d9 f4       	brne	.+54     	; 0x15ce <xQueuePeek+0x104>
		{
			/* Timeout has not expired yet, check to see if there is data in the
			queue now, and if not enter the Blocked state to wait for data. */
			if( prvIsQueueEmpty( pxQueue ) != pdFALSE )
    1598:	c8 01       	movw	r24, r16
    159a:	0e 94 f2 06 	call	0xde4	; 0xde4 <prvIsQueueEmpty>
    159e:	88 23       	and	r24, r24
    15a0:	81 f0       	breq	.+32     	; 0x15c2 <xQueuePeek+0xf8>
			{
				traceBLOCKING_ON_QUEUE_PEEK( pxQueue );
				vTaskPlaceOnEventList( &( pxQueue->xTasksWaitingToReceive ), xTicksToWait );
    15a2:	6c 81       	ldd	r22, Y+4	; 0x04
    15a4:	7d 81       	ldd	r23, Y+5	; 0x05
    15a6:	c6 01       	movw	r24, r12
    15a8:	0e 94 cb 10 	call	0x2196	; 0x2196 <vTaskPlaceOnEventList>
				prvUnlockQueue( pxQueue );
    15ac:	c8 01       	movw	r24, r16
    15ae:	0e 94 6f 07 	call	0xede	; 0xede <prvUnlockQueue>
				if( xTaskResumeAll() == pdFALSE )
    15b2:	0e 94 9c 0f 	call	0x1f38	; 0x1f38 <xTaskResumeAll>
    15b6:	88 23       	and	r24, r24
    15b8:	09 f0       	breq	.+2      	; 0x15bc <xQueuePeek+0xf2>
    15ba:	a4 cf       	rjmp	.-184    	; 0x1504 <xQueuePeek+0x3a>
				{
					portYIELD_WITHIN_API();
    15bc:	0e 94 39 06 	call	0xc72	; 0xc72 <vPortYield>
    15c0:	a1 cf       	rjmp	.-190    	; 0x1504 <xQueuePeek+0x3a>
			}
			else
			{
				/* There is data in the queue now, so don't enter the blocked
				state, instead return to try and obtain the data. */
				prvUnlockQueue( pxQueue );
    15c2:	c8 01       	movw	r24, r16
    15c4:	0e 94 6f 07 	call	0xede	; 0xede <prvUnlockQueue>
				( void ) xTaskResumeAll();
    15c8:	0e 94 9c 0f 	call	0x1f38	; 0x1f38 <xTaskResumeAll>
    15cc:	9b cf       	rjmp	.-202    	; 0x1504 <xQueuePeek+0x3a>
		}
		else
		{
			/* The timeout has expired.  If there is still no data in the queue
			exit, otherwise go back and try to read the data again. */
			prvUnlockQueue( pxQueue );
    15ce:	c8 01       	movw	r24, r16
    15d0:	0e 94 6f 07 	call	0xede	; 0xede <prvUnlockQueue>
			( void ) xTaskResumeAll();
    15d4:	0e 94 9c 0f 	call	0x1f38	; 0x1f38 <xTaskResumeAll>

			if( prvIsQueueEmpty( pxQueue ) != pdFALSE )
    15d8:	c8 01       	movw	r24, r16
    15da:	0e 94 f2 06 	call	0xde4	; 0xde4 <prvIsQueueEmpty>
    15de:	88 23       	and	r24, r24
    15e0:	09 f4       	brne	.+2      	; 0x15e4 <xQueuePeek+0x11a>
    15e2:	90 cf       	rjmp	.-224    	; 0x1504 <xQueuePeek+0x3a>
			{
				traceQUEUE_PEEK_FAILED( pxQueue );
				return errQUEUE_EMPTY;
    15e4:	80 e0       	ldi	r24, 0x00	; 0
			{
				mtCOVERAGE_TEST_MARKER();
			}
		}
	} /*lint -restore */
}
    15e6:	0f 90       	pop	r0
    15e8:	0f 90       	pop	r0
    15ea:	0f 90       	pop	r0
    15ec:	0f 90       	pop	r0
    15ee:	0f 90       	pop	r0
    15f0:	df 91       	pop	r29
    15f2:	cf 91       	pop	r28
    15f4:	1f 91       	pop	r17
    15f6:	0f 91       	pop	r16
    15f8:	ff 90       	pop	r15
    15fa:	ef 90       	pop	r14
    15fc:	df 90       	pop	r13
    15fe:	cf 90       	pop	r12
    1600:	bf 90       	pop	r11
    1602:	af 90       	pop	r10
    1604:	08 95       	ret

00001606 <xQueueReceiveFromISR>:
/*-----------------------------------------------------------*/

BaseType_t xQueueReceiveFromISR( QueueHandle_t xQueue, void * const pvBuffer, BaseType_t * const pxHigherPriorityTaskWoken )
{
    1606:	ef 92       	push	r14
    1608:	ff 92       	push	r15
    160a:	0f 93       	push	r16
    160c:	1f 93       	push	r17
    160e:	cf 93       	push	r28
    1610:	df 93       	push	r29
    1612:	8c 01       	movw	r16, r24
    1614:	7a 01       	movw	r14, r20
	link: http://www.freertos.org/RTOS-Cortex-M3-M4.html */
	portASSERT_IF_INTERRUPT_PRIORITY_INVALID();

	uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
	{
		const UBaseType_t uxMessagesWaiting = pxQueue->uxMessagesWaiting;
    1616:	fc 01       	movw	r30, r24
    1618:	c2 8d       	ldd	r28, Z+26	; 0x1a

		/* Cannot block in an ISR, so check there is data available. */
		if( uxMessagesWaiting > ( UBaseType_t ) 0 )
    161a:	cc 23       	and	r28, r28
    161c:	e9 f0       	breq	.+58     	; 0x1658 <xQueueReceiveFromISR+0x52>
		{
			const int8_t cRxLock = pxQueue->cRxLock;
    161e:	d5 8d       	ldd	r29, Z+29	; 0x1d

			traceQUEUE_RECEIVE_FROM_ISR( pxQueue );

			prvCopyDataFromQueue( pxQueue, pvBuffer );
    1620:	0e 94 52 07 	call	0xea4	; 0xea4 <prvCopyDataFromQueue>
			pxQueue->uxMessagesWaiting = uxMessagesWaiting - ( UBaseType_t ) 1;
    1624:	c1 50       	subi	r28, 0x01	; 1
    1626:	f8 01       	movw	r30, r16
    1628:	c2 8f       	std	Z+26, r28	; 0x1a

			/* If the queue is locked the event list will not be modified.
			Instead update the lock count so the task that unlocks the queue
			will know that an ISR has removed data while the queue was
			locked. */
			if( cRxLock == queueUNLOCKED )
    162a:	df 3f       	cpi	r29, 0xFF	; 255
    162c:	81 f4       	brne	.+32     	; 0x164e <xQueueReceiveFromISR+0x48>
			{
				if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )
    162e:	80 85       	ldd	r24, Z+8	; 0x08
    1630:	88 23       	and	r24, r24
    1632:	a1 f0       	breq	.+40     	; 0x165c <xQueueReceiveFromISR+0x56>
				{
					if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )
    1634:	c8 01       	movw	r24, r16
    1636:	08 96       	adiw	r24, 0x08	; 8
    1638:	0e 94 f6 10 	call	0x21ec	; 0x21ec <xTaskRemoveFromEventList>
    163c:	88 23       	and	r24, r24
    163e:	81 f0       	breq	.+32     	; 0x1660 <xQueueReceiveFromISR+0x5a>
					{
						/* The task waiting has a higher priority than us so
						force a context switch. */
						if( pxHigherPriorityTaskWoken != NULL )
    1640:	e1 14       	cp	r14, r1
    1642:	f1 04       	cpc	r15, r1
    1644:	79 f0       	breq	.+30     	; 0x1664 <xQueueReceiveFromISR+0x5e>
						{
							*pxHigherPriorityTaskWoken = pdTRUE;
    1646:	81 e0       	ldi	r24, 0x01	; 1
    1648:	f7 01       	movw	r30, r14
    164a:	80 83       	st	Z, r24
    164c:	0c c0       	rjmp	.+24     	; 0x1666 <xQueueReceiveFromISR+0x60>
			}
			else
			{
				/* Increment the lock count so the task that unlocks the queue
				knows that data was removed while it was locked. */
				pxQueue->cRxLock = ( int8_t ) ( cRxLock + 1 );
    164e:	df 5f       	subi	r29, 0xFF	; 255
    1650:	f8 01       	movw	r30, r16
    1652:	d5 8f       	std	Z+29, r29	; 0x1d
			}

			xReturn = pdPASS;
    1654:	81 e0       	ldi	r24, 0x01	; 1
    1656:	07 c0       	rjmp	.+14     	; 0x1666 <xQueueReceiveFromISR+0x60>
		}
		else
		{
			xReturn = pdFAIL;
    1658:	80 e0       	ldi	r24, 0x00	; 0
    165a:	05 c0       	rjmp	.+10     	; 0x1666 <xQueueReceiveFromISR+0x60>
				/* Increment the lock count so the task that unlocks the queue
				knows that data was removed while it was locked. */
				pxQueue->cRxLock = ( int8_t ) ( cRxLock + 1 );
			}

			xReturn = pdPASS;
    165c:	81 e0       	ldi	r24, 0x01	; 1
    165e:	03 c0       	rjmp	.+6      	; 0x1666 <xQueueReceiveFromISR+0x60>
    1660:	81 e0       	ldi	r24, 0x01	; 1
    1662:	01 c0       	rjmp	.+2      	; 0x1666 <xQueueReceiveFromISR+0x60>
    1664:	81 e0       	ldi	r24, 0x01	; 1
		}
	}
	portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );

	return xReturn;
}
    1666:	df 91       	pop	r29
    1668:	cf 91       	pop	r28
    166a:	1f 91       	pop	r17
    166c:	0f 91       	pop	r16
    166e:	ff 90       	pop	r15
    1670:	ef 90       	pop	r14
    1672:	08 95       	ret

00001674 <xQueuePeekFromISR>:
/*-----------------------------------------------------------*/

BaseType_t xQueuePeekFromISR( QueueHandle_t xQueue,  void * const pvBuffer )
{
    1674:	0f 93       	push	r16
    1676:	1f 93       	push	r17
    1678:	cf 93       	push	r28
    167a:	df 93       	push	r29
    167c:	ec 01       	movw	r28, r24
	portASSERT_IF_INTERRUPT_PRIORITY_INVALID();

	uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
	{
		/* Cannot block in an ISR, so check there is data available. */
		if( pxQueue->uxMessagesWaiting > ( UBaseType_t ) 0 )
    167e:	8a 8d       	ldd	r24, Y+26	; 0x1a
    1680:	88 23       	and	r24, r24
    1682:	49 f0       	breq	.+18     	; 0x1696 <xQueuePeekFromISR+0x22>
		{
			traceQUEUE_PEEK_FROM_ISR( pxQueue );

			/* Remember the read position so it can be reset as nothing is
			actually being removed from the queue. */
			pcOriginalReadPosition = pxQueue->u.xQueue.pcReadFrom;
    1684:	0e 81       	ldd	r16, Y+6	; 0x06
    1686:	1f 81       	ldd	r17, Y+7	; 0x07
			prvCopyDataFromQueue( pxQueue, pvBuffer );
    1688:	ce 01       	movw	r24, r28
    168a:	0e 94 52 07 	call	0xea4	; 0xea4 <prvCopyDataFromQueue>
			pxQueue->u.xQueue.pcReadFrom = pcOriginalReadPosition;
    168e:	1f 83       	std	Y+7, r17	; 0x07
    1690:	0e 83       	std	Y+6, r16	; 0x06

			xReturn = pdPASS;
    1692:	81 e0       	ldi	r24, 0x01	; 1
    1694:	01 c0       	rjmp	.+2      	; 0x1698 <xQueuePeekFromISR+0x24>
		}
		else
		{
			xReturn = pdFAIL;
    1696:	80 e0       	ldi	r24, 0x00	; 0
		}
	}
	portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );

	return xReturn;
}
    1698:	df 91       	pop	r29
    169a:	cf 91       	pop	r28
    169c:	1f 91       	pop	r17
    169e:	0f 91       	pop	r16
    16a0:	08 95       	ret

000016a2 <uxQueueMessagesWaiting>:
{
UBaseType_t uxReturn;

	configASSERT( xQueue );

	taskENTER_CRITICAL();
    16a2:	0f b6       	in	r0, 0x3f	; 63
    16a4:	f8 94       	cli
    16a6:	0f 92       	push	r0
	{
		uxReturn = ( ( Queue_t * ) xQueue )->uxMessagesWaiting;
    16a8:	fc 01       	movw	r30, r24
    16aa:	82 8d       	ldd	r24, Z+26	; 0x1a
	}
	taskEXIT_CRITICAL();
    16ac:	0f 90       	pop	r0
    16ae:	0f be       	out	0x3f, r0	; 63

	return uxReturn;
} /*lint !e818 Pointer cannot be declared const as xQueue is a typedef not pointer. */
    16b0:	08 95       	ret

000016b2 <uxQueueSpacesAvailable>:
/*-----------------------------------------------------------*/

UBaseType_t uxQueueSpacesAvailable( const QueueHandle_t xQueue )
{
    16b2:	fc 01       	movw	r30, r24
UBaseType_t uxReturn;
Queue_t * const pxQueue = xQueue;

	configASSERT( pxQueue );

	taskENTER_CRITICAL();
    16b4:	0f b6       	in	r0, 0x3f	; 63
    16b6:	f8 94       	cli
    16b8:	0f 92       	push	r0
	{
		uxReturn = pxQueue->uxLength - pxQueue->uxMessagesWaiting;
    16ba:	92 8d       	ldd	r25, Z+26	; 0x1a
	}
	taskEXIT_CRITICAL();
    16bc:	0f 90       	pop	r0
    16be:	0f be       	out	0x3f, r0	; 63

	configASSERT( pxQueue );

	taskENTER_CRITICAL();
	{
		uxReturn = pxQueue->uxLength - pxQueue->uxMessagesWaiting;
    16c0:	83 8d       	ldd	r24, Z+27	; 0x1b
	}
	taskEXIT_CRITICAL();

	return uxReturn;
} /*lint !e818 Pointer cannot be declared const as xQueue is a typedef not pointer. */
    16c2:	89 1b       	sub	r24, r25
    16c4:	08 95       	ret

000016c6 <uxQueueMessagesWaitingFromISR>:
{
UBaseType_t uxReturn;
Queue_t * const pxQueue = xQueue;

	configASSERT( pxQueue );
	uxReturn = pxQueue->uxMessagesWaiting;
    16c6:	fc 01       	movw	r30, r24
    16c8:	82 8d       	ldd	r24, Z+26	; 0x1a

	return uxReturn;
} /*lint !e818 Pointer cannot be declared const as xQueue is a typedef not pointer. */
    16ca:	08 95       	ret

000016cc <vQueueDelete>:

	#if( ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) && ( configSUPPORT_STATIC_ALLOCATION == 0 ) )
	{
		/* The queue can only have been allocated dynamically - free it
		again. */
		vPortFree( pxQueue );
    16cc:	0e 94 ae 04 	call	0x95c	; 0x95c <vPortFree>
		/* The queue must have been statically allocated, so is not going to be
		deleted.  Avoid compiler warnings about the unused parameter. */
		( void ) pxQueue;
	}
	#endif /* configSUPPORT_DYNAMIC_ALLOCATION */
}
    16d0:	08 95       	ret

000016d2 <xQueueIsQueueEmptyFromISR>:
{
BaseType_t xReturn;
Queue_t * const pxQueue = xQueue;

	configASSERT( pxQueue );
	if( pxQueue->uxMessagesWaiting == ( UBaseType_t ) 0 )
    16d2:	fc 01       	movw	r30, r24
    16d4:	92 8d       	ldd	r25, Z+26	; 0x1a
	{
		xReturn = pdTRUE;
    16d6:	81 e0       	ldi	r24, 0x01	; 1
    16d8:	91 11       	cpse	r25, r1
    16da:	80 e0       	ldi	r24, 0x00	; 0
	{
		xReturn = pdFALSE;
	}

	return xReturn;
} /*lint !e818 xQueue could not be pointer to const because it is a typedef. */
    16dc:	08 95       	ret

000016de <xQueueIsQueueFullFromISR>:
	return xReturn;
}
/*-----------------------------------------------------------*/

BaseType_t xQueueIsQueueFullFromISR( const QueueHandle_t xQueue )
{
    16de:	fc 01       	movw	r30, r24
BaseType_t xReturn;
Queue_t * const pxQueue = xQueue;

	configASSERT( pxQueue );
	if( pxQueue->uxMessagesWaiting == pxQueue->uxLength )
    16e0:	22 8d       	ldd	r18, Z+26	; 0x1a
	{
		xReturn = pdTRUE;
    16e2:	81 e0       	ldi	r24, 0x01	; 1
    16e4:	93 8d       	ldd	r25, Z+27	; 0x1b
    16e6:	29 13       	cpse	r18, r25
    16e8:	80 e0       	ldi	r24, 0x00	; 0
	{
		xReturn = pdFALSE;
	}

	return xReturn;
} /*lint !e818 xQueue could not be pointer to const because it is a typedef. */
    16ea:	08 95       	ret

000016ec <xQueueCRSend>:
/*-----------------------------------------------------------*/

#if ( configUSE_CO_ROUTINES == 1 )

	BaseType_t xQueueCRSend( QueueHandle_t xQueue, const void *pvItemToQueue, TickType_t xTicksToWait )
	{
    16ec:	ef 92       	push	r14
    16ee:	ff 92       	push	r15
    16f0:	0f 93       	push	r16
    16f2:	1f 93       	push	r17
    16f4:	cf 93       	push	r28
    16f6:	df 93       	push	r29
    16f8:	ec 01       	movw	r28, r24
    16fa:	7b 01       	movw	r14, r22
    16fc:	8a 01       	movw	r16, r20
	Queue_t * const pxQueue = xQueue;

		/* If the queue is already full we may have to block.  A critical section
		is required to prevent an interrupt removing something from the queue
		between the check to see if the queue is full and blocking on the queue. */
		portDISABLE_INTERRUPTS();
    16fe:	f8 94       	cli
		{
			if( prvIsQueueFull( pxQueue ) != pdFALSE )
    1700:	0e 94 fd 06 	call	0xdfa	; 0xdfa <prvIsQueueFull>
    1704:	88 23       	and	r24, r24
    1706:	79 f0       	breq	.+30     	; 0x1726 <xQueueCRSend+0x3a>
			{
				/* The queue is full - do we want to block or just leave without
				posting? */
				if( xTicksToWait > ( TickType_t ) 0 )
    1708:	01 15       	cp	r16, r1
    170a:	11 05       	cpc	r17, r1
    170c:	49 f0       	breq	.+18     	; 0x1720 <xQueueCRSend+0x34>
				{
					/* As this is called from a coroutine we cannot block directly, but
					return indicating that we need to block. */
					vCoRoutineAddToDelayedList( xTicksToWait, &( pxQueue->xTasksWaitingToSend ) );
    170e:	be 01       	movw	r22, r28
    1710:	68 5f       	subi	r22, 0xF8	; 248
    1712:	7f 4f       	sbci	r23, 0xFF	; 255
    1714:	c8 01       	movw	r24, r16
    1716:	0e 94 cc 00 	call	0x198	; 0x198 <vCoRoutineAddToDelayedList>
					portENABLE_INTERRUPTS();
    171a:	78 94       	sei
					return errQUEUE_BLOCKED;
    171c:	8c ef       	ldi	r24, 0xFC	; 252
    171e:	1f c0       	rjmp	.+62     	; 0x175e <xQueueCRSend+0x72>
				}
				else
				{
					portENABLE_INTERRUPTS();
    1720:	78 94       	sei
					return errQUEUE_FULL;
    1722:	80 e0       	ldi	r24, 0x00	; 0
    1724:	1c c0       	rjmp	.+56     	; 0x175e <xQueueCRSend+0x72>
				}
			}
		}
		portENABLE_INTERRUPTS();
    1726:	78 94       	sei

		portDISABLE_INTERRUPTS();
    1728:	f8 94       	cli
		{
			if( pxQueue->uxMessagesWaiting < pxQueue->uxLength )
    172a:	9a 8d       	ldd	r25, Y+26	; 0x1a
    172c:	8b 8d       	ldd	r24, Y+27	; 0x1b
    172e:	98 17       	cp	r25, r24
    1730:	80 f4       	brcc	.+32     	; 0x1752 <xQueueCRSend+0x66>
			{
				/* There is room in the queue, copy the data into the queue. */
				prvCopyDataToQueue( pxQueue, pvItemToQueue, queueSEND_TO_BACK );
    1732:	ce 01       	movw	r24, r28
    1734:	b7 01       	movw	r22, r14
    1736:	40 e0       	ldi	r20, 0x00	; 0
    1738:	0e 94 09 07 	call	0xe12	; 0xe12 <prvCopyDataToQueue>
				xReturn = pdPASS;

				/* Were any co-routines waiting for data to become available? */
				if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
    173c:	89 89       	ldd	r24, Y+17	; 0x11
    173e:	88 23       	and	r24, r24
    1740:	51 f0       	breq	.+20     	; 0x1756 <xQueueCRSend+0x6a>
				{
					/* In this instance the co-routine could be placed directly
					into the ready list as we are within a critical section.
					Instead the same pending ready list mechanism is used as if
					the event were caused from within an interrupt. */
					if( xCoRoutineRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
    1742:	ce 01       	movw	r24, r28
    1744:	41 96       	adiw	r24, 0x11	; 17
    1746:	0e 94 3e 02 	call	0x47c	; 0x47c <xCoRoutineRemoveFromEventList>
    174a:	88 23       	and	r24, r24
    174c:	31 f4       	brne	.+12     	; 0x175a <xQueueCRSend+0x6e>
		{
			if( pxQueue->uxMessagesWaiting < pxQueue->uxLength )
			{
				/* There is room in the queue, copy the data into the queue. */
				prvCopyDataToQueue( pxQueue, pvItemToQueue, queueSEND_TO_BACK );
				xReturn = pdPASS;
    174e:	81 e0       	ldi	r24, 0x01	; 1
    1750:	05 c0       	rjmp	.+10     	; 0x175c <xQueueCRSend+0x70>
					mtCOVERAGE_TEST_MARKER();
				}
			}
			else
			{
				xReturn = errQUEUE_FULL;
    1752:	80 e0       	ldi	r24, 0x00	; 0
    1754:	03 c0       	rjmp	.+6      	; 0x175c <xQueueCRSend+0x70>
		{
			if( pxQueue->uxMessagesWaiting < pxQueue->uxLength )
			{
				/* There is room in the queue, copy the data into the queue. */
				prvCopyDataToQueue( pxQueue, pvItemToQueue, queueSEND_TO_BACK );
				xReturn = pdPASS;
    1756:	81 e0       	ldi	r24, 0x01	; 1
    1758:	01 c0       	rjmp	.+2      	; 0x175c <xQueueCRSend+0x70>
					the event were caused from within an interrupt. */
					if( xCoRoutineRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
					{
						/* The co-routine waiting has a higher priority so record
						that a yield might be appropriate. */
						xReturn = errQUEUE_YIELD;
    175a:	8b ef       	ldi	r24, 0xFB	; 251
			else
			{
				xReturn = errQUEUE_FULL;
			}
		}
		portENABLE_INTERRUPTS();
    175c:	78 94       	sei

		return xReturn;
	}
    175e:	df 91       	pop	r29
    1760:	cf 91       	pop	r28
    1762:	1f 91       	pop	r17
    1764:	0f 91       	pop	r16
    1766:	ff 90       	pop	r15
    1768:	ef 90       	pop	r14
    176a:	08 95       	ret

0000176c <xQueueCRReceive>:
/*-----------------------------------------------------------*/

#if ( configUSE_CO_ROUTINES == 1 )

	BaseType_t xQueueCRReceive( QueueHandle_t xQueue, void *pvBuffer, TickType_t xTicksToWait )
	{
    176c:	cf 93       	push	r28
    176e:	df 93       	push	r29
    1770:	ec 01       	movw	r28, r24
	Queue_t * const pxQueue = xQueue;

		/* If the queue is already empty we may have to block.  A critical section
		is required to prevent an interrupt adding something to the queue
		between the check to see if the queue is empty and blocking on the queue. */
		portDISABLE_INTERRUPTS();
    1772:	f8 94       	cli
		{
			if( pxQueue->uxMessagesWaiting == ( UBaseType_t ) 0 )
    1774:	8a 8d       	ldd	r24, Y+26	; 0x1a
    1776:	88 23       	and	r24, r24
    1778:	79 f4       	brne	.+30     	; 0x1798 <xQueueCRReceive+0x2c>
			{
				/* There are no messages in the queue, do we want to block or just
				leave with nothing? */
				if( xTicksToWait > ( TickType_t ) 0 )
    177a:	41 15       	cp	r20, r1
    177c:	51 05       	cpc	r21, r1
    177e:	49 f0       	breq	.+18     	; 0x1792 <xQueueCRReceive+0x26>
				{
					/* As this is a co-routine we cannot block directly, but return
					indicating that we need to block. */
					vCoRoutineAddToDelayedList( xTicksToWait, &( pxQueue->xTasksWaitingToReceive ) );
    1780:	be 01       	movw	r22, r28
    1782:	6f 5e       	subi	r22, 0xEF	; 239
    1784:	7f 4f       	sbci	r23, 0xFF	; 255
    1786:	ca 01       	movw	r24, r20
    1788:	0e 94 cc 00 	call	0x198	; 0x198 <vCoRoutineAddToDelayedList>
					portENABLE_INTERRUPTS();
    178c:	78 94       	sei
					return errQUEUE_BLOCKED;
    178e:	8c ef       	ldi	r24, 0xFC	; 252
    1790:	35 c0       	rjmp	.+106    	; 0x17fc <xQueueCRReceive+0x90>
				}
				else
				{
					portENABLE_INTERRUPTS();
    1792:	78 94       	sei
					return errQUEUE_FULL;
    1794:	80 e0       	ldi	r24, 0x00	; 0
    1796:	32 c0       	rjmp	.+100    	; 0x17fc <xQueueCRReceive+0x90>
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}
		}
		portENABLE_INTERRUPTS();
    1798:	78 94       	sei

		portDISABLE_INTERRUPTS();
    179a:	f8 94       	cli
		{
			if( pxQueue->uxMessagesWaiting > ( UBaseType_t ) 0 )
    179c:	8a 8d       	ldd	r24, Y+26	; 0x1a
    179e:	88 23       	and	r24, r24
    17a0:	39 f1       	breq	.+78     	; 0x17f0 <xQueueCRReceive+0x84>
			{
				/* Data is available from the queue. */
				pxQueue->u.xQueue.pcReadFrom += pxQueue->uxItemSize;
    17a2:	4c 8d       	ldd	r20, Y+28	; 0x1c
    17a4:	2e 81       	ldd	r18, Y+6	; 0x06
    17a6:	3f 81       	ldd	r19, Y+7	; 0x07
    17a8:	24 0f       	add	r18, r20
    17aa:	31 1d       	adc	r19, r1
    17ac:	3f 83       	std	Y+7, r19	; 0x07
    17ae:	2e 83       	std	Y+6, r18	; 0x06
				if( pxQueue->u.xQueue.pcReadFrom >= pxQueue->u.xQueue.pcTail )
    17b0:	ec 81       	ldd	r30, Y+4	; 0x04
    17b2:	fd 81       	ldd	r31, Y+5	; 0x05
    17b4:	2e 17       	cp	r18, r30
    17b6:	3f 07       	cpc	r19, r31
    17b8:	20 f0       	brcs	.+8      	; 0x17c2 <xQueueCRReceive+0x56>
				{
					pxQueue->u.xQueue.pcReadFrom = pxQueue->pcHead;
    17ba:	88 81       	ld	r24, Y
    17bc:	99 81       	ldd	r25, Y+1	; 0x01
    17be:	9f 83       	std	Y+7, r25	; 0x07
    17c0:	8e 83       	std	Y+6, r24	; 0x06
				}
				else
				{
					mtCOVERAGE_TEST_MARKER();
				}
				--( pxQueue->uxMessagesWaiting );
    17c2:	8a 8d       	ldd	r24, Y+26	; 0x1a
    17c4:	81 50       	subi	r24, 0x01	; 1
    17c6:	8a 8f       	std	Y+26, r24	; 0x1a
				( void ) memcpy( ( void * ) pvBuffer, ( void * ) pxQueue->u.xQueue.pcReadFrom, ( unsigned ) pxQueue->uxItemSize );
    17c8:	3e 81       	ldd	r19, Y+6	; 0x06
    17ca:	2f 81       	ldd	r18, Y+7	; 0x07
    17cc:	86 2f       	mov	r24, r22
    17ce:	97 2f       	mov	r25, r23
    17d0:	63 2f       	mov	r22, r19
    17d2:	72 2f       	mov	r23, r18
    17d4:	50 e0       	ldi	r21, 0x00	; 0
    17d6:	0e 94 30 14 	call	0x2860	; 0x2860 <memcpy>

				xReturn = pdPASS;

				/* Were any co-routines waiting for space to become available? */
				if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )
    17da:	88 85       	ldd	r24, Y+8	; 0x08
    17dc:	88 23       	and	r24, r24
    17de:	51 f0       	breq	.+20     	; 0x17f4 <xQueueCRReceive+0x88>
				{
					/* In this instance the co-routine could be placed directly
					into the ready list as we are within a critical section.
					Instead the same pending ready list mechanism is used as if
					the event were caused from within an interrupt. */
					if( xCoRoutineRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )
    17e0:	ce 01       	movw	r24, r28
    17e2:	08 96       	adiw	r24, 0x08	; 8
    17e4:	0e 94 3e 02 	call	0x47c	; 0x47c <xCoRoutineRemoveFromEventList>
    17e8:	88 23       	and	r24, r24
    17ea:	31 f4       	brne	.+12     	; 0x17f8 <xQueueCRReceive+0x8c>
					mtCOVERAGE_TEST_MARKER();
				}
				--( pxQueue->uxMessagesWaiting );
				( void ) memcpy( ( void * ) pvBuffer, ( void * ) pxQueue->u.xQueue.pcReadFrom, ( unsigned ) pxQueue->uxItemSize );

				xReturn = pdPASS;
    17ec:	81 e0       	ldi	r24, 0x01	; 1
    17ee:	05 c0       	rjmp	.+10     	; 0x17fa <xQueueCRReceive+0x8e>
					mtCOVERAGE_TEST_MARKER();
				}
			}
			else
			{
				xReturn = pdFAIL;
    17f0:	80 e0       	ldi	r24, 0x00	; 0
    17f2:	03 c0       	rjmp	.+6      	; 0x17fa <xQueueCRReceive+0x8e>
					mtCOVERAGE_TEST_MARKER();
				}
				--( pxQueue->uxMessagesWaiting );
				( void ) memcpy( ( void * ) pvBuffer, ( void * ) pxQueue->u.xQueue.pcReadFrom, ( unsigned ) pxQueue->uxItemSize );

				xReturn = pdPASS;
    17f4:	81 e0       	ldi	r24, 0x01	; 1
    17f6:	01 c0       	rjmp	.+2      	; 0x17fa <xQueueCRReceive+0x8e>
					into the ready list as we are within a critical section.
					Instead the same pending ready list mechanism is used as if
					the event were caused from within an interrupt. */
					if( xCoRoutineRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )
					{
						xReturn = errQUEUE_YIELD;
    17f8:	8b ef       	ldi	r24, 0xFB	; 251
			else
			{
				xReturn = pdFAIL;
			}
		}
		portENABLE_INTERRUPTS();
    17fa:	78 94       	sei

		return xReturn;
	}
    17fc:	df 91       	pop	r29
    17fe:	cf 91       	pop	r28
    1800:	08 95       	ret

00001802 <xQueueCRSendFromISR>:
/*-----------------------------------------------------------*/

#if ( configUSE_CO_ROUTINES == 1 )

	BaseType_t xQueueCRSendFromISR( QueueHandle_t xQueue, const void *pvItemToQueue, BaseType_t xCoRoutinePreviouslyWoken )
	{
    1802:	1f 93       	push	r17
    1804:	cf 93       	push	r28
    1806:	df 93       	push	r29
    1808:	ec 01       	movw	r28, r24
    180a:	14 2f       	mov	r17, r20
	Queue_t * const pxQueue = xQueue;

		/* Cannot block within an ISR so if there is no space on the queue then
		exit without doing anything. */
		if( pxQueue->uxMessagesWaiting < pxQueue->uxLength )
    180c:	9a 8d       	ldd	r25, Y+26	; 0x1a
    180e:	8b 8d       	ldd	r24, Y+27	; 0x1b
    1810:	98 17       	cp	r25, r24
    1812:	88 f4       	brcc	.+34     	; 0x1836 <xQueueCRSendFromISR+0x34>
		{
			prvCopyDataToQueue( pxQueue, pvItemToQueue, queueSEND_TO_BACK );
    1814:	ce 01       	movw	r24, r28
    1816:	40 e0       	ldi	r20, 0x00	; 0
    1818:	0e 94 09 07 	call	0xe12	; 0xe12 <prvCopyDataToQueue>

			/* We only want to wake one co-routine per ISR, so check that a
			co-routine has not already been woken. */
			if( xCoRoutinePreviouslyWoken == pdFALSE )
    181c:	11 23       	and	r17, r17
    181e:	59 f4       	brne	.+22     	; 0x1836 <xQueueCRSendFromISR+0x34>
			{
				if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
    1820:	89 89       	ldd	r24, Y+17	; 0x11
    1822:	88 23       	and	r24, r24
    1824:	41 f0       	breq	.+16     	; 0x1836 <xQueueCRSendFromISR+0x34>
				{
					if( xCoRoutineRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
    1826:	ce 01       	movw	r24, r28
    1828:	41 96       	adiw	r24, 0x11	; 17
    182a:	0e 94 3e 02 	call	0x47c	; 0x47c <xCoRoutineRemoveFromEventList>
#endif /* configUSE_CO_ROUTINES */
/*-----------------------------------------------------------*/

#if ( configUSE_CO_ROUTINES == 1 )

	BaseType_t xQueueCRSendFromISR( QueueHandle_t xQueue, const void *pvItemToQueue, BaseType_t xCoRoutinePreviouslyWoken )
    182e:	11 e0       	ldi	r17, 0x01	; 1
    1830:	88 23       	and	r24, r24
    1832:	09 f4       	brne	.+2      	; 0x1836 <xQueueCRSendFromISR+0x34>
    1834:	10 e0       	ldi	r17, 0x00	; 0
		{
			mtCOVERAGE_TEST_MARKER();
		}

		return xCoRoutinePreviouslyWoken;
	}
    1836:	81 2f       	mov	r24, r17
    1838:	df 91       	pop	r29
    183a:	cf 91       	pop	r28
    183c:	1f 91       	pop	r17
    183e:	08 95       	ret

00001840 <xQueueCRReceiveFromISR>:
/*-----------------------------------------------------------*/

#if ( configUSE_CO_ROUTINES == 1 )

	BaseType_t xQueueCRReceiveFromISR( QueueHandle_t xQueue, void *pvBuffer, BaseType_t *pxCoRoutineWoken )
	{
    1840:	0f 93       	push	r16
    1842:	1f 93       	push	r17
    1844:	cf 93       	push	r28
    1846:	df 93       	push	r29
    1848:	ec 01       	movw	r28, r24
    184a:	86 2f       	mov	r24, r22
    184c:	97 2f       	mov	r25, r23
    184e:	8a 01       	movw	r16, r20
	BaseType_t xReturn;
	Queue_t * const pxQueue = xQueue;

		/* We cannot block from an ISR, so check there is data available. If
		not then just leave without doing anything. */
		if( pxQueue->uxMessagesWaiting > ( UBaseType_t ) 0 )
    1850:	2a 8d       	ldd	r18, Y+26	; 0x1a
    1852:	22 23       	and	r18, r18
    1854:	49 f1       	breq	.+82     	; 0x18a8 <xQueueCRReceiveFromISR+0x68>
		{
			/* Copy the data from the queue. */
			pxQueue->u.xQueue.pcReadFrom += pxQueue->uxItemSize;
    1856:	4c 8d       	ldd	r20, Y+28	; 0x1c
    1858:	2e 81       	ldd	r18, Y+6	; 0x06
    185a:	3f 81       	ldd	r19, Y+7	; 0x07
    185c:	24 0f       	add	r18, r20
    185e:	31 1d       	adc	r19, r1
    1860:	3f 83       	std	Y+7, r19	; 0x07
    1862:	2e 83       	std	Y+6, r18	; 0x06
			if( pxQueue->u.xQueue.pcReadFrom >= pxQueue->u.xQueue.pcTail )
    1864:	ec 81       	ldd	r30, Y+4	; 0x04
    1866:	fd 81       	ldd	r31, Y+5	; 0x05
    1868:	2e 17       	cp	r18, r30
    186a:	3f 07       	cpc	r19, r31
    186c:	20 f0       	brcs	.+8      	; 0x1876 <xQueueCRReceiveFromISR+0x36>
			{
				pxQueue->u.xQueue.pcReadFrom = pxQueue->pcHead;
    186e:	28 81       	ld	r18, Y
    1870:	39 81       	ldd	r19, Y+1	; 0x01
    1872:	3f 83       	std	Y+7, r19	; 0x07
    1874:	2e 83       	std	Y+6, r18	; 0x06
			}
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}
			--( pxQueue->uxMessagesWaiting );
    1876:	2a 8d       	ldd	r18, Y+26	; 0x1a
    1878:	21 50       	subi	r18, 0x01	; 1
    187a:	2a 8f       	std	Y+26, r18	; 0x1a
			( void ) memcpy( ( void * ) pvBuffer, ( void * ) pxQueue->u.xQueue.pcReadFrom, ( unsigned ) pxQueue->uxItemSize );
    187c:	6e 81       	ldd	r22, Y+6	; 0x06
    187e:	7f 81       	ldd	r23, Y+7	; 0x07
    1880:	50 e0       	ldi	r21, 0x00	; 0
    1882:	0e 94 30 14 	call	0x2860	; 0x2860 <memcpy>

			if( ( *pxCoRoutineWoken ) == pdFALSE )
    1886:	f8 01       	movw	r30, r16
    1888:	80 81       	ld	r24, Z
    188a:	88 23       	and	r24, r24
    188c:	79 f4       	brne	.+30     	; 0x18ac <xQueueCRReceiveFromISR+0x6c>
			{
				if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )
    188e:	88 85       	ldd	r24, Y+8	; 0x08
    1890:	88 23       	and	r24, r24
    1892:	71 f0       	breq	.+28     	; 0x18b0 <xQueueCRReceiveFromISR+0x70>
				{
					if( xCoRoutineRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )
    1894:	ce 01       	movw	r24, r28
    1896:	08 96       	adiw	r24, 0x08	; 8
    1898:	0e 94 3e 02 	call	0x47c	; 0x47c <xCoRoutineRemoveFromEventList>
    189c:	88 23       	and	r24, r24
    189e:	51 f0       	breq	.+20     	; 0x18b4 <xQueueCRReceiveFromISR+0x74>
					{
						*pxCoRoutineWoken = pdTRUE;
    18a0:	81 e0       	ldi	r24, 0x01	; 1
    18a2:	f8 01       	movw	r30, r16
    18a4:	80 83       	st	Z, r24
    18a6:	07 c0       	rjmp	.+14     	; 0x18b6 <xQueueCRReceiveFromISR+0x76>

			xReturn = pdPASS;
		}
		else
		{
			xReturn = pdFAIL;
    18a8:	80 e0       	ldi	r24, 0x00	; 0
    18aa:	05 c0       	rjmp	.+10     	; 0x18b6 <xQueueCRReceiveFromISR+0x76>
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}

			xReturn = pdPASS;
    18ac:	81 e0       	ldi	r24, 0x01	; 1
    18ae:	03 c0       	rjmp	.+6      	; 0x18b6 <xQueueCRReceiveFromISR+0x76>
    18b0:	81 e0       	ldi	r24, 0x01	; 1
    18b2:	01 c0       	rjmp	.+2      	; 0x18b6 <xQueueCRReceiveFromISR+0x76>
    18b4:	81 e0       	ldi	r24, 0x01	; 1
		{
			xReturn = pdFAIL;
		}

		return xReturn;
	}
    18b6:	df 91       	pop	r29
    18b8:	cf 91       	pop	r28
    18ba:	1f 91       	pop	r17
    18bc:	0f 91       	pop	r16
    18be:	08 95       	ret

000018c0 <task>:
#include "FreeRTOS.h"
#include "task.h"

void task(void *p){
	
	 DDRC |= (1<<7);
    18c0:	a7 9a       	sbi	0x14, 7	; 20

	while (1)
	{
		PORTC ^= (1<<7);
    18c2:	85 b3       	in	r24, 0x15	; 21
    18c4:	80 58       	subi	r24, 0x80	; 128
    18c6:	85 bb       	out	0x15, r24	; 21
		vTaskDelay (1000/portTICK_PERIOD_MS);
    18c8:	88 ee       	ldi	r24, 0xE8	; 232
    18ca:	93 e0       	ldi	r25, 0x03	; 3
    18cc:	0e 94 1c 10 	call	0x2038	; 0x2038 <vTaskDelay>
    18d0:	f8 cf       	rjmp	.-16     	; 0x18c2 <task+0x2>

000018d2 <main>:
	}
}
int main(void)
{
    18d2:	ef 92       	push	r14
    18d4:	ff 92       	push	r15
    18d6:	0f 93       	push	r16
             xTaskCreate(task,"led",200,NULL,1,NULL);
    18d8:	80 e6       	ldi	r24, 0x60	; 96
    18da:	9c e0       	ldi	r25, 0x0C	; 12
    18dc:	62 e6       	ldi	r22, 0x62	; 98
    18de:	70 e0       	ldi	r23, 0x00	; 0
    18e0:	48 ec       	ldi	r20, 0xC8	; 200
    18e2:	50 e0       	ldi	r21, 0x00	; 0
    18e4:	20 e0       	ldi	r18, 0x00	; 0
    18e6:	30 e0       	ldi	r19, 0x00	; 0
    18e8:	01 e0       	ldi	r16, 0x01	; 1
    18ea:	ee 24       	eor	r14, r14
    18ec:	ff 24       	eor	r15, r15
    18ee:	0e 94 1b 0d 	call	0x1a36	; 0x1a36 <xTaskCreate>
 //  xTaskCreate(task,"firsttask",250,NULL,1,NULL);
           vTaskStartScheduler();
    18f2:	0e 94 8e 0e 	call	0x1d1c	; 0x1d1c <vTaskStartScheduler>
		  return 0;
    18f6:	80 e0       	ldi	r24, 0x00	; 0
    18f8:	90 e0       	ldi	r25, 0x00	; 0
    18fa:	0f 91       	pop	r16
    18fc:	ff 90       	pop	r15
    18fe:	ef 90       	pop	r14
    1900:	08 95       	ret

00001902 <prvResetNextTaskUnblockTime>:

static void prvResetNextTaskUnblockTime( void )
{
TCB_t *pxTCB;

	if( listLIST_IS_EMPTY( pxDelayedTaskList ) != pdFALSE )
    1902:	e0 91 9b 06 	lds	r30, 0x069B
    1906:	f0 91 9c 06 	lds	r31, 0x069C
    190a:	80 81       	ld	r24, Z
    190c:	88 23       	and	r24, r24
    190e:	39 f4       	brne	.+14     	; 0x191e <prvResetNextTaskUnblockTime+0x1c>
	{
		/* The new current delayed list is empty.  Set xNextTaskUnblockTime to
		the maximum possible value so it is	extremely unlikely that the
		if( xTickCount >= xNextTaskUnblockTime ) test will pass until
		there is an item in the delayed list. */
		xNextTaskUnblockTime = portMAX_DELAY;
    1910:	8f ef       	ldi	r24, 0xFF	; 255
    1912:	9f ef       	ldi	r25, 0xFF	; 255
    1914:	90 93 8f 06 	sts	0x068F, r25
    1918:	80 93 8e 06 	sts	0x068E, r24
    191c:	08 95       	ret
	{
		/* The new current delayed list is not empty, get the value of
		the item at the head of the delayed list.  This is the time at
		which the task at the head of the delayed list should be removed
		from the Blocked state. */
		( pxTCB ) = listGET_OWNER_OF_HEAD_ENTRY( pxDelayedTaskList ); /*lint !e9079 void * is used as this macro is used with timers and co-routines too.  Alignment is known to be fine as the type of the pointer stored and retrieved is the same. */
    191e:	e0 91 9b 06 	lds	r30, 0x069B
    1922:	f0 91 9c 06 	lds	r31, 0x069C
    1926:	05 80       	ldd	r0, Z+5	; 0x05
    1928:	f6 81       	ldd	r31, Z+6	; 0x06
    192a:	e0 2d       	mov	r30, r0
		xNextTaskUnblockTime = listGET_LIST_ITEM_VALUE( &( ( pxTCB )->xStateListItem ) );
    192c:	06 80       	ldd	r0, Z+6	; 0x06
    192e:	f7 81       	ldd	r31, Z+7	; 0x07
    1930:	e0 2d       	mov	r30, r0
    1932:	82 81       	ldd	r24, Z+2	; 0x02
    1934:	93 81       	ldd	r25, Z+3	; 0x03
    1936:	90 93 8f 06 	sts	0x068F, r25
    193a:	80 93 8e 06 	sts	0x068E, r24
    193e:	08 95       	ret

00001940 <prvAddCurrentTaskToDelayedList>:
	}
#endif
/*-----------------------------------------------------------*/

static void prvAddCurrentTaskToDelayedList( TickType_t xTicksToWait, const BaseType_t xCanBlockIndefinitely )
{
    1940:	0f 93       	push	r16
    1942:	1f 93       	push	r17
    1944:	cf 93       	push	r28
    1946:	df 93       	push	r29
    1948:	ec 01       	movw	r28, r24
TickType_t xTimeToWake;
const TickType_t xConstTickCount = xTickCount;
    194a:	00 91 95 06 	lds	r16, 0x0695
    194e:	10 91 96 06 	lds	r17, 0x0696
	}
	#endif

	/* Remove the task from the ready list before adding it to the blocked list
	as the same list item is used for both lists. */
	if( uxListRemove( &( pxCurrentTCB->xStateListItem ) ) == ( UBaseType_t ) 0 )
    1952:	80 91 8b 06 	lds	r24, 0x068B
    1956:	90 91 8c 06 	lds	r25, 0x068C
    195a:	02 96       	adiw	r24, 0x02	; 2
    195c:	0e 94 4a 05 	call	0xa94	; 0xa94 <uxListRemove>
	#else /* INCLUDE_vTaskSuspend */
	{
		/* Calculate the time at which the task should be woken if the event
		does not occur.  This may overflow but this doesn't matter, the kernel
		will manage it correctly. */
		xTimeToWake = xConstTickCount + xTicksToWait;
    1960:	c0 0f       	add	r28, r16
    1962:	d1 1f       	adc	r29, r17

		/* The list item will be inserted in wake time order. */
		listSET_LIST_ITEM_VALUE( &( pxCurrentTCB->xStateListItem ), xTimeToWake );
    1964:	e0 91 8b 06 	lds	r30, 0x068B
    1968:	f0 91 8c 06 	lds	r31, 0x068C
    196c:	d3 83       	std	Z+3, r29	; 0x03
    196e:	c2 83       	std	Z+2, r28	; 0x02

		if( xTimeToWake < xConstTickCount )
    1970:	c0 17       	cp	r28, r16
    1972:	d1 07       	cpc	r29, r17
    1974:	68 f4       	brcc	.+26     	; 0x1990 <prvAddCurrentTaskToDelayedList+0x50>
		{
			/* Wake time has overflowed.  Place this item in the overflow list. */
			vListInsert( pxOverflowDelayedTaskList, &( pxCurrentTCB->xStateListItem ) );
    1976:	80 91 99 06 	lds	r24, 0x0699
    197a:	90 91 9a 06 	lds	r25, 0x069A
    197e:	60 91 8b 06 	lds	r22, 0x068B
    1982:	70 91 8c 06 	lds	r23, 0x068C
    1986:	6e 5f       	subi	r22, 0xFE	; 254
    1988:	7f 4f       	sbci	r23, 0xFF	; 255
    198a:	0e 94 18 05 	call	0xa30	; 0xa30 <vListInsert>
    198e:	17 c0       	rjmp	.+46     	; 0x19be <prvAddCurrentTaskToDelayedList+0x7e>
		}
		else
		{
			/* The wake time has not overflowed, so the current block list is used. */
			vListInsert( pxDelayedTaskList, &( pxCurrentTCB->xStateListItem ) );
    1990:	80 91 9b 06 	lds	r24, 0x069B
    1994:	90 91 9c 06 	lds	r25, 0x069C
    1998:	60 91 8b 06 	lds	r22, 0x068B
    199c:	70 91 8c 06 	lds	r23, 0x068C
    19a0:	6e 5f       	subi	r22, 0xFE	; 254
    19a2:	7f 4f       	sbci	r23, 0xFF	; 255
    19a4:	0e 94 18 05 	call	0xa30	; 0xa30 <vListInsert>

			/* If the task entering the blocked state was placed at the head of the
			list of blocked tasks then xNextTaskUnblockTime needs to be updated
			too. */
			if( xTimeToWake < xNextTaskUnblockTime )
    19a8:	80 91 8e 06 	lds	r24, 0x068E
    19ac:	90 91 8f 06 	lds	r25, 0x068F
    19b0:	c8 17       	cp	r28, r24
    19b2:	d9 07       	cpc	r29, r25
    19b4:	20 f4       	brcc	.+8      	; 0x19be <prvAddCurrentTaskToDelayedList+0x7e>
			{
				xNextTaskUnblockTime = xTimeToWake;
    19b6:	d0 93 8f 06 	sts	0x068F, r29
    19ba:	c0 93 8e 06 	sts	0x068E, r28

		/* Avoid compiler warning when INCLUDE_vTaskSuspend is not 1. */
		( void ) xCanBlockIndefinitely;
	}
	#endif /* INCLUDE_vTaskSuspend */
}
    19be:	df 91       	pop	r29
    19c0:	cf 91       	pop	r28
    19c2:	1f 91       	pop	r17
    19c4:	0f 91       	pop	r16
    19c6:	08 95       	ret

000019c8 <prvDeleteTCB>:
/*-----------------------------------------------------------*/

#if ( INCLUDE_vTaskDelete == 1 )

	static void prvDeleteTCB( TCB_t *pxTCB )
	{
    19c8:	cf 93       	push	r28
    19ca:	df 93       	push	r29
    19cc:	ec 01       	movw	r28, r24

		#if( ( configSUPPORT_DYNAMIC_ALLOCATION == 1 ) && ( configSUPPORT_STATIC_ALLOCATION == 0 ) && ( portUSING_MPU_WRAPPERS == 0 ) )
		{
			/* The task can only have been allocated dynamically - free both
			the stack and TCB. */
			vPortFree( pxTCB->pxStack );
    19ce:	8f 89       	ldd	r24, Y+23	; 0x17
    19d0:	98 8d       	ldd	r25, Y+24	; 0x18
    19d2:	0e 94 ae 04 	call	0x95c	; 0x95c <vPortFree>
			vPortFree( pxTCB );
    19d6:	ce 01       	movw	r24, r28
    19d8:	0e 94 ae 04 	call	0x95c	; 0x95c <vPortFree>
				configASSERT( pxTCB->ucStaticallyAllocated == tskSTATICALLY_ALLOCATED_STACK_AND_TCB	);
				mtCOVERAGE_TEST_MARKER();
			}
		}
		#endif /* configSUPPORT_DYNAMIC_ALLOCATION */
	}
    19dc:	df 91       	pop	r29
    19de:	cf 91       	pop	r28
    19e0:	08 95       	ret

000019e2 <prvIdleTask>:

			A critical region is not required here as we are just reading from
			the list, and an occasional incorrect value will not matter.  If
			the ready list at the idle priority contains more than one task
			then a task other than the idle task is ready to execute. */
			if( listCURRENT_LIST_LENGTH( &( pxReadyTasksLists[ tskIDLE_PRIORITY ] ) ) > ( UBaseType_t ) 1 )
    19e2:	0e e9       	ldi	r16, 0x9E	; 158
    19e4:	16 e0       	ldi	r17, 0x06	; 6
    19e6:	1c c0       	rjmp	.+56     	; 0x1a20 <prvIdleTask+0x3e>

		/* uxDeletedTasksWaitingCleanUp is used to prevent taskENTER_CRITICAL()
		being called too often in the idle task. */
		while( uxDeletedTasksWaitingCleanUp > ( UBaseType_t ) 0U )
		{
			taskENTER_CRITICAL();
    19e8:	0f b6       	in	r0, 0x3f	; 63
    19ea:	f8 94       	cli
    19ec:	0f 92       	push	r0
			{
				pxTCB = listGET_OWNER_OF_HEAD_ENTRY( ( &xTasksWaitingTermination ) ); /*lint !e9079 void * is used as this macro is used with timers and co-routines too.  Alignment is known to be fine as the type of the pointer stored and retrieved is the same. */
    19ee:	e0 91 e2 06 	lds	r30, 0x06E2
    19f2:	f0 91 e3 06 	lds	r31, 0x06E3
    19f6:	c6 81       	ldd	r28, Z+6	; 0x06
    19f8:	d7 81       	ldd	r29, Z+7	; 0x07
				( void ) uxListRemove( &( pxTCB->xStateListItem ) );
    19fa:	ce 01       	movw	r24, r28
    19fc:	02 96       	adiw	r24, 0x02	; 2
    19fe:	0e 94 4a 05 	call	0xa94	; 0xa94 <uxListRemove>
				--uxCurrentNumberOfTasks;
    1a02:	80 91 97 06 	lds	r24, 0x0697
    1a06:	81 50       	subi	r24, 0x01	; 1
    1a08:	80 93 97 06 	sts	0x0697, r24
				--uxDeletedTasksWaitingCleanUp;
    1a0c:	80 91 98 06 	lds	r24, 0x0698
    1a10:	81 50       	subi	r24, 0x01	; 1
    1a12:	80 93 98 06 	sts	0x0698, r24
			}
			taskEXIT_CRITICAL();
    1a16:	0f 90       	pop	r0
    1a18:	0f be       	out	0x3f, r0	; 63

			prvDeleteTCB( pxTCB );
    1a1a:	ce 01       	movw	r24, r28
    1a1c:	0e 94 e4 0c 	call	0x19c8	; 0x19c8 <prvDeleteTCB>
	{
		TCB_t *pxTCB;

		/* uxDeletedTasksWaitingCleanUp is used to prevent taskENTER_CRITICAL()
		being called too often in the idle task. */
		while( uxDeletedTasksWaitingCleanUp > ( UBaseType_t ) 0U )
    1a20:	80 91 98 06 	lds	r24, 0x0698
    1a24:	88 23       	and	r24, r24
    1a26:	01 f7       	brne	.-64     	; 0x19e8 <prvIdleTask+0x6>

			A critical region is not required here as we are just reading from
			the list, and an occasional incorrect value will not matter.  If
			the ready list at the idle priority contains more than one task
			then a task other than the idle task is ready to execute. */
			if( listCURRENT_LIST_LENGTH( &( pxReadyTasksLists[ tskIDLE_PRIORITY ] ) ) > ( UBaseType_t ) 1 )
    1a28:	f8 01       	movw	r30, r16
    1a2a:	80 81       	ld	r24, Z
    1a2c:	82 30       	cpi	r24, 0x02	; 2
    1a2e:	c0 f3       	brcs	.-16     	; 0x1a20 <prvIdleTask+0x3e>
			{
				taskYIELD();
    1a30:	0e 94 39 06 	call	0xc72	; 0xc72 <vPortYield>
    1a34:	f5 cf       	rjmp	.-22     	; 0x1a20 <prvIdleTask+0x3e>

00001a36 <xTaskCreate>:
							const char * const pcName,		/*lint !e971 Unqualified char types are allowed for strings and single characters only. */
							const configSTACK_DEPTH_TYPE usStackDepth,
							void * const pvParameters,
							UBaseType_t uxPriority,
							TaskHandle_t * const pxCreatedTask )
	{
    1a36:	2f 92       	push	r2
    1a38:	3f 92       	push	r3
    1a3a:	4f 92       	push	r4
    1a3c:	5f 92       	push	r5
    1a3e:	6f 92       	push	r6
    1a40:	7f 92       	push	r7
    1a42:	8f 92       	push	r8
    1a44:	9f 92       	push	r9
    1a46:	af 92       	push	r10
    1a48:	bf 92       	push	r11
    1a4a:	df 92       	push	r13
    1a4c:	ef 92       	push	r14
    1a4e:	ff 92       	push	r15
    1a50:	0f 93       	push	r16
    1a52:	1f 93       	push	r17
    1a54:	cf 93       	push	r28
    1a56:	df 93       	push	r29
    1a58:	3c 01       	movw	r6, r24
    1a5a:	5b 01       	movw	r10, r22
    1a5c:	ea 01       	movw	r28, r20
    1a5e:	29 01       	movw	r4, r18
    1a60:	d0 2e       	mov	r13, r16
    1a62:	47 01       	movw	r8, r14
		#else /* portSTACK_GROWTH */
		{
		StackType_t *pxStack;

			/* Allocate space for the stack used by the task being created. */
			pxStack = pvPortMalloc( ( ( ( size_t ) usStackDepth ) * sizeof( StackType_t ) ) ); /*lint !e9079 All values returned by pvPortMalloc() have at least the alignment required by the MCU's stack and this allocation is the stack. */
    1a64:	ca 01       	movw	r24, r20
    1a66:	0e 94 0e 04 	call	0x81c	; 0x81c <pvPortMalloc>
    1a6a:	7c 01       	movw	r14, r24

			if( pxStack != NULL )
    1a6c:	00 97       	sbiw	r24, 0x00	; 0
    1a6e:	09 f4       	brne	.+2      	; 0x1a72 <xTaskCreate+0x3c>
    1a70:	ec c0       	rjmp	.+472    	; 0x1c4a <xTaskCreate+0x214>
			{
				/* Allocate space for the TCB. */
				pxNewTCB = ( TCB_t * ) pvPortMalloc( sizeof( TCB_t ) ); /*lint !e9087 !e9079 All values returned by pvPortMalloc() have at least the alignment required by the MCU's stack, and the first member of TCB_t is always a pointer to the task's stack. */
    1a72:	86 e2       	ldi	r24, 0x26	; 38
    1a74:	90 e0       	ldi	r25, 0x00	; 0
    1a76:	0e 94 0e 04 	call	0x81c	; 0x81c <pvPortMalloc>
    1a7a:	8c 01       	movw	r16, r24

				if( pxNewTCB != NULL )
    1a7c:	00 97       	sbiw	r24, 0x00	; 0
    1a7e:	59 f0       	breq	.+22     	; 0x1a96 <xTaskCreate+0x60>
				{
					/* Store the stack location in the TCB. */
					pxNewTCB->pxStack = pxStack;
    1a80:	fc 01       	movw	r30, r24
    1a82:	f0 8e       	std	Z+24, r15	; 0x18
    1a84:	e7 8a       	std	Z+23, r14	; 0x17
	grows from high memory to low (as per the 80x86) or vice versa.
	portSTACK_GROWTH is used to make the result positive or negative as required
	by the port. */
	#if( portSTACK_GROWTH < 0 )
	{
		pxTopOfStack = &( pxNewTCB->pxStack[ ulStackDepth - ( uint32_t ) 1 ] );
    1a86:	21 97       	sbiw	r28, 0x01	; 1
    1a88:	17 01       	movw	r2, r14
    1a8a:	2c 0e       	add	r2, r28
    1a8c:	3d 1e       	adc	r3, r29
		pxNewTCB->pxEndOfStack = pxNewTCB->pxStack + ( ulStackDepth - ( uint32_t ) 1 );
	}
	#endif /* portSTACK_GROWTH */

	/* Store the task name in the TCB. */
	if( pcName != NULL )
    1a8e:	a1 14       	cp	r10, r1
    1a90:	b1 04       	cpc	r11, r1
    1a92:	31 f4       	brne	.+12     	; 0x1aa0 <xTaskCreate+0x6a>
    1a94:	1e c0       	rjmp	.+60     	; 0x1ad2 <xTaskCreate+0x9c>
				}
				else
				{
					/* The stack cannot be used as the TCB was not created.  Free
					it again. */
					vPortFree( pxStack );
    1a96:	c7 01       	movw	r24, r14
    1a98:	0e 94 ae 04 	call	0x95c	; 0x95c <vPortFree>
			prvAddNewTaskToReadyList( pxNewTCB );
			xReturn = pdPASS;
		}
		else
		{
			xReturn = errCOULD_NOT_ALLOCATE_REQUIRED_MEMORY;
    1a9c:	8f ef       	ldi	r24, 0xFF	; 255
    1a9e:	da c0       	rjmp	.+436    	; 0x1c54 <xTaskCreate+0x21e>
	/* Store the task name in the TCB. */
	if( pcName != NULL )
	{
		for( x = ( UBaseType_t ) 0; x < ( UBaseType_t ) configMAX_TASK_NAME_LEN; x++ )
		{
			pxNewTCB->pcTaskName[ x ] = pcName[ x ];
    1aa0:	f5 01       	movw	r30, r10
    1aa2:	80 81       	ld	r24, Z
    1aa4:	f8 01       	movw	r30, r16
    1aa6:	81 8f       	std	Z+25, r24	; 0x19

			/* Don't copy all configMAX_TASK_NAME_LEN if the string is shorter than
			configMAX_TASK_NAME_LEN characters just in case the memory after the
			string is not accessible (extremely unlikely). */
			if( pcName[ x ] == ( char ) 0x00 )
    1aa8:	f5 01       	movw	r30, r10
    1aaa:	80 81       	ld	r24, Z
    1aac:	88 23       	and	r24, r24
    1aae:	71 f0       	breq	.+28     	; 0x1acc <xTaskCreate+0x96>
#endif /* portUSING_MPU_WRAPPERS */
/*-----------------------------------------------------------*/

#if( configSUPPORT_DYNAMIC_ALLOCATION == 1 )

	BaseType_t xTaskCreate(	TaskFunction_t pxTaskCode,
    1ab0:	e8 01       	movw	r28, r16
    1ab2:	6a 96       	adiw	r28, 0x1a	; 26
    1ab4:	d5 01       	movw	r26, r10
    1ab6:	11 96       	adiw	r26, 0x01	; 1
	#endif /* portSTACK_GROWTH */

	/* Store the task name in the TCB. */
	if( pcName != NULL )
	{
		for( x = ( UBaseType_t ) 0; x < ( UBaseType_t ) configMAX_TASK_NAME_LEN; x++ )
    1ab8:	81 e0       	ldi	r24, 0x01	; 1
#endif /* portUSING_MPU_WRAPPERS */
/*-----------------------------------------------------------*/

#if( configSUPPORT_DYNAMIC_ALLOCATION == 1 )

	BaseType_t xTaskCreate(	TaskFunction_t pxTaskCode,
    1aba:	fd 01       	movw	r30, r26
	/* Store the task name in the TCB. */
	if( pcName != NULL )
	{
		for( x = ( UBaseType_t ) 0; x < ( UBaseType_t ) configMAX_TASK_NAME_LEN; x++ )
		{
			pxNewTCB->pcTaskName[ x ] = pcName[ x ];
    1abc:	9d 91       	ld	r25, X+
    1abe:	99 93       	st	Y+, r25

			/* Don't copy all configMAX_TASK_NAME_LEN if the string is shorter than
			configMAX_TASK_NAME_LEN characters just in case the memory after the
			string is not accessible (extremely unlikely). */
			if( pcName[ x ] == ( char ) 0x00 )
    1ac0:	90 81       	ld	r25, Z
    1ac2:	99 23       	and	r25, r25
    1ac4:	19 f0       	breq	.+6      	; 0x1acc <xTaskCreate+0x96>
	#endif /* portSTACK_GROWTH */

	/* Store the task name in the TCB. */
	if( pcName != NULL )
	{
		for( x = ( UBaseType_t ) 0; x < ( UBaseType_t ) configMAX_TASK_NAME_LEN; x++ )
    1ac6:	8f 5f       	subi	r24, 0xFF	; 255
    1ac8:	88 30       	cpi	r24, 0x08	; 8
    1aca:	b9 f7       	brne	.-18     	; 0x1aba <xTaskCreate+0x84>
			}
		}

		/* Ensure the name string is terminated in the case that the string length
		was greater or equal to configMAX_TASK_NAME_LEN. */
		pxNewTCB->pcTaskName[ configMAX_TASK_NAME_LEN - 1 ] = '\0';
    1acc:	f8 01       	movw	r30, r16
    1ace:	10 a2       	lds	r17, 0x90
    1ad0:	02 c0       	rjmp	.+4      	; 0x1ad6 <xTaskCreate+0xa0>
	}
	else
	{
		/* The task has not been given a name, so just ensure there is a NULL
		terminator when it is read out. */
		pxNewTCB->pcTaskName[ 0 ] = 0x00;
    1ad2:	fc 01       	movw	r30, r24
    1ad4:	11 8e       	std	Z+25, r1	; 0x19
    1ad6:	cd 2d       	mov	r28, r13
    1ad8:	c4 30       	cpi	r28, 0x04	; 4
    1ada:	08 f0       	brcs	.+2      	; 0x1ade <xTaskCreate+0xa8>
    1adc:	c3 e0       	ldi	r28, 0x03	; 3
	else
	{
		mtCOVERAGE_TEST_MARKER();
	}

	pxNewTCB->uxPriority = uxPriority;
    1ade:	f8 01       	movw	r30, r16
    1ae0:	c6 8b       	std	Z+22, r28	; 0x16
		pxNewTCB->uxBasePriority = uxPriority;
		pxNewTCB->uxMutexesHeld = 0;
	}
	#endif /* configUSE_MUTEXES */

	vListInitialiseItem( &( pxNewTCB->xStateListItem ) );
    1ae2:	ee 24       	eor	r14, r14
    1ae4:	ff 24       	eor	r15, r15
    1ae6:	68 94       	set
    1ae8:	e1 f8       	bld	r14, 1
    1aea:	e0 0e       	add	r14, r16
    1aec:	f1 1e       	adc	r15, r17
    1aee:	c7 01       	movw	r24, r14
    1af0:	0e 94 f5 04 	call	0x9ea	; 0x9ea <vListInitialiseItem>
	vListInitialiseItem( &( pxNewTCB->xEventListItem ) );
    1af4:	c8 01       	movw	r24, r16
    1af6:	0c 96       	adiw	r24, 0x0c	; 12
    1af8:	0e 94 f5 04 	call	0x9ea	; 0x9ea <vListInitialiseItem>

	/* Set the pxNewTCB as a link back from the ListItem_t.  This is so we can get
	back to	the containing TCB from a generic item in a list. */
	listSET_LIST_ITEM_OWNER( &( pxNewTCB->xStateListItem ), pxNewTCB );
    1afc:	f8 01       	movw	r30, r16
    1afe:	11 87       	std	Z+9, r17	; 0x09
    1b00:	00 87       	std	Z+8, r16	; 0x08

	/* Event lists are always in priority order. */
	listSET_LIST_ITEM_VALUE( &( pxNewTCB->xEventListItem ), ( TickType_t ) configMAX_PRIORITIES - ( TickType_t ) uxPriority ); /*lint !e961 MISRA exception as the casts are only redundant for some ports. */
    1b02:	84 e0       	ldi	r24, 0x04	; 4
    1b04:	90 e0       	ldi	r25, 0x00	; 0
    1b06:	8c 1b       	sub	r24, r28
    1b08:	91 09       	sbc	r25, r1
    1b0a:	95 87       	std	Z+13, r25	; 0x0d
    1b0c:	84 87       	std	Z+12, r24	; 0x0c
	listSET_LIST_ITEM_OWNER( &( pxNewTCB->xEventListItem ), pxNewTCB );
    1b0e:	13 8b       	std	Z+19, r17	; 0x13
    1b10:	02 8b       	std	Z+18, r16	; 0x12
	}
	#endif

	#if ( configUSE_TASK_NOTIFICATIONS == 1 )
	{
		pxNewTCB->ulNotifiedValue = 0;
    1b12:	11 a2       	lds	r17, 0x91
    1b14:	12 a2       	lds	r17, 0x92
    1b16:	13 a2       	lds	r17, 0x93
    1b18:	14 a2       	lds	r17, 0x94
		pxNewTCB->ucNotifyState = taskNOT_WAITING_NOTIFICATION;
    1b1a:	15 a2       	lds	r17, 0x95
			}
			#endif /* portSTACK_GROWTH */
		}
		#else /* portHAS_STACK_OVERFLOW_CHECKING */
		{
			pxNewTCB->pxTopOfStack = pxPortInitialiseStack( pxTopOfStack, pxTaskCode, pvParameters );
    1b1c:	c1 01       	movw	r24, r2
    1b1e:	b3 01       	movw	r22, r6
    1b20:	a2 01       	movw	r20, r4
    1b22:	0e 94 73 05 	call	0xae6	; 0xae6 <pxPortInitialiseStack>
    1b26:	f8 01       	movw	r30, r16
    1b28:	91 83       	std	Z+1, r25	; 0x01
    1b2a:	80 83       	st	Z, r24
		}
		#endif /* portHAS_STACK_OVERFLOW_CHECKING */
	}
	#endif /* portUSING_MPU_WRAPPERS */

	if( pxCreatedTask != NULL )
    1b2c:	81 14       	cp	r8, r1
    1b2e:	91 04       	cpc	r9, r1
    1b30:	19 f0       	breq	.+6      	; 0x1b38 <xTaskCreate+0x102>
	{
		/* Pass the handle out in an anonymous way.  The handle can be used to
		change the created task's priority, delete the created task, etc.*/
		*pxCreatedTask = ( TaskHandle_t ) pxNewTCB;
    1b32:	f4 01       	movw	r30, r8
    1b34:	11 83       	std	Z+1, r17	; 0x01
    1b36:	00 83       	st	Z, r16

static void prvAddNewTaskToReadyList( TCB_t *pxNewTCB )
{
	/* Ensure interrupts don't access the task lists while the lists are being
	updated. */
	taskENTER_CRITICAL();
    1b38:	0f b6       	in	r0, 0x3f	; 63
    1b3a:	f8 94       	cli
    1b3c:	0f 92       	push	r0
	{
		uxCurrentNumberOfTasks++;
    1b3e:	80 91 97 06 	lds	r24, 0x0697
    1b42:	8f 5f       	subi	r24, 0xFF	; 255
    1b44:	80 93 97 06 	sts	0x0697, r24
		if( pxCurrentTCB == NULL )
    1b48:	80 91 8b 06 	lds	r24, 0x068B
    1b4c:	90 91 8c 06 	lds	r25, 0x068C
    1b50:	00 97       	sbiw	r24, 0x00	; 0
    1b52:	d9 f5       	brne	.+118    	; 0x1bca <xTaskCreate+0x194>
		{
			/* There are no other tasks, or all the other tasks are in
			the suspended state - make this the current task. */
			pxCurrentTCB = pxNewTCB;
    1b54:	10 93 8c 06 	sts	0x068C, r17
    1b58:	00 93 8b 06 	sts	0x068B, r16

			if( uxCurrentNumberOfTasks == ( UBaseType_t ) 1 )
    1b5c:	80 91 97 06 	lds	r24, 0x0697
    1b60:	81 30       	cpi	r24, 0x01	; 1
    1b62:	09 f0       	breq	.+2      	; 0x1b66 <xTaskCreate+0x130>
    1b64:	43 c0       	rjmp	.+134    	; 0x1bec <xTaskCreate+0x1b6>
    1b66:	c0 e0       	ldi	r28, 0x00	; 0
    1b68:	d0 e0       	ldi	r29, 0x00	; 0
{
UBaseType_t uxPriority;

	for( uxPriority = ( UBaseType_t ) 0U; uxPriority < ( UBaseType_t ) configMAX_PRIORITIES; uxPriority++ )
	{
		vListInitialise( &( pxReadyTasksLists[ uxPriority ] ) );
    1b6a:	ce 01       	movw	r24, r28
    1b6c:	88 0f       	add	r24, r24
    1b6e:	99 1f       	adc	r25, r25
    1b70:	88 0f       	add	r24, r24
    1b72:	99 1f       	adc	r25, r25
    1b74:	88 0f       	add	r24, r24
    1b76:	99 1f       	adc	r25, r25
    1b78:	8c 0f       	add	r24, r28
    1b7a:	9d 1f       	adc	r25, r29
    1b7c:	82 56       	subi	r24, 0x62	; 98
    1b7e:	99 4f       	sbci	r25, 0xF9	; 249
    1b80:	0e 94 e7 04 	call	0x9ce	; 0x9ce <vListInitialise>
    1b84:	21 96       	adiw	r28, 0x01	; 1

static void prvInitialiseTaskLists( void )
{
UBaseType_t uxPriority;

	for( uxPriority = ( UBaseType_t ) 0U; uxPriority < ( UBaseType_t ) configMAX_PRIORITIES; uxPriority++ )
    1b86:	c4 30       	cpi	r28, 0x04	; 4
    1b88:	d1 05       	cpc	r29, r1
    1b8a:	79 f7       	brne	.-34     	; 0x1b6a <xTaskCreate+0x134>
	{
		vListInitialise( &( pxReadyTasksLists[ uxPriority ] ) );
	}

	vListInitialise( &xDelayedTaskList1 );
    1b8c:	c2 ec       	ldi	r28, 0xC2	; 194
    1b8e:	d6 e0       	ldi	r29, 0x06	; 6
    1b90:	ce 01       	movw	r24, r28
    1b92:	0e 94 e7 04 	call	0x9ce	; 0x9ce <vListInitialise>
	vListInitialise( &xDelayedTaskList2 );
    1b96:	0f 2e       	mov	r0, r31
    1b98:	fb ec       	ldi	r31, 0xCB	; 203
    1b9a:	af 2e       	mov	r10, r31
    1b9c:	f6 e0       	ldi	r31, 0x06	; 6
    1b9e:	bf 2e       	mov	r11, r31
    1ba0:	f0 2d       	mov	r31, r0
    1ba2:	c5 01       	movw	r24, r10
    1ba4:	0e 94 e7 04 	call	0x9ce	; 0x9ce <vListInitialise>
	vListInitialise( &xPendingReadyList );
    1ba8:	84 ed       	ldi	r24, 0xD4	; 212
    1baa:	96 e0       	ldi	r25, 0x06	; 6
    1bac:	0e 94 e7 04 	call	0x9ce	; 0x9ce <vListInitialise>

	#if ( INCLUDE_vTaskDelete == 1 )
	{
		vListInitialise( &xTasksWaitingTermination );
    1bb0:	8d ed       	ldi	r24, 0xDD	; 221
    1bb2:	96 e0       	ldi	r25, 0x06	; 6
    1bb4:	0e 94 e7 04 	call	0x9ce	; 0x9ce <vListInitialise>
	}
	#endif /* INCLUDE_vTaskSuspend */

	/* Start with pxDelayedTaskList using list1 and the pxOverflowDelayedTaskList
	using list2. */
	pxDelayedTaskList = &xDelayedTaskList1;
    1bb8:	d0 93 9c 06 	sts	0x069C, r29
    1bbc:	c0 93 9b 06 	sts	0x069B, r28
	pxOverflowDelayedTaskList = &xDelayedTaskList2;
    1bc0:	b0 92 9a 06 	sts	0x069A, r11
    1bc4:	a0 92 99 06 	sts	0x0699, r10
    1bc8:	11 c0       	rjmp	.+34     	; 0x1bec <xTaskCreate+0x1b6>
		else
		{
			/* If the scheduler is not already running, make this task the
			current task if it is the highest priority task to be created
			so far. */
			if( xSchedulerRunning == pdFALSE )
    1bca:	80 91 93 06 	lds	r24, 0x0693
    1bce:	88 23       	and	r24, r24
    1bd0:	69 f4       	brne	.+26     	; 0x1bec <xTaskCreate+0x1b6>
			{
				if( pxCurrentTCB->uxPriority <= pxNewTCB->uxPriority )
    1bd2:	e0 91 8b 06 	lds	r30, 0x068B
    1bd6:	f0 91 8c 06 	lds	r31, 0x068C
    1bda:	96 89       	ldd	r25, Z+22	; 0x16
    1bdc:	f8 01       	movw	r30, r16
    1bde:	86 89       	ldd	r24, Z+22	; 0x16
    1be0:	89 17       	cp	r24, r25
    1be2:	20 f0       	brcs	.+8      	; 0x1bec <xTaskCreate+0x1b6>
				{
					pxCurrentTCB = pxNewTCB;
    1be4:	10 93 8c 06 	sts	0x068C, r17
    1be8:	00 93 8b 06 	sts	0x068B, r16
			{
				mtCOVERAGE_TEST_MARKER();
			}
		}

		uxTaskNumber++;
    1bec:	80 91 9d 06 	lds	r24, 0x069D
    1bf0:	8f 5f       	subi	r24, 0xFF	; 255
    1bf2:	80 93 9d 06 	sts	0x069D, r24
			pxNewTCB->uxTCBNumber = uxTaskNumber;
		}
		#endif /* configUSE_TRACE_FACILITY */
		traceTASK_CREATE( pxNewTCB );

		prvAddTaskToReadyList( pxNewTCB );
    1bf6:	f8 01       	movw	r30, r16
    1bf8:	86 89       	ldd	r24, Z+22	; 0x16
    1bfa:	90 91 94 06 	lds	r25, 0x0694
    1bfe:	98 17       	cp	r25, r24
    1c00:	10 f4       	brcc	.+4      	; 0x1c06 <xTaskCreate+0x1d0>
    1c02:	80 93 94 06 	sts	0x0694, r24
    1c06:	90 e0       	ldi	r25, 0x00	; 0
    1c08:	9c 01       	movw	r18, r24
    1c0a:	22 0f       	add	r18, r18
    1c0c:	33 1f       	adc	r19, r19
    1c0e:	22 0f       	add	r18, r18
    1c10:	33 1f       	adc	r19, r19
    1c12:	22 0f       	add	r18, r18
    1c14:	33 1f       	adc	r19, r19
    1c16:	82 0f       	add	r24, r18
    1c18:	93 1f       	adc	r25, r19
    1c1a:	82 56       	subi	r24, 0x62	; 98
    1c1c:	99 4f       	sbci	r25, 0xF9	; 249
    1c1e:	b7 01       	movw	r22, r14
    1c20:	0e 94 f9 04 	call	0x9f2	; 0x9f2 <vListInsertEnd>

		portSETUP_TCB( pxNewTCB );
	}
	taskEXIT_CRITICAL();
    1c24:	0f 90       	pop	r0
    1c26:	0f be       	out	0x3f, r0	; 63

	if( xSchedulerRunning != pdFALSE )
    1c28:	80 91 93 06 	lds	r24, 0x0693
    1c2c:	88 23       	and	r24, r24
    1c2e:	79 f0       	breq	.+30     	; 0x1c4e <xTaskCreate+0x218>
	{
		/* If the created task is of a higher priority than the current task
		then it should run now. */
		if( pxCurrentTCB->uxPriority < pxNewTCB->uxPriority )
    1c30:	e0 91 8b 06 	lds	r30, 0x068B
    1c34:	f0 91 8c 06 	lds	r31, 0x068C
    1c38:	96 89       	ldd	r25, Z+22	; 0x16
    1c3a:	f8 01       	movw	r30, r16
    1c3c:	86 89       	ldd	r24, Z+22	; 0x16
    1c3e:	98 17       	cp	r25, r24
    1c40:	40 f4       	brcc	.+16     	; 0x1c52 <xTaskCreate+0x21c>
		{
			taskYIELD_IF_USING_PREEMPTION();
    1c42:	0e 94 39 06 	call	0xc72	; 0xc72 <vPortYield>
			}
			#endif /* tskSTATIC_AND_DYNAMIC_ALLOCATION_POSSIBLE */

			prvInitialiseNewTask( pxTaskCode, pcName, ( uint32_t ) usStackDepth, pvParameters, uxPriority, pxCreatedTask, pxNewTCB, NULL );
			prvAddNewTaskToReadyList( pxNewTCB );
			xReturn = pdPASS;
    1c46:	81 e0       	ldi	r24, 0x01	; 1
    1c48:	05 c0       	rjmp	.+10     	; 0x1c54 <xTaskCreate+0x21e>
		}
		else
		{
			xReturn = errCOULD_NOT_ALLOCATE_REQUIRED_MEMORY;
    1c4a:	8f ef       	ldi	r24, 0xFF	; 255
    1c4c:	03 c0       	rjmp	.+6      	; 0x1c54 <xTaskCreate+0x21e>
			}
			#endif /* tskSTATIC_AND_DYNAMIC_ALLOCATION_POSSIBLE */

			prvInitialiseNewTask( pxTaskCode, pcName, ( uint32_t ) usStackDepth, pvParameters, uxPriority, pxCreatedTask, pxNewTCB, NULL );
			prvAddNewTaskToReadyList( pxNewTCB );
			xReturn = pdPASS;
    1c4e:	81 e0       	ldi	r24, 0x01	; 1
    1c50:	01 c0       	rjmp	.+2      	; 0x1c54 <xTaskCreate+0x21e>
    1c52:	81 e0       	ldi	r24, 0x01	; 1
		{
			xReturn = errCOULD_NOT_ALLOCATE_REQUIRED_MEMORY;
		}

		return xReturn;
	}
    1c54:	df 91       	pop	r29
    1c56:	cf 91       	pop	r28
    1c58:	1f 91       	pop	r17
    1c5a:	0f 91       	pop	r16
    1c5c:	ff 90       	pop	r15
    1c5e:	ef 90       	pop	r14
    1c60:	df 90       	pop	r13
    1c62:	bf 90       	pop	r11
    1c64:	af 90       	pop	r10
    1c66:	9f 90       	pop	r9
    1c68:	8f 90       	pop	r8
    1c6a:	7f 90       	pop	r7
    1c6c:	6f 90       	pop	r6
    1c6e:	5f 90       	pop	r5
    1c70:	4f 90       	pop	r4
    1c72:	3f 90       	pop	r3
    1c74:	2f 90       	pop	r2
    1c76:	08 95       	ret

00001c78 <vTaskDelete>:
/*-----------------------------------------------------------*/

#if ( INCLUDE_vTaskDelete == 1 )

	void vTaskDelete( TaskHandle_t xTaskToDelete )
	{
    1c78:	0f 93       	push	r16
    1c7a:	1f 93       	push	r17
    1c7c:	cf 93       	push	r28
    1c7e:	df 93       	push	r29
	TCB_t *pxTCB;

		taskENTER_CRITICAL();
    1c80:	0f b6       	in	r0, 0x3f	; 63
    1c82:	f8 94       	cli
    1c84:	0f 92       	push	r0
		{
			/* If null is passed in here then it is the calling task that is
			being deleted. */
			pxTCB = prvGetTCBFromHandle( xTaskToDelete );
    1c86:	00 97       	sbiw	r24, 0x00	; 0
    1c88:	29 f4       	brne	.+10     	; 0x1c94 <vTaskDelete+0x1c>
    1c8a:	c0 91 8b 06 	lds	r28, 0x068B
    1c8e:	d0 91 8c 06 	lds	r29, 0x068C
    1c92:	01 c0       	rjmp	.+2      	; 0x1c96 <vTaskDelete+0x1e>
    1c94:	ec 01       	movw	r28, r24

			/* Remove task from the ready list. */
			if( uxListRemove( &( pxTCB->xStateListItem ) ) == ( UBaseType_t ) 0 )
    1c96:	8e 01       	movw	r16, r28
    1c98:	0e 5f       	subi	r16, 0xFE	; 254
    1c9a:	1f 4f       	sbci	r17, 0xFF	; 255
    1c9c:	c8 01       	movw	r24, r16
    1c9e:	0e 94 4a 05 	call	0xa94	; 0xa94 <uxListRemove>
			{
				mtCOVERAGE_TEST_MARKER();
			}

			/* Is the task waiting on an event also? */
			if( listLIST_ITEM_CONTAINER( &( pxTCB->xEventListItem ) ) != NULL )
    1ca2:	8c 89       	ldd	r24, Y+20	; 0x14
    1ca4:	9d 89       	ldd	r25, Y+21	; 0x15
    1ca6:	00 97       	sbiw	r24, 0x00	; 0
    1ca8:	21 f0       	breq	.+8      	; 0x1cb2 <vTaskDelete+0x3a>
			{
				( void ) uxListRemove( &( pxTCB->xEventListItem ) );
    1caa:	ce 01       	movw	r24, r28
    1cac:	0c 96       	adiw	r24, 0x0c	; 12
    1cae:	0e 94 4a 05 	call	0xa94	; 0xa94 <uxListRemove>

			/* Increment the uxTaskNumber also so kernel aware debuggers can
			detect that the task lists need re-generating.  This is done before
			portPRE_TASK_DELETE_HOOK() as in the Windows port that macro will
			not return. */
			uxTaskNumber++;
    1cb2:	80 91 9d 06 	lds	r24, 0x069D
    1cb6:	8f 5f       	subi	r24, 0xFF	; 255
    1cb8:	80 93 9d 06 	sts	0x069D, r24

			if( pxTCB == pxCurrentTCB )
    1cbc:	80 91 8b 06 	lds	r24, 0x068B
    1cc0:	90 91 8c 06 	lds	r25, 0x068C
    1cc4:	c8 17       	cp	r28, r24
    1cc6:	d9 07       	cpc	r29, r25
    1cc8:	59 f4       	brne	.+22     	; 0x1ce0 <vTaskDelete+0x68>
				/* A task is deleting itself.  This cannot complete within the
				task itself, as a context switch to another task is required.
				Place the task in the termination list.  The idle task will
				check the termination list and free up any memory allocated by
				the scheduler for the TCB and stack of the deleted task. */
				vListInsertEnd( &xTasksWaitingTermination, &( pxTCB->xStateListItem ) );
    1cca:	8d ed       	ldi	r24, 0xDD	; 221
    1ccc:	96 e0       	ldi	r25, 0x06	; 6
    1cce:	b8 01       	movw	r22, r16
    1cd0:	0e 94 f9 04 	call	0x9f2	; 0x9f2 <vListInsertEnd>

				/* Increment the ucTasksDeleted variable so the idle task knows
				there is a task that has been deleted and that it should therefore
				check the xTasksWaitingTermination list. */
				++uxDeletedTasksWaitingCleanUp;
    1cd4:	80 91 98 06 	lds	r24, 0x0698
    1cd8:	8f 5f       	subi	r24, 0xFF	; 255
    1cda:	80 93 98 06 	sts	0x0698, r24
    1cde:	0a c0       	rjmp	.+20     	; 0x1cf4 <vTaskDelete+0x7c>
				required. */
				portPRE_TASK_DELETE_HOOK( pxTCB, &xYieldPending );
			}
			else
			{
				--uxCurrentNumberOfTasks;
    1ce0:	80 91 97 06 	lds	r24, 0x0697
    1ce4:	81 50       	subi	r24, 0x01	; 1
    1ce6:	80 93 97 06 	sts	0x0697, r24
				prvDeleteTCB( pxTCB );
    1cea:	ce 01       	movw	r24, r28
    1cec:	0e 94 e4 0c 	call	0x19c8	; 0x19c8 <prvDeleteTCB>

				/* Reset the next expected unblock time in case it referred to
				the task that has just been deleted. */
				prvResetNextTaskUnblockTime();
    1cf0:	0e 94 81 0c 	call	0x1902	; 0x1902 <prvResetNextTaskUnblockTime>
			}

			traceTASK_DELETE( pxTCB );
		}
		taskEXIT_CRITICAL();
    1cf4:	0f 90       	pop	r0
    1cf6:	0f be       	out	0x3f, r0	; 63

		/* Force a reschedule if it is the currently running task that has just
		been deleted. */
		if( xSchedulerRunning != pdFALSE )
    1cf8:	80 91 93 06 	lds	r24, 0x0693
    1cfc:	88 23       	and	r24, r24
    1cfe:	49 f0       	breq	.+18     	; 0x1d12 <vTaskDelete+0x9a>
		{
			if( pxTCB == pxCurrentTCB )
    1d00:	80 91 8b 06 	lds	r24, 0x068B
    1d04:	90 91 8c 06 	lds	r25, 0x068C
    1d08:	c8 17       	cp	r28, r24
    1d0a:	d9 07       	cpc	r29, r25
    1d0c:	11 f4       	brne	.+4      	; 0x1d12 <vTaskDelete+0x9a>
			{
				configASSERT( uxSchedulerSuspended == 0 );
				portYIELD_WITHIN_API();
    1d0e:	0e 94 39 06 	call	0xc72	; 0xc72 <vPortYield>
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}
		}
	}
    1d12:	df 91       	pop	r29
    1d14:	cf 91       	pop	r28
    1d16:	1f 91       	pop	r17
    1d18:	0f 91       	pop	r16
    1d1a:	08 95       	ret

00001d1c <vTaskStartScheduler>:

#endif /* ( ( INCLUDE_xTaskResumeFromISR == 1 ) && ( INCLUDE_vTaskSuspend == 1 ) ) */
/*-----------------------------------------------------------*/

void vTaskStartScheduler( void )
{
    1d1c:	ef 92       	push	r14
    1d1e:	ff 92       	push	r15
    1d20:	0f 93       	push	r16
		}
	}
	#else
	{
		/* The Idle task is being created using dynamically allocated RAM. */
		xReturn = xTaskCreate(	prvIdleTask,
    1d22:	81 ef       	ldi	r24, 0xF1	; 241
    1d24:	9c e0       	ldi	r25, 0x0C	; 12
    1d26:	66 e6       	ldi	r22, 0x66	; 102
    1d28:	70 e0       	ldi	r23, 0x00	; 0
    1d2a:	45 e5       	ldi	r20, 0x55	; 85
    1d2c:	50 e0       	ldi	r21, 0x00	; 0
    1d2e:	20 e0       	ldi	r18, 0x00	; 0
    1d30:	30 e0       	ldi	r19, 0x00	; 0
    1d32:	00 e0       	ldi	r16, 0x00	; 0
    1d34:	0f 2e       	mov	r0, r31
    1d36:	f6 ee       	ldi	r31, 0xE6	; 230
    1d38:	ef 2e       	mov	r14, r31
    1d3a:	f6 e0       	ldi	r31, 0x06	; 6
    1d3c:	ff 2e       	mov	r15, r31
    1d3e:	f0 2d       	mov	r31, r0
    1d40:	0e 94 1b 0d 	call	0x1a36	; 0x1a36 <xTaskCreate>
			mtCOVERAGE_TEST_MARKER();
		}
	}
	#endif /* configUSE_TIMERS */

	if( xReturn == pdPASS )
    1d44:	81 30       	cpi	r24, 0x01	; 1
    1d46:	81 f4       	brne	.+32     	; 0x1d68 <vTaskStartScheduler+0x4c>
		/* Interrupts are turned off here, to ensure a tick does not occur
		before or during the call to xPortStartScheduler().  The stacks of
		the created tasks contain a status word with interrupts switched on
		so interrupts will automatically get re-enabled when the first task
		starts to run. */
		portDISABLE_INTERRUPTS();
    1d48:	f8 94       	cli
			structure specific to the task that will run first. */
			_impure_ptr = &( pxCurrentTCB->xNewLib_reent );
		}
		#endif /* configUSE_NEWLIB_REENTRANT */

		xNextTaskUnblockTime = portMAX_DELAY;
    1d4a:	8f ef       	ldi	r24, 0xFF	; 255
    1d4c:	9f ef       	ldi	r25, 0xFF	; 255
    1d4e:	90 93 8f 06 	sts	0x068F, r25
    1d52:	80 93 8e 06 	sts	0x068E, r24
		xSchedulerRunning = pdTRUE;
    1d56:	81 e0       	ldi	r24, 0x01	; 1
    1d58:	80 93 93 06 	sts	0x0693, r24
		xTickCount = ( TickType_t ) configINITIAL_TICK_COUNT;
    1d5c:	10 92 96 06 	sts	0x0696, r1
    1d60:	10 92 95 06 	sts	0x0695, r1

		traceTASK_SWITCHED_IN();

		/* Setting up the timer tick is hardware specific and thus in the
		portable interface. */
		if( xPortStartScheduler() != pdFALSE )
    1d64:	0e 94 03 06 	call	0xc06	; 0xc06 <xPortStartScheduler>
	}

	/* Prevent compiler warnings if INCLUDE_xTaskGetIdleTaskHandle is set to 0,
	meaning xIdleTaskHandle is not used anywhere else. */
	( void ) xIdleTaskHandle;
}
    1d68:	0f 91       	pop	r16
    1d6a:	ff 90       	pop	r15
    1d6c:	ef 90       	pop	r14
    1d6e:	08 95       	ret

00001d70 <vTaskEndScheduler>:
void vTaskEndScheduler( void )
{
	/* Stop the scheduler interrupts and call the portable scheduler end
	routine so the original ISRs can be restored if necessary.  The port
	layer must ensure interrupts enable	bit is left in the correct state. */
	portDISABLE_INTERRUPTS();
    1d70:	f8 94       	cli
	xSchedulerRunning = pdFALSE;
    1d72:	10 92 93 06 	sts	0x0693, r1
	vPortEndScheduler();
    1d76:	0e 94 38 06 	call	0xc70	; 0xc70 <vPortEndScheduler>
}
    1d7a:	08 95       	ret

00001d7c <vTaskSuspendAll>:
{
	/* A critical section is not required as the variable is of type
	BaseType_t.  Please read Richard Barry's reply in the following link to a
	post in the FreeRTOS support forum before reporting this as a bug! -
	http://goo.gl/wu4acr */
	++uxSchedulerSuspended;
    1d7c:	80 91 8d 06 	lds	r24, 0x068D
    1d80:	8f 5f       	subi	r24, 0xFF	; 255
    1d82:	80 93 8d 06 	sts	0x068D, r24
	portMEMORY_BARRIER();
}
    1d86:	08 95       	ret

00001d88 <xTaskGetTickCount>:
TickType_t xTaskGetTickCount( void )
{
TickType_t xTicks;

	/* Critical section required if running on a 16 bit processor. */
	portTICK_TYPE_ENTER_CRITICAL();
    1d88:	0f b6       	in	r0, 0x3f	; 63
    1d8a:	f8 94       	cli
    1d8c:	0f 92       	push	r0
	{
		xTicks = xTickCount;
    1d8e:	80 91 95 06 	lds	r24, 0x0695
    1d92:	90 91 96 06 	lds	r25, 0x0696
	}
	portTICK_TYPE_EXIT_CRITICAL();
    1d96:	0f 90       	pop	r0
    1d98:	0f be       	out	0x3f, r0	; 63

	return xTicks;
}
    1d9a:	08 95       	ret

00001d9c <xTaskGetTickCountFromISR>:
	link: https://www.freertos.org/RTOS-Cortex-M3-M4.html */
	portASSERT_IF_INTERRUPT_PRIORITY_INVALID();

	uxSavedInterruptStatus = portTICK_TYPE_SET_INTERRUPT_MASK_FROM_ISR();
	{
		xReturn = xTickCount;
    1d9c:	80 91 95 06 	lds	r24, 0x0695
    1da0:	90 91 96 06 	lds	r25, 0x0696
	}
	portTICK_TYPE_CLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );

	return xReturn;
}
    1da4:	08 95       	ret

00001da6 <uxTaskGetNumberOfTasks>:

UBaseType_t uxTaskGetNumberOfTasks( void )
{
	/* A critical section is not required because the variables are of type
	BaseType_t. */
	return uxCurrentNumberOfTasks;
    1da6:	80 91 97 06 	lds	r24, 0x0697
}
    1daa:	08 95       	ret

00001dac <pcTaskGetName>:
{
TCB_t *pxTCB;

	/* If null is passed in here then the name of the calling task is being
	queried. */
	pxTCB = prvGetTCBFromHandle( xTaskToQuery );
    1dac:	00 97       	sbiw	r24, 0x00	; 0
    1dae:	21 f4       	brne	.+8      	; 0x1db8 <pcTaskGetName+0xc>
    1db0:	80 91 8b 06 	lds	r24, 0x068B
    1db4:	90 91 8c 06 	lds	r25, 0x068C
	configASSERT( pxTCB );
	return &( pxTCB->pcTaskName[ 0 ] );
    1db8:	49 96       	adiw	r24, 0x19	; 25
}
    1dba:	08 95       	ret

00001dbc <xTaskIncrementTick>:

#endif /* INCLUDE_xTaskAbortDelay */
/*----------------------------------------------------------*/

BaseType_t xTaskIncrementTick( void )
{
    1dbc:	cf 92       	push	r12
    1dbe:	df 92       	push	r13
    1dc0:	ef 92       	push	r14
    1dc2:	ff 92       	push	r15
    1dc4:	0f 93       	push	r16
    1dc6:	1f 93       	push	r17
    1dc8:	cf 93       	push	r28
    1dca:	df 93       	push	r29

	/* Called by the portable layer each time a tick interrupt occurs.
	Increments the tick then checks to see if the new tick value will cause any
	tasks to be unblocked. */
	traceTASK_INCREMENT_TICK( xTickCount );
	if( uxSchedulerSuspended == ( UBaseType_t ) pdFALSE )
    1dcc:	80 91 8d 06 	lds	r24, 0x068D
    1dd0:	88 23       	and	r24, r24
    1dd2:	09 f0       	breq	.+2      	; 0x1dd6 <xTaskIncrementTick+0x1a>
    1dd4:	98 c0       	rjmp	.+304    	; 0x1f06 <xTaskIncrementTick+0x14a>
	{
		/* Minor optimisation.  The tick count cannot change in this
		block. */
		const TickType_t xConstTickCount = xTickCount + ( TickType_t ) 1;
    1dd6:	c0 90 95 06 	lds	r12, 0x0695
    1dda:	d0 90 96 06 	lds	r13, 0x0696
    1dde:	08 94       	sec
    1de0:	c1 1c       	adc	r12, r1
    1de2:	d1 1c       	adc	r13, r1

		/* Increment the RTOS tick, switching the delayed and overflowed
		delayed lists if it wraps to 0. */
		xTickCount = xConstTickCount;
    1de4:	d0 92 96 06 	sts	0x0696, r13
    1de8:	c0 92 95 06 	sts	0x0695, r12

		if( xConstTickCount == ( TickType_t ) 0U ) /*lint !e774 'if' does not always evaluate to false as it is looking for an overflow. */
    1dec:	c1 14       	cp	r12, r1
    1dee:	d1 04       	cpc	r13, r1
    1df0:	b9 f4       	brne	.+46     	; 0x1e20 <xTaskIncrementTick+0x64>
		{
			taskSWITCH_DELAYED_LISTS();
    1df2:	80 91 9b 06 	lds	r24, 0x069B
    1df6:	90 91 9c 06 	lds	r25, 0x069C
    1dfa:	20 91 99 06 	lds	r18, 0x0699
    1dfe:	30 91 9a 06 	lds	r19, 0x069A
    1e02:	30 93 9c 06 	sts	0x069C, r19
    1e06:	20 93 9b 06 	sts	0x069B, r18
    1e0a:	90 93 9a 06 	sts	0x069A, r25
    1e0e:	80 93 99 06 	sts	0x0699, r24
    1e12:	80 91 90 06 	lds	r24, 0x0690
    1e16:	8f 5f       	subi	r24, 0xFF	; 255
    1e18:	80 93 90 06 	sts	0x0690, r24
    1e1c:	0e 94 81 0c 	call	0x1902	; 0x1902 <prvResetNextTaskUnblockTime>

		/* See if this tick has made a timeout expire.  Tasks are stored in
		the	queue in the order of their wake time - meaning once one task
		has been found whose block time has not expired there is no need to
		look any further down the list. */
		if( xConstTickCount >= xNextTaskUnblockTime )
    1e20:	80 91 8e 06 	lds	r24, 0x068E
    1e24:	90 91 8f 06 	lds	r25, 0x068F
    1e28:	c8 16       	cp	r12, r24
    1e2a:	d9 06       	cpc	r13, r25
    1e2c:	20 f4       	brcc	.+8      	; 0x1e36 <xTaskIncrementTick+0x7a>

BaseType_t xTaskIncrementTick( void )
{
TCB_t * pxTCB;
TickType_t xItemValue;
BaseType_t xSwitchRequired = pdFALSE;
    1e2e:	ff 24       	eor	r15, r15
    1e30:	54 c0       	rjmp	.+168    	; 0x1eda <xTaskIncrementTick+0x11e>
						only be performed if the unblocked task has a
						priority that is equal to or higher than the
						currently executing task. */
						if( pxTCB->uxPriority >= pxCurrentTCB->uxPriority )
						{
							xSwitchRequired = pdTRUE;
    1e32:	fe 2c       	mov	r15, r14
    1e34:	03 c0       	rjmp	.+6      	; 0x1e3c <xTaskIncrementTick+0x80>

		/* See if this tick has made a timeout expire.  Tasks are stored in
		the	queue in the order of their wake time - meaning once one task
		has been found whose block time has not expired there is no need to
		look any further down the list. */
		if( xConstTickCount >= xNextTaskUnblockTime )
    1e36:	ff 24       	eor	r15, r15
						only be performed if the unblocked task has a
						priority that is equal to or higher than the
						currently executing task. */
						if( pxTCB->uxPriority >= pxCurrentTCB->uxPriority )
						{
							xSwitchRequired = pdTRUE;
    1e38:	ee 24       	eor	r14, r14
    1e3a:	e3 94       	inc	r14
		look any further down the list. */
		if( xConstTickCount >= xNextTaskUnblockTime )
		{
			for( ;; )
			{
				if( listLIST_IS_EMPTY( pxDelayedTaskList ) != pdFALSE )
    1e3c:	e0 91 9b 06 	lds	r30, 0x069B
    1e40:	f0 91 9c 06 	lds	r31, 0x069C
    1e44:	80 81       	ld	r24, Z
    1e46:	88 23       	and	r24, r24
    1e48:	39 f4       	brne	.+14     	; 0x1e58 <xTaskIncrementTick+0x9c>
					/* The delayed list is empty.  Set xNextTaskUnblockTime
					to the maximum possible value so it is extremely
					unlikely that the
					if( xTickCount >= xNextTaskUnblockTime ) test will pass
					next time through. */
					xNextTaskUnblockTime = portMAX_DELAY; /*lint !e961 MISRA exception as the casts are only redundant for some ports. */
    1e4a:	8f ef       	ldi	r24, 0xFF	; 255
    1e4c:	9f ef       	ldi	r25, 0xFF	; 255
    1e4e:	90 93 8f 06 	sts	0x068F, r25
    1e52:	80 93 8e 06 	sts	0x068E, r24
					break;
    1e56:	41 c0       	rjmp	.+130    	; 0x1eda <xTaskIncrementTick+0x11e>
				{
					/* The delayed list is not empty, get the value of the
					item at the head of the delayed list.  This is the time
					at which the task at the head of the delayed list must
					be removed from the Blocked state. */
					pxTCB = listGET_OWNER_OF_HEAD_ENTRY( pxDelayedTaskList ); /*lint !e9079 void * is used as this macro is used with timers and co-routines too.  Alignment is known to be fine as the type of the pointer stored and retrieved is the same. */
    1e58:	e0 91 9b 06 	lds	r30, 0x069B
    1e5c:	f0 91 9c 06 	lds	r31, 0x069C
    1e60:	05 80       	ldd	r0, Z+5	; 0x05
    1e62:	f6 81       	ldd	r31, Z+6	; 0x06
    1e64:	e0 2d       	mov	r30, r0
    1e66:	c6 81       	ldd	r28, Z+6	; 0x06
    1e68:	d7 81       	ldd	r29, Z+7	; 0x07
					xItemValue = listGET_LIST_ITEM_VALUE( &( pxTCB->xStateListItem ) );
    1e6a:	8a 81       	ldd	r24, Y+2	; 0x02
    1e6c:	9b 81       	ldd	r25, Y+3	; 0x03

					if( xConstTickCount < xItemValue )
    1e6e:	c8 16       	cp	r12, r24
    1e70:	d9 06       	cpc	r13, r25
    1e72:	28 f4       	brcc	.+10     	; 0x1e7e <xTaskIncrementTick+0xc2>
						/* It is not time to unblock this item yet, but the
						item value is the time at which the task at the head
						of the blocked list must be removed from the Blocked
						state -	so record the item value in
						xNextTaskUnblockTime. */
						xNextTaskUnblockTime = xItemValue;
    1e74:	90 93 8f 06 	sts	0x068F, r25
    1e78:	80 93 8e 06 	sts	0x068E, r24
						break; /*lint !e9011 Code structure here is deedmed easier to understand with multiple breaks. */
    1e7c:	2e c0       	rjmp	.+92     	; 0x1eda <xTaskIncrementTick+0x11e>
					{
						mtCOVERAGE_TEST_MARKER();
					}

					/* It is time to remove the item from the Blocked state. */
					( void ) uxListRemove( &( pxTCB->xStateListItem ) );
    1e7e:	8e 01       	movw	r16, r28
    1e80:	0e 5f       	subi	r16, 0xFE	; 254
    1e82:	1f 4f       	sbci	r17, 0xFF	; 255
    1e84:	c8 01       	movw	r24, r16
    1e86:	0e 94 4a 05 	call	0xa94	; 0xa94 <uxListRemove>

					/* Is the task waiting on an event also?  If so remove
					it from the event list. */
					if( listLIST_ITEM_CONTAINER( &( pxTCB->xEventListItem ) ) != NULL )
    1e8a:	8c 89       	ldd	r24, Y+20	; 0x14
    1e8c:	9d 89       	ldd	r25, Y+21	; 0x15
    1e8e:	00 97       	sbiw	r24, 0x00	; 0
    1e90:	21 f0       	breq	.+8      	; 0x1e9a <xTaskIncrementTick+0xde>
					{
						( void ) uxListRemove( &( pxTCB->xEventListItem ) );
    1e92:	ce 01       	movw	r24, r28
    1e94:	0c 96       	adiw	r24, 0x0c	; 12
    1e96:	0e 94 4a 05 	call	0xa94	; 0xa94 <uxListRemove>
						mtCOVERAGE_TEST_MARKER();
					}

					/* Place the unblocked task into the appropriate ready
					list. */
					prvAddTaskToReadyList( pxTCB );
    1e9a:	8e 89       	ldd	r24, Y+22	; 0x16
    1e9c:	90 91 94 06 	lds	r25, 0x0694
    1ea0:	98 17       	cp	r25, r24
    1ea2:	10 f4       	brcc	.+4      	; 0x1ea8 <xTaskIncrementTick+0xec>
    1ea4:	80 93 94 06 	sts	0x0694, r24
    1ea8:	90 e0       	ldi	r25, 0x00	; 0
    1eaa:	9c 01       	movw	r18, r24
    1eac:	22 0f       	add	r18, r18
    1eae:	33 1f       	adc	r19, r19
    1eb0:	22 0f       	add	r18, r18
    1eb2:	33 1f       	adc	r19, r19
    1eb4:	22 0f       	add	r18, r18
    1eb6:	33 1f       	adc	r19, r19
    1eb8:	82 0f       	add	r24, r18
    1eba:	93 1f       	adc	r25, r19
    1ebc:	82 56       	subi	r24, 0x62	; 98
    1ebe:	99 4f       	sbci	r25, 0xF9	; 249
    1ec0:	b8 01       	movw	r22, r16
    1ec2:	0e 94 f9 04 	call	0x9f2	; 0x9f2 <vListInsertEnd>
					{
						/* Preemption is on, but a context switch should
						only be performed if the unblocked task has a
						priority that is equal to or higher than the
						currently executing task. */
						if( pxTCB->uxPriority >= pxCurrentTCB->uxPriority )
    1ec6:	e0 91 8b 06 	lds	r30, 0x068B
    1eca:	f0 91 8c 06 	lds	r31, 0x068C
    1ece:	9e 89       	ldd	r25, Y+22	; 0x16
    1ed0:	86 89       	ldd	r24, Z+22	; 0x16
    1ed2:	98 17       	cp	r25, r24
    1ed4:	08 f0       	brcs	.+2      	; 0x1ed8 <xTaskIncrementTick+0x11c>
    1ed6:	ad cf       	rjmp	.-166    	; 0x1e32 <xTaskIncrementTick+0x76>
    1ed8:	b1 cf       	rjmp	.-158    	; 0x1e3c <xTaskIncrementTick+0x80>
		/* Tasks of equal priority to the currently running task will share
		processing time (time slice) if preemption is on, and the application
		writer has not explicitly turned time slicing off. */
		#if ( ( configUSE_PREEMPTION == 1 ) && ( configUSE_TIME_SLICING == 1 ) )
		{
			if( listCURRENT_LIST_LENGTH( &( pxReadyTasksLists[ pxCurrentTCB->uxPriority ] ) ) > ( UBaseType_t ) 1 )
    1eda:	e0 91 8b 06 	lds	r30, 0x068B
    1ede:	f0 91 8c 06 	lds	r31, 0x068C
    1ee2:	86 89       	ldd	r24, Z+22	; 0x16
    1ee4:	90 e0       	ldi	r25, 0x00	; 0
    1ee6:	fc 01       	movw	r30, r24
    1ee8:	ee 0f       	add	r30, r30
    1eea:	ff 1f       	adc	r31, r31
    1eec:	ee 0f       	add	r30, r30
    1eee:	ff 1f       	adc	r31, r31
    1ef0:	ee 0f       	add	r30, r30
    1ef2:	ff 1f       	adc	r31, r31
    1ef4:	8e 0f       	add	r24, r30
    1ef6:	9f 1f       	adc	r25, r31
    1ef8:	fc 01       	movw	r30, r24
    1efa:	e2 56       	subi	r30, 0x62	; 98
    1efc:	f9 4f       	sbci	r31, 0xF9	; 249
    1efe:	80 81       	ld	r24, Z
    1f00:	82 30       	cpi	r24, 0x02	; 2
    1f02:	40 f4       	brcc	.+16     	; 0x1f14 <xTaskIncrementTick+0x158>
    1f04:	09 c0       	rjmp	.+18     	; 0x1f18 <xTaskIncrementTick+0x15c>
		}
		#endif /* configUSE_TICK_HOOK */
	}
	else
	{
		++uxPendedTicks;
    1f06:	80 91 92 06 	lds	r24, 0x0692
    1f0a:	8f 5f       	subi	r24, 0xFF	; 255
    1f0c:	80 93 92 06 	sts	0x0692, r24

BaseType_t xTaskIncrementTick( void )
{
TCB_t * pxTCB;
TickType_t xItemValue;
BaseType_t xSwitchRequired = pdFALSE;
    1f10:	ff 24       	eor	r15, r15
    1f12:	02 c0       	rjmp	.+4      	; 0x1f18 <xTaskIncrementTick+0x15c>
		writer has not explicitly turned time slicing off. */
		#if ( ( configUSE_PREEMPTION == 1 ) && ( configUSE_TIME_SLICING == 1 ) )
		{
			if( listCURRENT_LIST_LENGTH( &( pxReadyTasksLists[ pxCurrentTCB->uxPriority ] ) ) > ( UBaseType_t ) 1 )
			{
				xSwitchRequired = pdTRUE;
    1f14:	ff 24       	eor	r15, r15
    1f16:	f3 94       	inc	r15
		#endif
	}

	#if ( configUSE_PREEMPTION == 1 )
	{
		if( xYieldPending != pdFALSE )
    1f18:	80 91 91 06 	lds	r24, 0x0691
    1f1c:	88 23       	and	r24, r24
    1f1e:	11 f0       	breq	.+4      	; 0x1f24 <xTaskIncrementTick+0x168>
		{
			xSwitchRequired = pdTRUE;
    1f20:	ff 24       	eor	r15, r15
    1f22:	f3 94       	inc	r15
		}
	}
	#endif /* configUSE_PREEMPTION */

	return xSwitchRequired;
}
    1f24:	8f 2d       	mov	r24, r15
    1f26:	df 91       	pop	r29
    1f28:	cf 91       	pop	r28
    1f2a:	1f 91       	pop	r17
    1f2c:	0f 91       	pop	r16
    1f2e:	ff 90       	pop	r15
    1f30:	ef 90       	pop	r14
    1f32:	df 90       	pop	r13
    1f34:	cf 90       	pop	r12
    1f36:	08 95       	ret

00001f38 <xTaskResumeAll>:

#endif /* configUSE_TICKLESS_IDLE */
/*----------------------------------------------------------*/

BaseType_t xTaskResumeAll( void )
{
    1f38:	df 92       	push	r13
    1f3a:	ef 92       	push	r14
    1f3c:	ff 92       	push	r15
    1f3e:	0f 93       	push	r16
    1f40:	1f 93       	push	r17
    1f42:	cf 93       	push	r28
    1f44:	df 93       	push	r29
	/* It is possible that an ISR caused a task to be removed from an event
	list while the scheduler was suspended.  If this was the case then the
	removed task will have been added to the xPendingReadyList.  Once the
	scheduler has been resumed it is safe to move all the pending ready
	tasks from this list into their appropriate ready list. */
	taskENTER_CRITICAL();
    1f46:	0f b6       	in	r0, 0x3f	; 63
    1f48:	f8 94       	cli
    1f4a:	0f 92       	push	r0
	{
		--uxSchedulerSuspended;
    1f4c:	80 91 8d 06 	lds	r24, 0x068D
    1f50:	81 50       	subi	r24, 0x01	; 1
    1f52:	80 93 8d 06 	sts	0x068D, r24

		if( uxSchedulerSuspended == ( UBaseType_t ) pdFALSE )
    1f56:	80 91 8d 06 	lds	r24, 0x068D
    1f5a:	88 23       	and	r24, r24
    1f5c:	09 f0       	breq	.+2      	; 0x1f60 <xTaskResumeAll+0x28>
    1f5e:	5f c0       	rjmp	.+190    	; 0x201e <xTaskResumeAll+0xe6>
		{
			if( uxCurrentNumberOfTasks > ( UBaseType_t ) 0U )
    1f60:	80 91 97 06 	lds	r24, 0x0697
    1f64:	88 23       	and	r24, r24
    1f66:	91 f5       	brne	.+100    	; 0x1fcc <xTaskResumeAll+0x94>
    1f68:	5d c0       	rjmp	.+186    	; 0x2024 <xTaskResumeAll+0xec>
			{
				/* Move any readied tasks from the pending list into the
				appropriate ready list. */
				while( listLIST_IS_EMPTY( &xPendingReadyList ) == pdFALSE )
				{
					pxTCB = listGET_OWNER_OF_HEAD_ENTRY( ( &xPendingReadyList ) ); /*lint !e9079 void * is used as this macro is used with timers and co-routines too.  Alignment is known to be fine as the type of the pointer stored and retrieved is the same. */
    1f6a:	e0 91 d9 06 	lds	r30, 0x06D9
    1f6e:	f0 91 da 06 	lds	r31, 0x06DA
    1f72:	c6 81       	ldd	r28, Z+6	; 0x06
    1f74:	d7 81       	ldd	r29, Z+7	; 0x07
					( void ) uxListRemove( &( pxTCB->xEventListItem ) );
    1f76:	ce 01       	movw	r24, r28
    1f78:	0c 96       	adiw	r24, 0x0c	; 12
    1f7a:	0e 94 4a 05 	call	0xa94	; 0xa94 <uxListRemove>
					( void ) uxListRemove( &( pxTCB->xStateListItem ) );
    1f7e:	8e 01       	movw	r16, r28
    1f80:	0e 5f       	subi	r16, 0xFE	; 254
    1f82:	1f 4f       	sbci	r17, 0xFF	; 255
    1f84:	c8 01       	movw	r24, r16
    1f86:	0e 94 4a 05 	call	0xa94	; 0xa94 <uxListRemove>
					prvAddTaskToReadyList( pxTCB );
    1f8a:	8e 89       	ldd	r24, Y+22	; 0x16
    1f8c:	90 91 94 06 	lds	r25, 0x0694
    1f90:	98 17       	cp	r25, r24
    1f92:	10 f4       	brcc	.+4      	; 0x1f98 <xTaskResumeAll+0x60>
    1f94:	80 93 94 06 	sts	0x0694, r24
    1f98:	90 e0       	ldi	r25, 0x00	; 0
    1f9a:	9c 01       	movw	r18, r24
    1f9c:	22 0f       	add	r18, r18
    1f9e:	33 1f       	adc	r19, r19
    1fa0:	22 0f       	add	r18, r18
    1fa2:	33 1f       	adc	r19, r19
    1fa4:	22 0f       	add	r18, r18
    1fa6:	33 1f       	adc	r19, r19
    1fa8:	82 0f       	add	r24, r18
    1faa:	93 1f       	adc	r25, r19
    1fac:	82 56       	subi	r24, 0x62	; 98
    1fae:	99 4f       	sbci	r25, 0xF9	; 249
    1fb0:	b8 01       	movw	r22, r16
    1fb2:	0e 94 f9 04 	call	0x9f2	; 0x9f2 <vListInsertEnd>

					/* If the moved task has a priority higher than the current
					task then a yield must be performed. */
					if( pxTCB->uxPriority >= pxCurrentTCB->uxPriority )
    1fb6:	e0 91 8b 06 	lds	r30, 0x068B
    1fba:	f0 91 8c 06 	lds	r31, 0x068C
    1fbe:	9e 89       	ldd	r25, Y+22	; 0x16
    1fc0:	86 89       	ldd	r24, Z+22	; 0x16
    1fc2:	98 17       	cp	r25, r24
    1fc4:	68 f0       	brcs	.+26     	; 0x1fe0 <xTaskResumeAll+0xa8>
					{
						xYieldPending = pdTRUE;
    1fc6:	d0 92 91 06 	sts	0x0691, r13
    1fca:	0a c0       	rjmp	.+20     	; 0x1fe0 <xTaskResumeAll+0xa8>
	{
		--uxSchedulerSuspended;

		if( uxSchedulerSuspended == ( UBaseType_t ) pdFALSE )
		{
			if( uxCurrentNumberOfTasks > ( UBaseType_t ) 0U )
    1fcc:	c0 e0       	ldi	r28, 0x00	; 0
    1fce:	d0 e0       	ldi	r29, 0x00	; 0
			{
				/* Move any readied tasks from the pending list into the
				appropriate ready list. */
				while( listLIST_IS_EMPTY( &xPendingReadyList ) == pdFALSE )
    1fd0:	0f 2e       	mov	r0, r31
    1fd2:	f4 ed       	ldi	r31, 0xD4	; 212
    1fd4:	ef 2e       	mov	r14, r31
    1fd6:	f6 e0       	ldi	r31, 0x06	; 6
    1fd8:	ff 2e       	mov	r15, r31
    1fda:	f0 2d       	mov	r31, r0

					/* If the moved task has a priority higher than the current
					task then a yield must be performed. */
					if( pxTCB->uxPriority >= pxCurrentTCB->uxPriority )
					{
						xYieldPending = pdTRUE;
    1fdc:	dd 24       	eor	r13, r13
    1fde:	d3 94       	inc	r13
		{
			if( uxCurrentNumberOfTasks > ( UBaseType_t ) 0U )
			{
				/* Move any readied tasks from the pending list into the
				appropriate ready list. */
				while( listLIST_IS_EMPTY( &xPendingReadyList ) == pdFALSE )
    1fe0:	f7 01       	movw	r30, r14
    1fe2:	80 81       	ld	r24, Z
    1fe4:	88 23       	and	r24, r24
    1fe6:	09 f6       	brne	.-126    	; 0x1f6a <xTaskResumeAll+0x32>
					{
						mtCOVERAGE_TEST_MARKER();
					}
				}

				if( pxTCB != NULL )
    1fe8:	20 97       	sbiw	r28, 0x00	; 0
    1fea:	11 f0       	breq	.+4      	; 0x1ff0 <xTaskResumeAll+0xb8>
					which may have prevented the next unblock time from being
					re-calculated, in which case re-calculate it now.  Mainly
					important for low power tickless implementations, where
					this can prevent an unnecessary exit from low power
					state. */
					prvResetNextTaskUnblockTime();
    1fec:	0e 94 81 0c 	call	0x1902	; 0x1902 <prvResetNextTaskUnblockTime>
				/* If any ticks occurred while the scheduler was suspended then
				they should be processed now.  This ensures the tick count does
				not	slip, and that any delayed tasks are resumed at the correct
				time. */
				{
					UBaseType_t uxPendedCounts = uxPendedTicks; /* Non-volatile copy. */
    1ff0:	c0 91 92 06 	lds	r28, 0x0692

					if( uxPendedCounts > ( UBaseType_t ) 0U )
    1ff4:	cc 23       	and	r28, r28
    1ff6:	59 f0       	breq	.+22     	; 0x200e <xTaskResumeAll+0xd6>
					{
						do
						{
							if( xTaskIncrementTick() != pdFALSE )
							{
								xYieldPending = pdTRUE;
    1ff8:	01 e0       	ldi	r16, 0x01	; 1

					if( uxPendedCounts > ( UBaseType_t ) 0U )
					{
						do
						{
							if( xTaskIncrementTick() != pdFALSE )
    1ffa:	0e 94 de 0e 	call	0x1dbc	; 0x1dbc <xTaskIncrementTick>
    1ffe:	88 23       	and	r24, r24
    2000:	11 f0       	breq	.+4      	; 0x2006 <xTaskResumeAll+0xce>
							{
								xYieldPending = pdTRUE;
    2002:	00 93 91 06 	sts	0x0691, r16
							}
							else
							{
								mtCOVERAGE_TEST_MARKER();
							}
							--uxPendedCounts;
    2006:	c1 50       	subi	r28, 0x01	; 1
						} while( uxPendedCounts > ( UBaseType_t ) 0U );
    2008:	c1 f7       	brne	.-16     	; 0x1ffa <xTaskResumeAll+0xc2>

						uxPendedTicks = 0;
    200a:	10 92 92 06 	sts	0x0692, r1
					{
						mtCOVERAGE_TEST_MARKER();
					}
				}

				if( xYieldPending != pdFALSE )
    200e:	80 91 91 06 	lds	r24, 0x0691
    2012:	88 23       	and	r24, r24
    2014:	31 f0       	breq	.+12     	; 0x2022 <xTaskResumeAll+0xea>
					#if( configUSE_PREEMPTION != 0 )
					{
						xAlreadyYielded = pdTRUE;
					}
					#endif
					taskYIELD_IF_USING_PREEMPTION();
    2016:	0e 94 39 06 	call	0xc72	; 0xc72 <vPortYield>

				if( xYieldPending != pdFALSE )
				{
					#if( configUSE_PREEMPTION != 0 )
					{
						xAlreadyYielded = pdTRUE;
    201a:	81 e0       	ldi	r24, 0x01	; 1
    201c:	03 c0       	rjmp	.+6      	; 0x2024 <xTaskResumeAll+0xec>
/*----------------------------------------------------------*/

BaseType_t xTaskResumeAll( void )
{
TCB_t *pxTCB = NULL;
BaseType_t xAlreadyYielded = pdFALSE;
    201e:	80 e0       	ldi	r24, 0x00	; 0
    2020:	01 c0       	rjmp	.+2      	; 0x2024 <xTaskResumeAll+0xec>
    2022:	80 e0       	ldi	r24, 0x00	; 0
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}
	}
	taskEXIT_CRITICAL();
    2024:	0f 90       	pop	r0
    2026:	0f be       	out	0x3f, r0	; 63

	return xAlreadyYielded;
}
    2028:	df 91       	pop	r29
    202a:	cf 91       	pop	r28
    202c:	1f 91       	pop	r17
    202e:	0f 91       	pop	r16
    2030:	ff 90       	pop	r15
    2032:	ef 90       	pop	r14
    2034:	df 90       	pop	r13
    2036:	08 95       	ret

00002038 <vTaskDelay>:
/*-----------------------------------------------------------*/

#if ( INCLUDE_vTaskDelay == 1 )

	void vTaskDelay( const TickType_t xTicksToDelay )
	{
    2038:	cf 93       	push	r28
    203a:	df 93       	push	r29
    203c:	ec 01       	movw	r28, r24
	BaseType_t xAlreadyYielded = pdFALSE;

		/* A delay time of zero just forces a reschedule. */
		if( xTicksToDelay > ( TickType_t ) 0U )
    203e:	00 97       	sbiw	r24, 0x00	; 0
    2040:	51 f0       	breq	.+20     	; 0x2056 <vTaskDelay+0x1e>
		{
			configASSERT( uxSchedulerSuspended == 0 );
			vTaskSuspendAll();
    2042:	0e 94 be 0e 	call	0x1d7c	; 0x1d7c <vTaskSuspendAll>
				list or removed from the blocked list until the scheduler
				is resumed.

				This task cannot be in an event list as it is the currently
				executing task. */
				prvAddCurrentTaskToDelayedList( xTicksToDelay, pdFALSE );
    2046:	ce 01       	movw	r24, r28
    2048:	60 e0       	ldi	r22, 0x00	; 0
    204a:	0e 94 a0 0c 	call	0x1940	; 0x1940 <prvAddCurrentTaskToDelayedList>
			}
			xAlreadyYielded = xTaskResumeAll();
    204e:	0e 94 9c 0f 	call	0x1f38	; 0x1f38 <xTaskResumeAll>
			mtCOVERAGE_TEST_MARKER();
		}

		/* Force a reschedule if xTaskResumeAll has not already done so, we may
		have put ourselves to sleep. */
		if( xAlreadyYielded == pdFALSE )
    2052:	88 23       	and	r24, r24
    2054:	11 f4       	brne	.+4      	; 0x205a <vTaskDelay+0x22>
		{
			portYIELD_WITHIN_API();
    2056:	0e 94 39 06 	call	0xc72	; 0xc72 <vPortYield>
		}
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}
	}
    205a:	df 91       	pop	r29
    205c:	cf 91       	pop	r28
    205e:	08 95       	ret

00002060 <vTaskDelayUntil>:
/*-----------------------------------------------------------*/

#if ( INCLUDE_vTaskDelayUntil == 1 )

	void vTaskDelayUntil( TickType_t * const pxPreviousWakeTime, const TickType_t xTimeIncrement )
	{
    2060:	0f 93       	push	r16
    2062:	1f 93       	push	r17
    2064:	cf 93       	push	r28
    2066:	df 93       	push	r29
    2068:	8c 01       	movw	r16, r24
    206a:	eb 01       	movw	r28, r22

		configASSERT( pxPreviousWakeTime );
		configASSERT( ( xTimeIncrement > 0U ) );
		configASSERT( uxSchedulerSuspended == 0 );

		vTaskSuspendAll();
    206c:	0e 94 be 0e 	call	0x1d7c	; 0x1d7c <vTaskSuspendAll>
		{
			/* Minor optimisation.  The tick count cannot change in this
			block. */
			const TickType_t xConstTickCount = xTickCount;
    2070:	80 91 95 06 	lds	r24, 0x0695
    2074:	90 91 96 06 	lds	r25, 0x0696

			/* Generate the tick time at which the task wants to wake. */
			xTimeToWake = *pxPreviousWakeTime + xTimeIncrement;
    2078:	f8 01       	movw	r30, r16
    207a:	20 81       	ld	r18, Z
    207c:	31 81       	ldd	r19, Z+1	; 0x01
    207e:	c2 0f       	add	r28, r18
    2080:	d3 1f       	adc	r29, r19

			if( xConstTickCount < *pxPreviousWakeTime )
    2082:	82 17       	cp	r24, r18
    2084:	93 07       	cpc	r25, r19
    2086:	48 f4       	brcc	.+18     	; 0x209a <vTaskDelayUntil+0x3a>
				/* The tick count has overflowed since this function was
				lasted called.  In this case the only time we should ever
				actually delay is if the wake time has also	overflowed,
				and the wake time is greater than the tick time.  When this
				is the case it is as if neither time had overflowed. */
				if( ( xTimeToWake < *pxPreviousWakeTime ) && ( xTimeToWake > xConstTickCount ) )
    2088:	c2 17       	cp	r28, r18
    208a:	d3 07       	cpc	r29, r19
    208c:	f8 f4       	brcc	.+62     	; 0x20cc <vTaskDelayUntil+0x6c>
					mtCOVERAGE_TEST_MARKER();
				}
			}

			/* Update the wake time ready for the next call. */
			*pxPreviousWakeTime = xTimeToWake;
    208e:	d1 83       	std	Z+1, r29	; 0x01
    2090:	c0 83       	st	Z, r28

			if( xShouldDelay != pdFALSE )
    2092:	8c 17       	cp	r24, r28
    2094:	9d 07       	cpc	r25, r29
    2096:	78 f4       	brcc	.+30     	; 0x20b6 <vTaskDelayUntil+0x56>
    2098:	07 c0       	rjmp	.+14     	; 0x20a8 <vTaskDelayUntil+0x48>
			else
			{
				/* The tick time has not overflowed.  In this case we will
				delay if either the wake time has overflowed, and/or the
				tick time is less than the wake time. */
				if( ( xTimeToWake < *pxPreviousWakeTime ) || ( xTimeToWake > xConstTickCount ) )
    209a:	c2 17       	cp	r28, r18
    209c:	d3 07       	cpc	r29, r19
    209e:	90 f0       	brcs	.+36     	; 0x20c4 <vTaskDelayUntil+0x64>
    20a0:	8c 17       	cp	r24, r28
    20a2:	9d 07       	cpc	r25, r29
    20a4:	78 f0       	brcs	.+30     	; 0x20c4 <vTaskDelayUntil+0x64>
    20a6:	12 c0       	rjmp	.+36     	; 0x20cc <vTaskDelayUntil+0x6c>
			{
				traceTASK_DELAY_UNTIL( xTimeToWake );

				/* prvAddCurrentTaskToDelayedList() needs the block time, not
				the time to wake, so subtract the current tick count. */
				prvAddCurrentTaskToDelayedList( xTimeToWake - xConstTickCount, pdFALSE );
    20a8:	9e 01       	movw	r18, r28
    20aa:	28 1b       	sub	r18, r24
    20ac:	39 0b       	sbc	r19, r25
    20ae:	c9 01       	movw	r24, r18
    20b0:	60 e0       	ldi	r22, 0x00	; 0
    20b2:	0e 94 a0 0c 	call	0x1940	; 0x1940 <prvAddCurrentTaskToDelayedList>
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}
		}
		xAlreadyYielded = xTaskResumeAll();
    20b6:	0e 94 9c 0f 	call	0x1f38	; 0x1f38 <xTaskResumeAll>

		/* Force a reschedule if xTaskResumeAll has not already done so, we may
		have put ourselves to sleep. */
		if( xAlreadyYielded == pdFALSE )
    20ba:	88 23       	and	r24, r24
    20bc:	59 f4       	brne	.+22     	; 0x20d4 <vTaskDelayUntil+0x74>
		{
			portYIELD_WITHIN_API();
    20be:	0e 94 39 06 	call	0xc72	; 0xc72 <vPortYield>
    20c2:	08 c0       	rjmp	.+16     	; 0x20d4 <vTaskDelayUntil+0x74>
					mtCOVERAGE_TEST_MARKER();
				}
			}

			/* Update the wake time ready for the next call. */
			*pxPreviousWakeTime = xTimeToWake;
    20c4:	f8 01       	movw	r30, r16
    20c6:	d1 83       	std	Z+1, r29	; 0x01
    20c8:	c0 83       	st	Z, r28
    20ca:	ee cf       	rjmp	.-36     	; 0x20a8 <vTaskDelayUntil+0x48>
    20cc:	f8 01       	movw	r30, r16
    20ce:	d1 83       	std	Z+1, r29	; 0x01
    20d0:	c0 83       	st	Z, r28
    20d2:	f1 cf       	rjmp	.-30     	; 0x20b6 <vTaskDelayUntil+0x56>
		}
		else
		{
			mtCOVERAGE_TEST_MARKER();
		}
	}
    20d4:	df 91       	pop	r29
    20d6:	cf 91       	pop	r28
    20d8:	1f 91       	pop	r17
    20da:	0f 91       	pop	r16
    20dc:	08 95       	ret

000020de <vTaskSwitchContext>:
#endif /* configUSE_APPLICATION_TASK_TAG */
/*-----------------------------------------------------------*/

void vTaskSwitchContext( void )
{
	if( uxSchedulerSuspended != ( UBaseType_t ) pdFALSE )
    20de:	80 91 8d 06 	lds	r24, 0x068D
    20e2:	88 23       	and	r24, r24
    20e4:	21 f0       	breq	.+8      	; 0x20ee <vTaskSwitchContext+0x10>
	{
		/* The scheduler is currently suspended - do not allow a context
		switch. */
		xYieldPending = pdTRUE;
    20e6:	81 e0       	ldi	r24, 0x01	; 1
    20e8:	80 93 91 06 	sts	0x0691, r24
    20ec:	08 95       	ret
	}
	else
	{
		xYieldPending = pdFALSE;
    20ee:	10 92 91 06 	sts	0x0691, r1
		}
		#endif

		/* Select a new task to run using either the generic C or port
		optimised asm code. */
		taskSELECT_HIGHEST_PRIORITY_TASK(); /*lint !e9079 void * is used as this macro is used with timers and co-routines too.  Alignment is known to be fine as the type of the pointer stored and retrieved is the same. */
    20f2:	20 91 94 06 	lds	r18, 0x0694
    20f6:	82 2f       	mov	r24, r18
    20f8:	90 e0       	ldi	r25, 0x00	; 0
    20fa:	fc 01       	movw	r30, r24
    20fc:	ee 0f       	add	r30, r30
    20fe:	ff 1f       	adc	r31, r31
    2100:	ee 0f       	add	r30, r30
    2102:	ff 1f       	adc	r31, r31
    2104:	ee 0f       	add	r30, r30
    2106:	ff 1f       	adc	r31, r31
    2108:	e8 0f       	add	r30, r24
    210a:	f9 1f       	adc	r31, r25
    210c:	e2 56       	subi	r30, 0x62	; 98
    210e:	f9 4f       	sbci	r31, 0xF9	; 249
    2110:	30 81       	ld	r19, Z
    2112:	33 23       	and	r19, r19
    2114:	89 f4       	brne	.+34     	; 0x2138 <vTaskSwitchContext+0x5a>
    2116:	21 50       	subi	r18, 0x01	; 1
    2118:	82 2f       	mov	r24, r18
    211a:	90 e0       	ldi	r25, 0x00	; 0
    211c:	fc 01       	movw	r30, r24
    211e:	ee 0f       	add	r30, r30
    2120:	ff 1f       	adc	r31, r31
    2122:	ee 0f       	add	r30, r30
    2124:	ff 1f       	adc	r31, r31
    2126:	ee 0f       	add	r30, r30
    2128:	ff 1f       	adc	r31, r31
    212a:	e8 0f       	add	r30, r24
    212c:	f9 1f       	adc	r31, r25
    212e:	e2 56       	subi	r30, 0x62	; 98
    2130:	f9 4f       	sbci	r31, 0xF9	; 249
    2132:	30 81       	ld	r19, Z
    2134:	33 23       	and	r19, r19
    2136:	79 f3       	breq	.-34     	; 0x2116 <vTaskSwitchContext+0x38>
    2138:	dc 01       	movw	r26, r24
    213a:	aa 0f       	add	r26, r26
    213c:	bb 1f       	adc	r27, r27
    213e:	aa 0f       	add	r26, r26
    2140:	bb 1f       	adc	r27, r27
    2142:	aa 0f       	add	r26, r26
    2144:	bb 1f       	adc	r27, r27
    2146:	8a 0f       	add	r24, r26
    2148:	9b 1f       	adc	r25, r27
    214a:	dc 01       	movw	r26, r24
    214c:	a2 56       	subi	r26, 0x62	; 98
    214e:	b9 4f       	sbci	r27, 0xF9	; 249
    2150:	11 96       	adiw	r26, 0x01	; 1
    2152:	ed 91       	ld	r30, X+
    2154:	fc 91       	ld	r31, X
    2156:	12 97       	sbiw	r26, 0x02	; 2
    2158:	02 80       	ldd	r0, Z+2	; 0x02
    215a:	f3 81       	ldd	r31, Z+3	; 0x03
    215c:	e0 2d       	mov	r30, r0
    215e:	12 96       	adiw	r26, 0x02	; 2
    2160:	fc 93       	st	X, r31
    2162:	ee 93       	st	-X, r30
    2164:	11 97       	sbiw	r26, 0x01	; 1
    2166:	cd 01       	movw	r24, r26
    2168:	03 96       	adiw	r24, 0x03	; 3
    216a:	e8 17       	cp	r30, r24
    216c:	f9 07       	cpc	r31, r25
    216e:	31 f4       	brne	.+12     	; 0x217c <vTaskSwitchContext+0x9e>
    2170:	82 81       	ldd	r24, Z+2	; 0x02
    2172:	93 81       	ldd	r25, Z+3	; 0x03
    2174:	12 96       	adiw	r26, 0x02	; 2
    2176:	9c 93       	st	X, r25
    2178:	8e 93       	st	-X, r24
    217a:	11 97       	sbiw	r26, 0x01	; 1
    217c:	11 96       	adiw	r26, 0x01	; 1
    217e:	ed 91       	ld	r30, X+
    2180:	fc 91       	ld	r31, X
    2182:	12 97       	sbiw	r26, 0x02	; 2
    2184:	86 81       	ldd	r24, Z+6	; 0x06
    2186:	97 81       	ldd	r25, Z+7	; 0x07
    2188:	90 93 8c 06 	sts	0x068C, r25
    218c:	80 93 8b 06 	sts	0x068B, r24
    2190:	20 93 94 06 	sts	0x0694, r18
    2194:	08 95       	ret

00002196 <vTaskPlaceOnEventList>:
	}
}
/*-----------------------------------------------------------*/

void vTaskPlaceOnEventList( List_t * const pxEventList, const TickType_t xTicksToWait )
{
    2196:	cf 93       	push	r28
    2198:	df 93       	push	r29
    219a:	eb 01       	movw	r28, r22

	/* Place the event list item of the TCB in the appropriate event list.
	This is placed in the list in priority order so the highest priority task
	is the first to be woken by the event.  The queue that contains the event
	list is locked, preventing simultaneous access from interrupts. */
	vListInsert( pxEventList, &( pxCurrentTCB->xEventListItem ) );
    219c:	60 91 8b 06 	lds	r22, 0x068B
    21a0:	70 91 8c 06 	lds	r23, 0x068C
    21a4:	64 5f       	subi	r22, 0xF4	; 244
    21a6:	7f 4f       	sbci	r23, 0xFF	; 255
    21a8:	0e 94 18 05 	call	0xa30	; 0xa30 <vListInsert>

	prvAddCurrentTaskToDelayedList( xTicksToWait, pdTRUE );
    21ac:	ce 01       	movw	r24, r28
    21ae:	61 e0       	ldi	r22, 0x01	; 1
    21b0:	0e 94 a0 0c 	call	0x1940	; 0x1940 <prvAddCurrentTaskToDelayedList>
}
    21b4:	df 91       	pop	r29
    21b6:	cf 91       	pop	r28
    21b8:	08 95       	ret

000021ba <vTaskPlaceOnUnorderedEventList>:
/*-----------------------------------------------------------*/

void vTaskPlaceOnUnorderedEventList( List_t * pxEventList, const TickType_t xItemValue, const TickType_t xTicksToWait )
{
    21ba:	cf 93       	push	r28
    21bc:	df 93       	push	r29
    21be:	ea 01       	movw	r28, r20
	configASSERT( uxSchedulerSuspended != 0 );

	/* Store the item value in the event list item.  It is safe to access the
	event list item here as interrupts won't access the event list item of a
	task that is not in the Blocked state. */
	listSET_LIST_ITEM_VALUE( &( pxCurrentTCB->xEventListItem ), xItemValue | taskEVENT_LIST_ITEM_VALUE_IN_USE );
    21c0:	e0 91 8b 06 	lds	r30, 0x068B
    21c4:	f0 91 8c 06 	lds	r31, 0x068C
    21c8:	70 68       	ori	r23, 0x80	; 128
    21ca:	75 87       	std	Z+13, r23	; 0x0d
    21cc:	64 87       	std	Z+12, r22	; 0x0c
	/* Place the event list item of the TCB at the end of the appropriate event
	list.  It is safe to access the event list here because it is part of an
	event group implementation - and interrupts don't access event groups
	directly (instead they access them indirectly by pending function calls to
	the task level). */
	vListInsertEnd( pxEventList, &( pxCurrentTCB->xEventListItem ) );
    21ce:	60 91 8b 06 	lds	r22, 0x068B
    21d2:	70 91 8c 06 	lds	r23, 0x068C
    21d6:	64 5f       	subi	r22, 0xF4	; 244
    21d8:	7f 4f       	sbci	r23, 0xFF	; 255
    21da:	0e 94 f9 04 	call	0x9f2	; 0x9f2 <vListInsertEnd>

	prvAddCurrentTaskToDelayedList( xTicksToWait, pdTRUE );
    21de:	ce 01       	movw	r24, r28
    21e0:	61 e0       	ldi	r22, 0x01	; 1
    21e2:	0e 94 a0 0c 	call	0x1940	; 0x1940 <prvAddCurrentTaskToDelayedList>
}
    21e6:	df 91       	pop	r29
    21e8:	cf 91       	pop	r28
    21ea:	08 95       	ret

000021ec <xTaskRemoveFromEventList>:

#endif /* configUSE_TIMERS */
/*-----------------------------------------------------------*/

BaseType_t xTaskRemoveFromEventList( const List_t * const pxEventList )
{
    21ec:	0f 93       	push	r16
    21ee:	1f 93       	push	r17
    21f0:	cf 93       	push	r28
    21f2:	df 93       	push	r29
	get called - the lock count on the queue will get modified instead.  This
	means exclusive access to the event list is guaranteed here.

	This function assumes that a check has already been made to ensure that
	pxEventList is not empty. */
	pxUnblockedTCB = listGET_OWNER_OF_HEAD_ENTRY( pxEventList ); /*lint !e9079 void * is used as this macro is used with timers and co-routines too.  Alignment is known to be fine as the type of the pointer stored and retrieved is the same. */
    21f4:	dc 01       	movw	r26, r24
    21f6:	15 96       	adiw	r26, 0x05	; 5
    21f8:	ed 91       	ld	r30, X+
    21fa:	fc 91       	ld	r31, X
    21fc:	16 97       	sbiw	r26, 0x06	; 6
    21fe:	06 81       	ldd	r16, Z+6	; 0x06
    2200:	17 81       	ldd	r17, Z+7	; 0x07
	configASSERT( pxUnblockedTCB );
	( void ) uxListRemove( &( pxUnblockedTCB->xEventListItem ) );
    2202:	e8 01       	movw	r28, r16
    2204:	2c 96       	adiw	r28, 0x0c	; 12
    2206:	ce 01       	movw	r24, r28
    2208:	0e 94 4a 05 	call	0xa94	; 0xa94 <uxListRemove>

	if( uxSchedulerSuspended == ( UBaseType_t ) pdFALSE )
    220c:	80 91 8d 06 	lds	r24, 0x068D
    2210:	88 23       	and	r24, r24
    2212:	e9 f4       	brne	.+58     	; 0x224e <xTaskRemoveFromEventList+0x62>
	{
		( void ) uxListRemove( &( pxUnblockedTCB->xStateListItem ) );
    2214:	e8 01       	movw	r28, r16
    2216:	22 96       	adiw	r28, 0x02	; 2
    2218:	ce 01       	movw	r24, r28
    221a:	0e 94 4a 05 	call	0xa94	; 0xa94 <uxListRemove>
		prvAddTaskToReadyList( pxUnblockedTCB );
    221e:	f8 01       	movw	r30, r16
    2220:	86 89       	ldd	r24, Z+22	; 0x16
    2222:	90 91 94 06 	lds	r25, 0x0694
    2226:	98 17       	cp	r25, r24
    2228:	10 f4       	brcc	.+4      	; 0x222e <xTaskRemoveFromEventList+0x42>
    222a:	80 93 94 06 	sts	0x0694, r24
    222e:	90 e0       	ldi	r25, 0x00	; 0
    2230:	9c 01       	movw	r18, r24
    2232:	22 0f       	add	r18, r18
    2234:	33 1f       	adc	r19, r19
    2236:	22 0f       	add	r18, r18
    2238:	33 1f       	adc	r19, r19
    223a:	22 0f       	add	r18, r18
    223c:	33 1f       	adc	r19, r19
    223e:	82 0f       	add	r24, r18
    2240:	93 1f       	adc	r25, r19
    2242:	82 56       	subi	r24, 0x62	; 98
    2244:	99 4f       	sbci	r25, 0xF9	; 249
    2246:	be 01       	movw	r22, r28
    2248:	0e 94 f9 04 	call	0x9f2	; 0x9f2 <vListInsertEnd>
    224c:	05 c0       	rjmp	.+10     	; 0x2258 <xTaskRemoveFromEventList+0x6c>
	}
	else
	{
		/* The delayed and ready lists cannot be accessed, so hold this task
		pending until the scheduler is resumed. */
		vListInsertEnd( &( xPendingReadyList ), &( pxUnblockedTCB->xEventListItem ) );
    224e:	84 ed       	ldi	r24, 0xD4	; 212
    2250:	96 e0       	ldi	r25, 0x06	; 6
    2252:	be 01       	movw	r22, r28
    2254:	0e 94 f9 04 	call	0x9f2	; 0x9f2 <vListInsertEnd>
	}

	if( pxUnblockedTCB->uxPriority > pxCurrentTCB->uxPriority )
    2258:	e0 91 8b 06 	lds	r30, 0x068B
    225c:	f0 91 8c 06 	lds	r31, 0x068C
    2260:	d8 01       	movw	r26, r16
    2262:	56 96       	adiw	r26, 0x16	; 22
    2264:	9c 91       	ld	r25, X
    2266:	56 97       	sbiw	r26, 0x16	; 22
    2268:	86 89       	ldd	r24, Z+22	; 0x16
    226a:	89 17       	cp	r24, r25
    226c:	20 f4       	brcc	.+8      	; 0x2276 <xTaskRemoveFromEventList+0x8a>
		it should force a context switch now. */
		xReturn = pdTRUE;

		/* Mark that a yield is pending in case the user is not using the
		"xHigherPriorityTaskWoken" parameter to an ISR safe FreeRTOS function. */
		xYieldPending = pdTRUE;
    226e:	81 e0       	ldi	r24, 0x01	; 1
    2270:	80 93 91 06 	sts	0x0691, r24
    2274:	01 c0       	rjmp	.+2      	; 0x2278 <xTaskRemoveFromEventList+0x8c>
	}
	else
	{
		xReturn = pdFALSE;
    2276:	80 e0       	ldi	r24, 0x00	; 0
	}

	return xReturn;
}
    2278:	df 91       	pop	r29
    227a:	cf 91       	pop	r28
    227c:	1f 91       	pop	r17
    227e:	0f 91       	pop	r16
    2280:	08 95       	ret

00002282 <vTaskRemoveFromUnorderedEventList>:
/*-----------------------------------------------------------*/

void vTaskRemoveFromUnorderedEventList( ListItem_t * pxEventListItem, const TickType_t xItemValue )
{
    2282:	0f 93       	push	r16
    2284:	1f 93       	push	r17
    2286:	cf 93       	push	r28
    2288:	df 93       	push	r29
	/* THIS FUNCTION MUST BE CALLED WITH THE SCHEDULER SUSPENDED.  It is used by
	the event flags implementation. */
	configASSERT( uxSchedulerSuspended != pdFALSE );

	/* Store the new item value in the event list. */
	listSET_LIST_ITEM_VALUE( pxEventListItem, xItemValue | taskEVENT_LIST_ITEM_VALUE_IN_USE );
    228a:	70 68       	ori	r23, 0x80	; 128
    228c:	fc 01       	movw	r30, r24
    228e:	71 83       	std	Z+1, r23	; 0x01
    2290:	60 83       	st	Z, r22

	/* Remove the event list form the event flag.  Interrupts do not access
	event flags. */
	pxUnblockedTCB = listGET_LIST_ITEM_OWNER( pxEventListItem ); /*lint !e9079 void * is used as this macro is used with timers and co-routines too.  Alignment is known to be fine as the type of the pointer stored and retrieved is the same. */
    2292:	c6 81       	ldd	r28, Z+6	; 0x06
    2294:	d7 81       	ldd	r29, Z+7	; 0x07
	configASSERT( pxUnblockedTCB );
	( void ) uxListRemove( pxEventListItem );
    2296:	0e 94 4a 05 	call	0xa94	; 0xa94 <uxListRemove>

	/* Remove the task from the delayed list and add it to the ready list.  The
	scheduler is suspended so interrupts will not be accessing the ready
	lists. */
	( void ) uxListRemove( &( pxUnblockedTCB->xStateListItem ) );
    229a:	8e 01       	movw	r16, r28
    229c:	0e 5f       	subi	r16, 0xFE	; 254
    229e:	1f 4f       	sbci	r17, 0xFF	; 255
    22a0:	c8 01       	movw	r24, r16
    22a2:	0e 94 4a 05 	call	0xa94	; 0xa94 <uxListRemove>
	prvAddTaskToReadyList( pxUnblockedTCB );
    22a6:	8e 89       	ldd	r24, Y+22	; 0x16
    22a8:	90 91 94 06 	lds	r25, 0x0694
    22ac:	98 17       	cp	r25, r24
    22ae:	10 f4       	brcc	.+4      	; 0x22b4 <vTaskRemoveFromUnorderedEventList+0x32>
    22b0:	80 93 94 06 	sts	0x0694, r24
    22b4:	90 e0       	ldi	r25, 0x00	; 0
    22b6:	9c 01       	movw	r18, r24
    22b8:	22 0f       	add	r18, r18
    22ba:	33 1f       	adc	r19, r19
    22bc:	22 0f       	add	r18, r18
    22be:	33 1f       	adc	r19, r19
    22c0:	22 0f       	add	r18, r18
    22c2:	33 1f       	adc	r19, r19
    22c4:	82 0f       	add	r24, r18
    22c6:	93 1f       	adc	r25, r19
    22c8:	82 56       	subi	r24, 0x62	; 98
    22ca:	99 4f       	sbci	r25, 0xF9	; 249
    22cc:	b8 01       	movw	r22, r16
    22ce:	0e 94 f9 04 	call	0x9f2	; 0x9f2 <vListInsertEnd>

	if( pxUnblockedTCB->uxPriority > pxCurrentTCB->uxPriority )
    22d2:	e0 91 8b 06 	lds	r30, 0x068B
    22d6:	f0 91 8c 06 	lds	r31, 0x068C
    22da:	9e 89       	ldd	r25, Y+22	; 0x16
    22dc:	86 89       	ldd	r24, Z+22	; 0x16
    22de:	89 17       	cp	r24, r25
    22e0:	18 f4       	brcc	.+6      	; 0x22e8 <vTaskRemoveFromUnorderedEventList+0x66>
	{
		/* The unblocked task has a priority above that of the calling task, so
		a context switch is required.  This function is called with the
		scheduler suspended so xYieldPending is set so the context switch
		occurs immediately that the scheduler is resumed (unsuspended). */
		xYieldPending = pdTRUE;
    22e2:	81 e0       	ldi	r24, 0x01	; 1
    22e4:	80 93 91 06 	sts	0x0691, r24
	}
}
    22e8:	df 91       	pop	r29
    22ea:	cf 91       	pop	r28
    22ec:	1f 91       	pop	r17
    22ee:	0f 91       	pop	r16
    22f0:	08 95       	ret

000022f2 <vTaskSetTimeOutState>:
/*-----------------------------------------------------------*/

void vTaskSetTimeOutState( TimeOut_t * const pxTimeOut )
{
    22f2:	fc 01       	movw	r30, r24
	configASSERT( pxTimeOut );
	taskENTER_CRITICAL();
    22f4:	0f b6       	in	r0, 0x3f	; 63
    22f6:	f8 94       	cli
    22f8:	0f 92       	push	r0
	{
		pxTimeOut->xOverflowCount = xNumOfOverflows;
    22fa:	80 91 90 06 	lds	r24, 0x0690
    22fe:	80 83       	st	Z, r24
		pxTimeOut->xTimeOnEntering = xTickCount;
    2300:	80 91 95 06 	lds	r24, 0x0695
    2304:	90 91 96 06 	lds	r25, 0x0696
    2308:	92 83       	std	Z+2, r25	; 0x02
    230a:	81 83       	std	Z+1, r24	; 0x01
	}
	taskEXIT_CRITICAL();
    230c:	0f 90       	pop	r0
    230e:	0f be       	out	0x3f, r0	; 63
}
    2310:	08 95       	ret

00002312 <vTaskInternalSetTimeOutState>:
/*-----------------------------------------------------------*/

void vTaskInternalSetTimeOutState( TimeOut_t * const pxTimeOut )
{
    2312:	fc 01       	movw	r30, r24
	/* For internal use only as it does not use a critical section. */
	pxTimeOut->xOverflowCount = xNumOfOverflows;
    2314:	80 91 90 06 	lds	r24, 0x0690
    2318:	80 83       	st	Z, r24
	pxTimeOut->xTimeOnEntering = xTickCount;
    231a:	80 91 95 06 	lds	r24, 0x0695
    231e:	90 91 96 06 	lds	r25, 0x0696
    2322:	92 83       	std	Z+2, r25	; 0x02
    2324:	81 83       	std	Z+1, r24	; 0x01
}
    2326:	08 95       	ret

00002328 <xTaskCheckForTimeOut>:
/*-----------------------------------------------------------*/

BaseType_t xTaskCheckForTimeOut( TimeOut_t * const pxTimeOut, TickType_t * const pxTicksToWait )
{
    2328:	fc 01       	movw	r30, r24
    232a:	db 01       	movw	r26, r22
BaseType_t xReturn;

	configASSERT( pxTimeOut );
	configASSERT( pxTicksToWait );

	taskENTER_CRITICAL();
    232c:	0f b6       	in	r0, 0x3f	; 63
    232e:	f8 94       	cli
    2330:	0f 92       	push	r0
	{
		/* Minor optimisation.  The tick count cannot change in this block. */
		const TickType_t xConstTickCount = xTickCount;
    2332:	20 91 95 06 	lds	r18, 0x0695
    2336:	30 91 96 06 	lds	r19, 0x0696
		const TickType_t xElapsedTime = xConstTickCount - pxTimeOut->xTimeOnEntering;
    233a:	81 81       	ldd	r24, Z+1	; 0x01
    233c:	92 81       	ldd	r25, Z+2	; 0x02
				xReturn = pdFALSE;
			}
			else
		#endif

		if( ( xNumOfOverflows != pxTimeOut->xOverflowCount ) && ( xConstTickCount >= pxTimeOut->xTimeOnEntering ) ) /*lint !e525 Indentation preferred as is to make code within pre-processor directives clearer. */
    233e:	40 91 90 06 	lds	r20, 0x0690
    2342:	50 81       	ld	r21, Z
    2344:	54 17       	cp	r21, r20
    2346:	19 f0       	breq	.+6      	; 0x234e <xTaskCheckForTimeOut+0x26>
    2348:	28 17       	cp	r18, r24
    234a:	39 07       	cpc	r19, r25
    234c:	b0 f4       	brcc	.+44     	; 0x237a <xTaskCheckForTimeOut+0x52>

	taskENTER_CRITICAL();
	{
		/* Minor optimisation.  The tick count cannot change in this block. */
		const TickType_t xConstTickCount = xTickCount;
		const TickType_t xElapsedTime = xConstTickCount - pxTimeOut->xTimeOnEntering;
    234e:	28 1b       	sub	r18, r24
    2350:	39 0b       	sbc	r19, r25
			vTaskSetTimeOut() was called.  It must have wrapped all the way
			around and gone past again. This passed since vTaskSetTimeout()
			was called. */
			xReturn = pdTRUE;
		}
		else if( xElapsedTime < *pxTicksToWait ) /*lint !e961 Explicit casting is only redundant with some compilers, whereas others require it to prevent integer conversion errors. */
    2352:	8d 91       	ld	r24, X+
    2354:	9c 91       	ld	r25, X
    2356:	11 97       	sbiw	r26, 0x01	; 1
    2358:	28 17       	cp	r18, r24
    235a:	39 07       	cpc	r19, r25
    235c:	48 f4       	brcc	.+18     	; 0x2370 <xTaskCheckForTimeOut+0x48>
		{
			/* Not a genuine timeout. Adjust parameters for time remaining. */
			*pxTicksToWait -= xElapsedTime;
    235e:	82 1b       	sub	r24, r18
    2360:	93 0b       	sbc	r25, r19
    2362:	8d 93       	st	X+, r24
    2364:	9c 93       	st	X, r25
			vTaskInternalSetTimeOutState( pxTimeOut );
    2366:	cf 01       	movw	r24, r30
    2368:	0e 94 89 11 	call	0x2312	; 0x2312 <vTaskInternalSetTimeOutState>
			xReturn = pdFALSE;
    236c:	80 e0       	ldi	r24, 0x00	; 0
    236e:	06 c0       	rjmp	.+12     	; 0x237c <xTaskCheckForTimeOut+0x54>
		}
		else
		{
			*pxTicksToWait = 0;
    2370:	11 96       	adiw	r26, 0x01	; 1
    2372:	1c 92       	st	X, r1
    2374:	1e 92       	st	-X, r1
			xReturn = pdTRUE;
    2376:	81 e0       	ldi	r24, 0x01	; 1
    2378:	01 c0       	rjmp	.+2      	; 0x237c <xTaskCheckForTimeOut+0x54>
			/* The tick count is greater than the time at which
			vTaskSetTimeout() was called, but has also overflowed since
			vTaskSetTimeOut() was called.  It must have wrapped all the way
			around and gone past again. This passed since vTaskSetTimeout()
			was called. */
			xReturn = pdTRUE;
    237a:	81 e0       	ldi	r24, 0x01	; 1
		{
			*pxTicksToWait = 0;
			xReturn = pdTRUE;
		}
	}
	taskEXIT_CRITICAL();
    237c:	0f 90       	pop	r0
    237e:	0f be       	out	0x3f, r0	; 63

	return xReturn;
}
    2380:	08 95       	ret

00002382 <vTaskMissedYield>:
/*-----------------------------------------------------------*/

void vTaskMissedYield( void )
{
	xYieldPending = pdTRUE;
    2382:	81 e0       	ldi	r24, 0x01	; 1
    2384:	80 93 91 06 	sts	0x0691, r24
}
    2388:	08 95       	ret

0000238a <uxTaskResetEventItemValue>:

TickType_t uxTaskResetEventItemValue( void )
{
TickType_t uxReturn;

	uxReturn = listGET_LIST_ITEM_VALUE( &( pxCurrentTCB->xEventListItem ) );
    238a:	e0 91 8b 06 	lds	r30, 0x068B
    238e:	f0 91 8c 06 	lds	r31, 0x068C
    2392:	84 85       	ldd	r24, Z+12	; 0x0c
    2394:	95 85       	ldd	r25, Z+13	; 0x0d

	/* Reset the event list item to its normal value - so it can be used with
	queues and semaphores. */
	listSET_LIST_ITEM_VALUE( &( pxCurrentTCB->xEventListItem ), ( ( TickType_t ) configMAX_PRIORITIES - ( TickType_t ) pxCurrentTCB->uxPriority ) ); /*lint !e961 MISRA exception as the casts are only redundant for some ports. */
    2396:	e0 91 8b 06 	lds	r30, 0x068B
    239a:	f0 91 8c 06 	lds	r31, 0x068C
    239e:	a0 91 8b 06 	lds	r26, 0x068B
    23a2:	b0 91 8c 06 	lds	r27, 0x068C
    23a6:	56 96       	adiw	r26, 0x16	; 22
    23a8:	4c 91       	ld	r20, X
    23aa:	56 97       	sbiw	r26, 0x16	; 22
    23ac:	24 e0       	ldi	r18, 0x04	; 4
    23ae:	30 e0       	ldi	r19, 0x00	; 0
    23b0:	24 1b       	sub	r18, r20
    23b2:	31 09       	sbc	r19, r1
    23b4:	35 87       	std	Z+13, r19	; 0x0d
    23b6:	24 87       	std	Z+12, r18	; 0x0c

	return uxReturn;
}
    23b8:	08 95       	ret

000023ba <ulTaskNotifyTake>:
/*-----------------------------------------------------------*/

#if( configUSE_TASK_NOTIFICATIONS == 1 )

	uint32_t ulTaskNotifyTake( BaseType_t xClearCountOnExit, TickType_t xTicksToWait )
	{
    23ba:	0f 93       	push	r16
    23bc:	1f 93       	push	r17
    23be:	cf 93       	push	r28
    23c0:	c8 2f       	mov	r28, r24
	uint32_t ulReturn;

		taskENTER_CRITICAL();
    23c2:	0f b6       	in	r0, 0x3f	; 63
    23c4:	f8 94       	cli
    23c6:	0f 92       	push	r0
		{
			/* Only block if the notification count is not already non-zero. */
			if( pxCurrentTCB->ulNotifiedValue == 0UL )
    23c8:	e0 91 8b 06 	lds	r30, 0x068B
    23cc:	f0 91 8c 06 	lds	r31, 0x068C
    23d0:	81 a1       	lds	r24, 0x41
    23d2:	92 a1       	lds	r25, 0x42
    23d4:	a3 a1       	lds	r26, 0x43
    23d6:	b4 a1       	lds	r27, 0x44
    23d8:	00 97       	sbiw	r24, 0x00	; 0
    23da:	a1 05       	cpc	r26, r1
    23dc:	b1 05       	cpc	r27, r1
    23de:	79 f4       	brne	.+30     	; 0x23fe <ulTaskNotifyTake+0x44>
			{
				/* Mark this task as waiting for a notification. */
				pxCurrentTCB->ucNotifyState = taskWAITING_NOTIFICATION;
    23e0:	e0 91 8b 06 	lds	r30, 0x068B
    23e4:	f0 91 8c 06 	lds	r31, 0x068C
    23e8:	81 e0       	ldi	r24, 0x01	; 1
    23ea:	85 a3       	lds	r24, 0x55

				if( xTicksToWait > ( TickType_t ) 0 )
    23ec:	61 15       	cp	r22, r1
    23ee:	71 05       	cpc	r23, r1
    23f0:	31 f0       	breq	.+12     	; 0x23fe <ulTaskNotifyTake+0x44>
				{
					prvAddCurrentTaskToDelayedList( xTicksToWait, pdTRUE );
    23f2:	cb 01       	movw	r24, r22
    23f4:	61 e0       	ldi	r22, 0x01	; 1
    23f6:	0e 94 a0 0c 	call	0x1940	; 0x1940 <prvAddCurrentTaskToDelayedList>

					/* All ports are written to allow a yield in a critical
					section (some will yield immediately, others wait until the
					critical section exits) - but it is not something that
					application code should ever do. */
					portYIELD_WITHIN_API();
    23fa:	0e 94 39 06 	call	0xc72	; 0xc72 <vPortYield>
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}
		}
		taskEXIT_CRITICAL();
    23fe:	0f 90       	pop	r0
    2400:	0f be       	out	0x3f, r0	; 63

		taskENTER_CRITICAL();
    2402:	0f b6       	in	r0, 0x3f	; 63
    2404:	f8 94       	cli
    2406:	0f 92       	push	r0
		{
			traceTASK_NOTIFY_TAKE();
			ulReturn = pxCurrentTCB->ulNotifiedValue;
    2408:	e0 91 8b 06 	lds	r30, 0x068B
    240c:	f0 91 8c 06 	lds	r31, 0x068C
    2410:	01 a1       	lds	r16, 0x41
    2412:	12 a1       	lds	r17, 0x42
    2414:	23 a1       	lds	r18, 0x43
    2416:	34 a1       	lds	r19, 0x44

			if( ulReturn != 0UL )
    2418:	01 15       	cp	r16, r1
    241a:	11 05       	cpc	r17, r1
    241c:	21 05       	cpc	r18, r1
    241e:	31 05       	cpc	r19, r1
    2420:	c1 f0       	breq	.+48     	; 0x2452 <ulTaskNotifyTake+0x98>
			{
				if( xClearCountOnExit != pdFALSE )
    2422:	cc 23       	and	r28, r28
    2424:	49 f0       	breq	.+18     	; 0x2438 <ulTaskNotifyTake+0x7e>
				{
					pxCurrentTCB->ulNotifiedValue = 0UL;
    2426:	e0 91 8b 06 	lds	r30, 0x068B
    242a:	f0 91 8c 06 	lds	r31, 0x068C
    242e:	11 a2       	lds	r17, 0x91
    2430:	12 a2       	lds	r17, 0x92
    2432:	13 a2       	lds	r17, 0x93
    2434:	14 a2       	lds	r17, 0x94
    2436:	0d c0       	rjmp	.+26     	; 0x2452 <ulTaskNotifyTake+0x98>
				}
				else
				{
					pxCurrentTCB->ulNotifiedValue = ulReturn - ( uint32_t ) 1;
    2438:	e0 91 8b 06 	lds	r30, 0x068B
    243c:	f0 91 8c 06 	lds	r31, 0x068C
    2440:	d9 01       	movw	r26, r18
    2442:	c8 01       	movw	r24, r16
    2444:	01 97       	sbiw	r24, 0x01	; 1
    2446:	a1 09       	sbc	r26, r1
    2448:	b1 09       	sbc	r27, r1
    244a:	81 a3       	lds	r24, 0x51
    244c:	92 a3       	lds	r25, 0x52
    244e:	a3 a3       	lds	r26, 0x53
    2450:	b4 a3       	lds	r27, 0x54
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}

			pxCurrentTCB->ucNotifyState = taskNOT_WAITING_NOTIFICATION;
    2452:	e0 91 8b 06 	lds	r30, 0x068B
    2456:	f0 91 8c 06 	lds	r31, 0x068C
    245a:	15 a2       	lds	r17, 0x95
		}
		taskEXIT_CRITICAL();
    245c:	0f 90       	pop	r0
    245e:	0f be       	out	0x3f, r0	; 63

		return ulReturn;
	}
    2460:	60 2f       	mov	r22, r16
    2462:	71 2f       	mov	r23, r17
    2464:	82 2f       	mov	r24, r18
    2466:	93 2f       	mov	r25, r19
    2468:	cf 91       	pop	r28
    246a:	1f 91       	pop	r17
    246c:	0f 91       	pop	r16
    246e:	08 95       	ret

00002470 <xTaskNotifyWait>:
/*-----------------------------------------------------------*/

#if( configUSE_TASK_NOTIFICATIONS == 1 )

	BaseType_t xTaskNotifyWait( uint32_t ulBitsToClearOnEntry, uint32_t ulBitsToClearOnExit, uint32_t *pulNotificationValue, TickType_t xTicksToWait )
	{
    2470:	8f 92       	push	r8
    2472:	9f 92       	push	r9
    2474:	af 92       	push	r10
    2476:	bf 92       	push	r11
    2478:	ef 92       	push	r14
    247a:	ff 92       	push	r15
    247c:	0f 93       	push	r16
    247e:	1f 93       	push	r17
    2480:	dc 01       	movw	r26, r24
    2482:	cb 01       	movw	r24, r22
    2484:	49 01       	movw	r8, r18
    2486:	5a 01       	movw	r10, r20
	BaseType_t xReturn;

		taskENTER_CRITICAL();
    2488:	0f b6       	in	r0, 0x3f	; 63
    248a:	f8 94       	cli
    248c:	0f 92       	push	r0
		{
			/* Only block if a notification is not already pending. */
			if( pxCurrentTCB->ucNotifyState != taskNOTIFICATION_RECEIVED )
    248e:	e0 91 8b 06 	lds	r30, 0x068B
    2492:	f0 91 8c 06 	lds	r31, 0x068C
    2496:	25 a1       	lds	r18, 0x45
    2498:	22 30       	cpi	r18, 0x02	; 2
    249a:	19 f1       	breq	.+70     	; 0x24e2 <xTaskNotifyWait+0x72>
			{
				/* Clear bits in the task's notification value as bits may get
				set	by the notifying task or interrupt.  This can be used to
				clear the value to zero. */
				pxCurrentTCB->ulNotifiedValue &= ~ulBitsToClearOnEntry;
    249c:	e0 91 8b 06 	lds	r30, 0x068B
    24a0:	f0 91 8c 06 	lds	r31, 0x068C
    24a4:	41 a1       	lds	r20, 0x41
    24a6:	52 a1       	lds	r21, 0x42
    24a8:	63 a1       	lds	r22, 0x43
    24aa:	74 a1       	lds	r23, 0x44
    24ac:	80 95       	com	r24
    24ae:	90 95       	com	r25
    24b0:	a0 95       	com	r26
    24b2:	b0 95       	com	r27
    24b4:	84 23       	and	r24, r20
    24b6:	95 23       	and	r25, r21
    24b8:	a6 23       	and	r26, r22
    24ba:	b7 23       	and	r27, r23
    24bc:	81 a3       	lds	r24, 0x51
    24be:	92 a3       	lds	r25, 0x52
    24c0:	a3 a3       	lds	r26, 0x53
    24c2:	b4 a3       	lds	r27, 0x54

				/* Mark this task as waiting for a notification. */
				pxCurrentTCB->ucNotifyState = taskWAITING_NOTIFICATION;
    24c4:	e0 91 8b 06 	lds	r30, 0x068B
    24c8:	f0 91 8c 06 	lds	r31, 0x068C
    24cc:	81 e0       	ldi	r24, 0x01	; 1
    24ce:	85 a3       	lds	r24, 0x55

				if( xTicksToWait > ( TickType_t ) 0 )
    24d0:	e1 14       	cp	r14, r1
    24d2:	f1 04       	cpc	r15, r1
    24d4:	31 f0       	breq	.+12     	; 0x24e2 <xTaskNotifyWait+0x72>
				{
					prvAddCurrentTaskToDelayedList( xTicksToWait, pdTRUE );
    24d6:	c7 01       	movw	r24, r14
    24d8:	61 e0       	ldi	r22, 0x01	; 1
    24da:	0e 94 a0 0c 	call	0x1940	; 0x1940 <prvAddCurrentTaskToDelayedList>

					/* All ports are written to allow a yield in a critical
					section (some will yield immediately, others wait until the
					critical section exits) - but it is not something that
					application code should ever do. */
					portYIELD_WITHIN_API();
    24de:	0e 94 39 06 	call	0xc72	; 0xc72 <vPortYield>
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}
		}
		taskEXIT_CRITICAL();
    24e2:	0f 90       	pop	r0
    24e4:	0f be       	out	0x3f, r0	; 63

		taskENTER_CRITICAL();
    24e6:	0f b6       	in	r0, 0x3f	; 63
    24e8:	f8 94       	cli
    24ea:	0f 92       	push	r0
		{
			traceTASK_NOTIFY_WAIT();

			if( pulNotificationValue != NULL )
    24ec:	01 15       	cp	r16, r1
    24ee:	11 05       	cpc	r17, r1
    24f0:	69 f0       	breq	.+26     	; 0x250c <xTaskNotifyWait+0x9c>
			{
				/* Output the current notification value, which may or may not
				have changed. */
				*pulNotificationValue = pxCurrentTCB->ulNotifiedValue;
    24f2:	e0 91 8b 06 	lds	r30, 0x068B
    24f6:	f0 91 8c 06 	lds	r31, 0x068C
    24fa:	81 a1       	lds	r24, 0x41
    24fc:	92 a1       	lds	r25, 0x42
    24fe:	a3 a1       	lds	r26, 0x43
    2500:	b4 a1       	lds	r27, 0x44
    2502:	f8 01       	movw	r30, r16
    2504:	80 83       	st	Z, r24
    2506:	91 83       	std	Z+1, r25	; 0x01
    2508:	a2 83       	std	Z+2, r26	; 0x02
    250a:	b3 83       	std	Z+3, r27	; 0x03

			/* If ucNotifyValue is set then either the task never entered the
			blocked state (because a notification was already pending) or the
			task unblocked because of a notification.  Otherwise the task
			unblocked because of a timeout. */
			if( pxCurrentTCB->ucNotifyState != taskNOTIFICATION_RECEIVED )
    250c:	e0 91 8b 06 	lds	r30, 0x068B
    2510:	f0 91 8c 06 	lds	r31, 0x068C
    2514:	85 a1       	lds	r24, 0x45
    2516:	82 30       	cpi	r24, 0x02	; 2
    2518:	b1 f4       	brne	.+44     	; 0x2546 <xTaskNotifyWait+0xd6>
			}
			else
			{
				/* A notification was already pending or a notification was
				received while the task was waiting. */
				pxCurrentTCB->ulNotifiedValue &= ~ulBitsToClearOnExit;
    251a:	e0 91 8b 06 	lds	r30, 0x068B
    251e:	f0 91 8c 06 	lds	r31, 0x068C
    2522:	81 a1       	lds	r24, 0x41
    2524:	92 a1       	lds	r25, 0x42
    2526:	a3 a1       	lds	r26, 0x43
    2528:	b4 a1       	lds	r27, 0x44
    252a:	80 94       	com	r8
    252c:	90 94       	com	r9
    252e:	a0 94       	com	r10
    2530:	b0 94       	com	r11
    2532:	88 22       	and	r8, r24
    2534:	99 22       	and	r9, r25
    2536:	aa 22       	and	r10, r26
    2538:	bb 22       	and	r11, r27
    253a:	81 a2       	lds	r24, 0x91
    253c:	92 a2       	lds	r25, 0x92
    253e:	a3 a2       	lds	r26, 0x93
    2540:	b4 a2       	lds	r27, 0x94
				xReturn = pdTRUE;
    2542:	81 e0       	ldi	r24, 0x01	; 1
    2544:	01 c0       	rjmp	.+2      	; 0x2548 <xTaskNotifyWait+0xd8>
			task unblocked because of a notification.  Otherwise the task
			unblocked because of a timeout. */
			if( pxCurrentTCB->ucNotifyState != taskNOTIFICATION_RECEIVED )
			{
				/* A notification was not received. */
				xReturn = pdFALSE;
    2546:	80 e0       	ldi	r24, 0x00	; 0
				received while the task was waiting. */
				pxCurrentTCB->ulNotifiedValue &= ~ulBitsToClearOnExit;
				xReturn = pdTRUE;
			}

			pxCurrentTCB->ucNotifyState = taskNOT_WAITING_NOTIFICATION;
    2548:	e0 91 8b 06 	lds	r30, 0x068B
    254c:	f0 91 8c 06 	lds	r31, 0x068C
    2550:	15 a2       	lds	r17, 0x95
		}
		taskEXIT_CRITICAL();
    2552:	0f 90       	pop	r0
    2554:	0f be       	out	0x3f, r0	; 63

		return xReturn;
	}
    2556:	1f 91       	pop	r17
    2558:	0f 91       	pop	r16
    255a:	ff 90       	pop	r15
    255c:	ef 90       	pop	r14
    255e:	bf 90       	pop	r11
    2560:	af 90       	pop	r10
    2562:	9f 90       	pop	r9
    2564:	8f 90       	pop	r8
    2566:	08 95       	ret

00002568 <xTaskGenericNotify>:
/*-----------------------------------------------------------*/

#if( configUSE_TASK_NOTIFICATIONS == 1 )

	BaseType_t xTaskGenericNotify( TaskHandle_t xTaskToNotify, uint32_t ulValue, eNotifyAction eAction, uint32_t *pulPreviousNotificationValue )
	{
    2568:	0f 93       	push	r16
    256a:	1f 93       	push	r17
    256c:	cf 93       	push	r28
    256e:	df 93       	push	r29
    2570:	ec 01       	movw	r28, r24
	uint8_t ucOriginalNotifyState;

		configASSERT( xTaskToNotify );
		pxTCB = xTaskToNotify;

		taskENTER_CRITICAL();
    2572:	0f b6       	in	r0, 0x3f	; 63
    2574:	f8 94       	cli
    2576:	0f 92       	push	r0
		{
			if( pulPreviousNotificationValue != NULL )
    2578:	01 15       	cp	r16, r1
    257a:	11 05       	cpc	r17, r1
    257c:	49 f0       	breq	.+18     	; 0x2590 <xTaskGenericNotify+0x28>
			{
				*pulPreviousNotificationValue = pxTCB->ulNotifiedValue;
    257e:	89 a1       	lds	r24, 0x49
    2580:	9a a1       	lds	r25, 0x4a
    2582:	ab a1       	lds	r26, 0x4b
    2584:	bc a1       	lds	r27, 0x4c
    2586:	f8 01       	movw	r30, r16
    2588:	80 83       	st	Z, r24
    258a:	91 83       	std	Z+1, r25	; 0x01
    258c:	a2 83       	std	Z+2, r26	; 0x02
    258e:	b3 83       	std	Z+3, r27	; 0x03
			}

			ucOriginalNotifyState = pxTCB->ucNotifyState;
    2590:	3d a1       	lds	r19, 0x4d

			pxTCB->ucNotifyState = taskNOTIFICATION_RECEIVED;
    2592:	82 e0       	ldi	r24, 0x02	; 2
    2594:	8d a3       	lds	r24, 0x5d

			switch( eAction )
    2596:	22 30       	cpi	r18, 0x02	; 2
    2598:	b9 f0       	breq	.+46     	; 0x25c8 <xTaskGenericNotify+0x60>
    259a:	23 30       	cpi	r18, 0x03	; 3
    259c:	18 f4       	brcc	.+6      	; 0x25a4 <xTaskGenericNotify+0x3c>
    259e:	21 30       	cpi	r18, 0x01	; 1
    25a0:	51 f5       	brne	.+84     	; 0x25f6 <xTaskGenericNotify+0x8e>
    25a2:	05 c0       	rjmp	.+10     	; 0x25ae <xTaskGenericNotify+0x46>
    25a4:	23 30       	cpi	r18, 0x03	; 3
    25a6:	e1 f0       	breq	.+56     	; 0x25e0 <xTaskGenericNotify+0x78>
    25a8:	24 30       	cpi	r18, 0x04	; 4
    25aa:	29 f5       	brne	.+74     	; 0x25f6 <xTaskGenericNotify+0x8e>
    25ac:	1e c0       	rjmp	.+60     	; 0x25ea <xTaskGenericNotify+0x82>
			{
				case eSetBits	:
					pxTCB->ulNotifiedValue |= ulValue;
    25ae:	89 a1       	lds	r24, 0x49
    25b0:	9a a1       	lds	r25, 0x4a
    25b2:	ab a1       	lds	r26, 0x4b
    25b4:	bc a1       	lds	r27, 0x4c
    25b6:	48 2b       	or	r20, r24
    25b8:	59 2b       	or	r21, r25
    25ba:	6a 2b       	or	r22, r26
    25bc:	7b 2b       	or	r23, r27
    25be:	49 a3       	lds	r20, 0x59
    25c0:	5a a3       	lds	r21, 0x5a
    25c2:	6b a3       	lds	r22, 0x5b
    25c4:	7c a3       	lds	r23, 0x5c
					break;
    25c6:	17 c0       	rjmp	.+46     	; 0x25f6 <xTaskGenericNotify+0x8e>

				case eIncrement	:
					( pxTCB->ulNotifiedValue )++;
    25c8:	89 a1       	lds	r24, 0x49
    25ca:	9a a1       	lds	r25, 0x4a
    25cc:	ab a1       	lds	r26, 0x4b
    25ce:	bc a1       	lds	r27, 0x4c
    25d0:	01 96       	adiw	r24, 0x01	; 1
    25d2:	a1 1d       	adc	r26, r1
    25d4:	b1 1d       	adc	r27, r1
    25d6:	89 a3       	lds	r24, 0x59
    25d8:	9a a3       	lds	r25, 0x5a
    25da:	ab a3       	lds	r26, 0x5b
    25dc:	bc a3       	lds	r27, 0x5c
					break;
    25de:	0b c0       	rjmp	.+22     	; 0x25f6 <xTaskGenericNotify+0x8e>

				case eSetValueWithOverwrite	:
					pxTCB->ulNotifiedValue = ulValue;
    25e0:	49 a3       	lds	r20, 0x59
    25e2:	5a a3       	lds	r21, 0x5a
    25e4:	6b a3       	lds	r22, 0x5b
    25e6:	7c a3       	lds	r23, 0x5c
					break;
    25e8:	06 c0       	rjmp	.+12     	; 0x25f6 <xTaskGenericNotify+0x8e>

				case eSetValueWithoutOverwrite :
					if( ucOriginalNotifyState != taskNOTIFICATION_RECEIVED )
    25ea:	32 30       	cpi	r19, 0x02	; 2
    25ec:	71 f1       	breq	.+92     	; 0x264a <xTaskGenericNotify+0xe2>
					{
						pxTCB->ulNotifiedValue = ulValue;
    25ee:	49 a3       	lds	r20, 0x59
    25f0:	5a a3       	lds	r21, 0x5a
    25f2:	6b a3       	lds	r22, 0x5b
    25f4:	7c a3       	lds	r23, 0x5c

			traceTASK_NOTIFY();

			/* If the task is in the blocked state specifically to wait for a
			notification then unblock it now. */
			if( ucOriginalNotifyState == taskWAITING_NOTIFICATION )
    25f6:	31 30       	cpi	r19, 0x01	; 1
    25f8:	51 f5       	brne	.+84     	; 0x264e <xTaskGenericNotify+0xe6>
			{
				( void ) uxListRemove( &( pxTCB->xStateListItem ) );
    25fa:	8e 01       	movw	r16, r28
    25fc:	0e 5f       	subi	r16, 0xFE	; 254
    25fe:	1f 4f       	sbci	r17, 0xFF	; 255
    2600:	c8 01       	movw	r24, r16
    2602:	0e 94 4a 05 	call	0xa94	; 0xa94 <uxListRemove>
				prvAddTaskToReadyList( pxTCB );
    2606:	8e 89       	ldd	r24, Y+22	; 0x16
    2608:	90 91 94 06 	lds	r25, 0x0694
    260c:	98 17       	cp	r25, r24
    260e:	10 f4       	brcc	.+4      	; 0x2614 <xTaskGenericNotify+0xac>
    2610:	80 93 94 06 	sts	0x0694, r24
    2614:	90 e0       	ldi	r25, 0x00	; 0
    2616:	9c 01       	movw	r18, r24
    2618:	22 0f       	add	r18, r18
    261a:	33 1f       	adc	r19, r19
    261c:	22 0f       	add	r18, r18
    261e:	33 1f       	adc	r19, r19
    2620:	22 0f       	add	r18, r18
    2622:	33 1f       	adc	r19, r19
    2624:	82 0f       	add	r24, r18
    2626:	93 1f       	adc	r25, r19
    2628:	82 56       	subi	r24, 0x62	; 98
    262a:	99 4f       	sbci	r25, 0xF9	; 249
    262c:	b8 01       	movw	r22, r16
    262e:	0e 94 f9 04 	call	0x9f2	; 0x9f2 <vListInsertEnd>
					earliest possible time. */
					prvResetNextTaskUnblockTime();
				}
				#endif

				if( pxTCB->uxPriority > pxCurrentTCB->uxPriority )
    2632:	e0 91 8b 06 	lds	r30, 0x068B
    2636:	f0 91 8c 06 	lds	r31, 0x068C
    263a:	9e 89       	ldd	r25, Y+22	; 0x16
    263c:	86 89       	ldd	r24, Z+22	; 0x16
    263e:	89 17       	cp	r24, r25
    2640:	40 f4       	brcc	.+16     	; 0x2652 <xTaskGenericNotify+0xea>
				{
					/* The notified task has a priority above the currently
					executing task so a yield is required. */
					taskYIELD_IF_USING_PREEMPTION();
    2642:	0e 94 39 06 	call	0xc72	; 0xc72 <vPortYield>
    2646:	81 e0       	ldi	r24, 0x01	; 1
    2648:	05 c0       	rjmp	.+10     	; 0x2654 <xTaskGenericNotify+0xec>
						pxTCB->ulNotifiedValue = ulValue;
					}
					else
					{
						/* The value could not be written to the task. */
						xReturn = pdFAIL;
    264a:	80 e0       	ldi	r24, 0x00	; 0
    264c:	03 c0       	rjmp	.+6      	; 0x2654 <xTaskGenericNotify+0xec>

			traceTASK_NOTIFY();

			/* If the task is in the blocked state specifically to wait for a
			notification then unblock it now. */
			if( ucOriginalNotifyState == taskWAITING_NOTIFICATION )
    264e:	81 e0       	ldi	r24, 0x01	; 1
    2650:	01 c0       	rjmp	.+2      	; 0x2654 <xTaskGenericNotify+0xec>
					earliest possible time. */
					prvResetNextTaskUnblockTime();
				}
				#endif

				if( pxTCB->uxPriority > pxCurrentTCB->uxPriority )
    2652:	81 e0       	ldi	r24, 0x01	; 1
			else
			{
				mtCOVERAGE_TEST_MARKER();
			}
		}
		taskEXIT_CRITICAL();
    2654:	0f 90       	pop	r0
    2656:	0f be       	out	0x3f, r0	; 63

		return xReturn;
	}
    2658:	df 91       	pop	r29
    265a:	cf 91       	pop	r28
    265c:	1f 91       	pop	r17
    265e:	0f 91       	pop	r16
    2660:	08 95       	ret

00002662 <xTaskGenericNotifyFromISR>:
/*-----------------------------------------------------------*/

#if( configUSE_TASK_NOTIFICATIONS == 1 )

	BaseType_t xTaskGenericNotifyFromISR( TaskHandle_t xTaskToNotify, uint32_t ulValue, eNotifyAction eAction, uint32_t *pulPreviousNotificationValue, BaseType_t *pxHigherPriorityTaskWoken )
	{
    2662:	ef 92       	push	r14
    2664:	ff 92       	push	r15
    2666:	0f 93       	push	r16
    2668:	1f 93       	push	r17
    266a:	cf 93       	push	r28
    266c:	df 93       	push	r29
    266e:	ec 01       	movw	r28, r24

		pxTCB = xTaskToNotify;

		uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
		{
			if( pulPreviousNotificationValue != NULL )
    2670:	01 15       	cp	r16, r1
    2672:	11 05       	cpc	r17, r1
    2674:	49 f0       	breq	.+18     	; 0x2688 <xTaskGenericNotifyFromISR+0x26>
			{
				*pulPreviousNotificationValue = pxTCB->ulNotifiedValue;
    2676:	89 a1       	lds	r24, 0x49
    2678:	9a a1       	lds	r25, 0x4a
    267a:	ab a1       	lds	r26, 0x4b
    267c:	bc a1       	lds	r27, 0x4c
    267e:	f8 01       	movw	r30, r16
    2680:	80 83       	st	Z, r24
    2682:	91 83       	std	Z+1, r25	; 0x01
    2684:	a2 83       	std	Z+2, r26	; 0x02
    2686:	b3 83       	std	Z+3, r27	; 0x03
			}

			ucOriginalNotifyState = pxTCB->ucNotifyState;
    2688:	3d a1       	lds	r19, 0x4d
			pxTCB->ucNotifyState = taskNOTIFICATION_RECEIVED;
    268a:	82 e0       	ldi	r24, 0x02	; 2
    268c:	8d a3       	lds	r24, 0x5d

			switch( eAction )
    268e:	22 30       	cpi	r18, 0x02	; 2
    2690:	b9 f0       	breq	.+46     	; 0x26c0 <xTaskGenericNotifyFromISR+0x5e>
    2692:	23 30       	cpi	r18, 0x03	; 3
    2694:	18 f4       	brcc	.+6      	; 0x269c <xTaskGenericNotifyFromISR+0x3a>
    2696:	21 30       	cpi	r18, 0x01	; 1
    2698:	59 f5       	brne	.+86     	; 0x26f0 <xTaskGenericNotifyFromISR+0x8e>
    269a:	05 c0       	rjmp	.+10     	; 0x26a6 <xTaskGenericNotifyFromISR+0x44>
    269c:	23 30       	cpi	r18, 0x03	; 3
    269e:	e1 f0       	breq	.+56     	; 0x26d8 <xTaskGenericNotifyFromISR+0x76>
    26a0:	24 30       	cpi	r18, 0x04	; 4
    26a2:	31 f5       	brne	.+76     	; 0x26f0 <xTaskGenericNotifyFromISR+0x8e>
    26a4:	1e c0       	rjmp	.+60     	; 0x26e2 <xTaskGenericNotifyFromISR+0x80>
			{
				case eSetBits	:
					pxTCB->ulNotifiedValue |= ulValue;
    26a6:	89 a1       	lds	r24, 0x49
    26a8:	9a a1       	lds	r25, 0x4a
    26aa:	ab a1       	lds	r26, 0x4b
    26ac:	bc a1       	lds	r27, 0x4c
    26ae:	84 2b       	or	r24, r20
    26b0:	95 2b       	or	r25, r21
    26b2:	a6 2b       	or	r26, r22
    26b4:	b7 2b       	or	r27, r23
    26b6:	89 a3       	lds	r24, 0x59
    26b8:	9a a3       	lds	r25, 0x5a
    26ba:	ab a3       	lds	r26, 0x5b
    26bc:	bc a3       	lds	r27, 0x5c
					break;
    26be:	18 c0       	rjmp	.+48     	; 0x26f0 <xTaskGenericNotifyFromISR+0x8e>

				case eIncrement	:
					( pxTCB->ulNotifiedValue )++;
    26c0:	89 a1       	lds	r24, 0x49
    26c2:	9a a1       	lds	r25, 0x4a
    26c4:	ab a1       	lds	r26, 0x4b
    26c6:	bc a1       	lds	r27, 0x4c
    26c8:	01 96       	adiw	r24, 0x01	; 1
    26ca:	a1 1d       	adc	r26, r1
    26cc:	b1 1d       	adc	r27, r1
    26ce:	89 a3       	lds	r24, 0x59
    26d0:	9a a3       	lds	r25, 0x5a
    26d2:	ab a3       	lds	r26, 0x5b
    26d4:	bc a3       	lds	r27, 0x5c
					break;
    26d6:	0c c0       	rjmp	.+24     	; 0x26f0 <xTaskGenericNotifyFromISR+0x8e>

				case eSetValueWithOverwrite	:
					pxTCB->ulNotifiedValue = ulValue;
    26d8:	49 a3       	lds	r20, 0x59
    26da:	5a a3       	lds	r21, 0x5a
    26dc:	6b a3       	lds	r22, 0x5b
    26de:	7c a3       	lds	r23, 0x5c
					break;
    26e0:	07 c0       	rjmp	.+14     	; 0x26f0 <xTaskGenericNotifyFromISR+0x8e>

				case eSetValueWithoutOverwrite :
					if( ucOriginalNotifyState != taskNOTIFICATION_RECEIVED )
    26e2:	32 30       	cpi	r19, 0x02	; 2
    26e4:	09 f4       	brne	.+2      	; 0x26e8 <xTaskGenericNotifyFromISR+0x86>
    26e6:	40 c0       	rjmp	.+128    	; 0x2768 <xTaskGenericNotifyFromISR+0x106>
					{
						pxTCB->ulNotifiedValue = ulValue;
    26e8:	49 a3       	lds	r20, 0x59
    26ea:	5a a3       	lds	r21, 0x5a
    26ec:	6b a3       	lds	r22, 0x5b
    26ee:	7c a3       	lds	r23, 0x5c

			traceTASK_NOTIFY_FROM_ISR();

			/* If the task is in the blocked state specifically to wait for a
			notification then unblock it now. */
			if( ucOriginalNotifyState == taskWAITING_NOTIFICATION )
    26f0:	31 30       	cpi	r19, 0x01	; 1
    26f2:	e1 f5       	brne	.+120    	; 0x276c <xTaskGenericNotifyFromISR+0x10a>
			{
				/* The task should not have been on an event list. */
				configASSERT( listLIST_ITEM_CONTAINER( &( pxTCB->xEventListItem ) ) == NULL );

				if( uxSchedulerSuspended == ( UBaseType_t ) pdFALSE )
    26f4:	80 91 8d 06 	lds	r24, 0x068D
    26f8:	88 23       	and	r24, r24
    26fa:	e9 f4       	brne	.+58     	; 0x2736 <xTaskGenericNotifyFromISR+0xd4>
				{
					( void ) uxListRemove( &( pxTCB->xStateListItem ) );
    26fc:	8e 01       	movw	r16, r28
    26fe:	0e 5f       	subi	r16, 0xFE	; 254
    2700:	1f 4f       	sbci	r17, 0xFF	; 255
    2702:	c8 01       	movw	r24, r16
    2704:	0e 94 4a 05 	call	0xa94	; 0xa94 <uxListRemove>
					prvAddTaskToReadyList( pxTCB );
    2708:	8e 89       	ldd	r24, Y+22	; 0x16
    270a:	90 91 94 06 	lds	r25, 0x0694
    270e:	98 17       	cp	r25, r24
    2710:	10 f4       	brcc	.+4      	; 0x2716 <xTaskGenericNotifyFromISR+0xb4>
    2712:	80 93 94 06 	sts	0x0694, r24
    2716:	90 e0       	ldi	r25, 0x00	; 0
    2718:	9c 01       	movw	r18, r24
    271a:	22 0f       	add	r18, r18
    271c:	33 1f       	adc	r19, r19
    271e:	22 0f       	add	r18, r18
    2720:	33 1f       	adc	r19, r19
    2722:	22 0f       	add	r18, r18
    2724:	33 1f       	adc	r19, r19
    2726:	82 0f       	add	r24, r18
    2728:	93 1f       	adc	r25, r19
    272a:	82 56       	subi	r24, 0x62	; 98
    272c:	99 4f       	sbci	r25, 0xF9	; 249
    272e:	b8 01       	movw	r22, r16
    2730:	0e 94 f9 04 	call	0x9f2	; 0x9f2 <vListInsertEnd>
    2734:	07 c0       	rjmp	.+14     	; 0x2744 <xTaskGenericNotifyFromISR+0xe2>
				}
				else
				{
					/* The delayed and ready lists cannot be accessed, so hold
					this task pending until the scheduler is resumed. */
					vListInsertEnd( &( xPendingReadyList ), &( pxTCB->xEventListItem ) );
    2736:	be 01       	movw	r22, r28
    2738:	64 5f       	subi	r22, 0xF4	; 244
    273a:	7f 4f       	sbci	r23, 0xFF	; 255
    273c:	84 ed       	ldi	r24, 0xD4	; 212
    273e:	96 e0       	ldi	r25, 0x06	; 6
    2740:	0e 94 f9 04 	call	0x9f2	; 0x9f2 <vListInsertEnd>
				}

				if( pxTCB->uxPriority > pxCurrentTCB->uxPriority )
    2744:	e0 91 8b 06 	lds	r30, 0x068B
    2748:	f0 91 8c 06 	lds	r31, 0x068C
    274c:	9e 89       	ldd	r25, Y+22	; 0x16
    274e:	86 89       	ldd	r24, Z+22	; 0x16
    2750:	89 17       	cp	r24, r25
    2752:	70 f4       	brcc	.+28     	; 0x2770 <xTaskGenericNotifyFromISR+0x10e>
				{
					/* The notified task has a priority above the currently
					executing task so a yield is required. */
					if( pxHigherPriorityTaskWoken != NULL )
    2754:	e1 14       	cp	r14, r1
    2756:	f1 04       	cpc	r15, r1
    2758:	19 f0       	breq	.+6      	; 0x2760 <xTaskGenericNotifyFromISR+0xfe>
					{
						*pxHigherPriorityTaskWoken = pdTRUE;
    275a:	81 e0       	ldi	r24, 0x01	; 1
    275c:	f7 01       	movw	r30, r14
    275e:	80 83       	st	Z, r24
					}

					/* Mark that a yield is pending in case the user is not
					using the "xHigherPriorityTaskWoken" parameter to an ISR
					safe FreeRTOS function. */
					xYieldPending = pdTRUE;
    2760:	81 e0       	ldi	r24, 0x01	; 1
    2762:	80 93 91 06 	sts	0x0691, r24
    2766:	05 c0       	rjmp	.+10     	; 0x2772 <xTaskGenericNotifyFromISR+0x110>
						pxTCB->ulNotifiedValue = ulValue;
					}
					else
					{
						/* The value could not be written to the task. */
						xReturn = pdFAIL;
    2768:	80 e0       	ldi	r24, 0x00	; 0
    276a:	03 c0       	rjmp	.+6      	; 0x2772 <xTaskGenericNotifyFromISR+0x110>

			traceTASK_NOTIFY_FROM_ISR();

			/* If the task is in the blocked state specifically to wait for a
			notification then unblock it now. */
			if( ucOriginalNotifyState == taskWAITING_NOTIFICATION )
    276c:	81 e0       	ldi	r24, 0x01	; 1
    276e:	01 c0       	rjmp	.+2      	; 0x2772 <xTaskGenericNotifyFromISR+0x110>
					/* The delayed and ready lists cannot be accessed, so hold
					this task pending until the scheduler is resumed. */
					vListInsertEnd( &( xPendingReadyList ), &( pxTCB->xEventListItem ) );
				}

				if( pxTCB->uxPriority > pxCurrentTCB->uxPriority )
    2770:	81 e0       	ldi	r24, 0x01	; 1
			}
		}
		portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );

		return xReturn;
	}
    2772:	df 91       	pop	r29
    2774:	cf 91       	pop	r28
    2776:	1f 91       	pop	r17
    2778:	0f 91       	pop	r16
    277a:	ff 90       	pop	r15
    277c:	ef 90       	pop	r14
    277e:	08 95       	ret

00002780 <vTaskNotifyGiveFromISR>:
/*-----------------------------------------------------------*/

#if( configUSE_TASK_NOTIFICATIONS == 1 )

	void vTaskNotifyGiveFromISR( TaskHandle_t xTaskToNotify, BaseType_t *pxHigherPriorityTaskWoken )
	{
    2780:	ef 92       	push	r14
    2782:	ff 92       	push	r15
    2784:	0f 93       	push	r16
    2786:	1f 93       	push	r17
    2788:	cf 93       	push	r28
    278a:	df 93       	push	r29
    278c:	ec 01       	movw	r28, r24
    278e:	8b 01       	movw	r16, r22

		pxTCB = xTaskToNotify;

		uxSavedInterruptStatus = portSET_INTERRUPT_MASK_FROM_ISR();
		{
			ucOriginalNotifyState = pxTCB->ucNotifyState;
    2790:	2d a1       	lds	r18, 0x4d
			pxTCB->ucNotifyState = taskNOTIFICATION_RECEIVED;
    2792:	82 e0       	ldi	r24, 0x02	; 2
    2794:	8d a3       	lds	r24, 0x5d

			/* 'Giving' is equivalent to incrementing a count in a counting
			semaphore. */
			( pxTCB->ulNotifiedValue )++;
    2796:	89 a1       	lds	r24, 0x49
    2798:	9a a1       	lds	r25, 0x4a
    279a:	ab a1       	lds	r26, 0x4b
    279c:	bc a1       	lds	r27, 0x4c
    279e:	01 96       	adiw	r24, 0x01	; 1
    27a0:	a1 1d       	adc	r26, r1
    27a2:	b1 1d       	adc	r27, r1
    27a4:	89 a3       	lds	r24, 0x59
    27a6:	9a a3       	lds	r25, 0x5a
    27a8:	ab a3       	lds	r26, 0x5b
    27aa:	bc a3       	lds	r27, 0x5c

			traceTASK_NOTIFY_GIVE_FROM_ISR();

			/* If the task is in the blocked state specifically to wait for a
			notification then unblock it now. */
			if( ucOriginalNotifyState == taskWAITING_NOTIFICATION )
    27ac:	21 30       	cpi	r18, 0x01	; 1
    27ae:	e1 f5       	brne	.+120    	; 0x2828 <vTaskNotifyGiveFromISR+0xa8>
			{
				/* The task should not have been on an event list. */
				configASSERT( listLIST_ITEM_CONTAINER( &( pxTCB->xEventListItem ) ) == NULL );

				if( uxSchedulerSuspended == ( UBaseType_t ) pdFALSE )
    27b0:	80 91 8d 06 	lds	r24, 0x068D
    27b4:	88 23       	and	r24, r24
    27b6:	01 f5       	brne	.+64     	; 0x27f8 <vTaskNotifyGiveFromISR+0x78>
				{
					( void ) uxListRemove( &( pxTCB->xStateListItem ) );
    27b8:	ee 24       	eor	r14, r14
    27ba:	ff 24       	eor	r15, r15
    27bc:	68 94       	set
    27be:	e1 f8       	bld	r14, 1
    27c0:	ec 0e       	add	r14, r28
    27c2:	fd 1e       	adc	r15, r29
    27c4:	c7 01       	movw	r24, r14
    27c6:	0e 94 4a 05 	call	0xa94	; 0xa94 <uxListRemove>
					prvAddTaskToReadyList( pxTCB );
    27ca:	8e 89       	ldd	r24, Y+22	; 0x16
    27cc:	90 91 94 06 	lds	r25, 0x0694
    27d0:	98 17       	cp	r25, r24
    27d2:	10 f4       	brcc	.+4      	; 0x27d8 <vTaskNotifyGiveFromISR+0x58>
    27d4:	80 93 94 06 	sts	0x0694, r24
    27d8:	90 e0       	ldi	r25, 0x00	; 0
    27da:	9c 01       	movw	r18, r24
    27dc:	22 0f       	add	r18, r18
    27de:	33 1f       	adc	r19, r19
    27e0:	22 0f       	add	r18, r18
    27e2:	33 1f       	adc	r19, r19
    27e4:	22 0f       	add	r18, r18
    27e6:	33 1f       	adc	r19, r19
    27e8:	82 0f       	add	r24, r18
    27ea:	93 1f       	adc	r25, r19
    27ec:	82 56       	subi	r24, 0x62	; 98
    27ee:	99 4f       	sbci	r25, 0xF9	; 249
    27f0:	b7 01       	movw	r22, r14
    27f2:	0e 94 f9 04 	call	0x9f2	; 0x9f2 <vListInsertEnd>
    27f6:	07 c0       	rjmp	.+14     	; 0x2806 <vTaskNotifyGiveFromISR+0x86>
				}
				else
				{
					/* The delayed and ready lists cannot be accessed, so hold
					this task pending until the scheduler is resumed. */
					vListInsertEnd( &( xPendingReadyList ), &( pxTCB->xEventListItem ) );
    27f8:	be 01       	movw	r22, r28
    27fa:	64 5f       	subi	r22, 0xF4	; 244
    27fc:	7f 4f       	sbci	r23, 0xFF	; 255
    27fe:	84 ed       	ldi	r24, 0xD4	; 212
    2800:	96 e0       	ldi	r25, 0x06	; 6
    2802:	0e 94 f9 04 	call	0x9f2	; 0x9f2 <vListInsertEnd>
				}

				if( pxTCB->uxPriority > pxCurrentTCB->uxPriority )
    2806:	e0 91 8b 06 	lds	r30, 0x068B
    280a:	f0 91 8c 06 	lds	r31, 0x068C
    280e:	9e 89       	ldd	r25, Y+22	; 0x16
    2810:	86 89       	ldd	r24, Z+22	; 0x16
    2812:	89 17       	cp	r24, r25
    2814:	48 f4       	brcc	.+18     	; 0x2828 <vTaskNotifyGiveFromISR+0xa8>
				{
					/* The notified task has a priority above the currently
					executing task so a yield is required. */
					if( pxHigherPriorityTaskWoken != NULL )
    2816:	01 15       	cp	r16, r1
    2818:	11 05       	cpc	r17, r1
    281a:	19 f0       	breq	.+6      	; 0x2822 <vTaskNotifyGiveFromISR+0xa2>
					{
						*pxHigherPriorityTaskWoken = pdTRUE;
    281c:	81 e0       	ldi	r24, 0x01	; 1
    281e:	f8 01       	movw	r30, r16
    2820:	80 83       	st	Z, r24
					}

					/* Mark that a yield is pending in case the user is not
					using the "xHigherPriorityTaskWoken" parameter in an ISR
					safe FreeRTOS function. */
					xYieldPending = pdTRUE;
    2822:	81 e0       	ldi	r24, 0x01	; 1
    2824:	80 93 91 06 	sts	0x0691, r24
					mtCOVERAGE_TEST_MARKER();
				}
			}
		}
		portCLEAR_INTERRUPT_MASK_FROM_ISR( uxSavedInterruptStatus );
	}
    2828:	df 91       	pop	r29
    282a:	cf 91       	pop	r28
    282c:	1f 91       	pop	r17
    282e:	0f 91       	pop	r16
    2830:	ff 90       	pop	r15
    2832:	ef 90       	pop	r14
    2834:	08 95       	ret

00002836 <xTaskNotifyStateClear>:
	TCB_t *pxTCB;
	BaseType_t xReturn;

		/* If null is passed in here then it is the calling task that is having
		its notification state cleared. */
		pxTCB = prvGetTCBFromHandle( xTask );
    2836:	00 97       	sbiw	r24, 0x00	; 0
    2838:	29 f4       	brne	.+10     	; 0x2844 <xTaskNotifyStateClear+0xe>
    283a:	e0 91 8b 06 	lds	r30, 0x068B
    283e:	f0 91 8c 06 	lds	r31, 0x068C
    2842:	01 c0       	rjmp	.+2      	; 0x2846 <xTaskNotifyStateClear+0x10>
    2844:	fc 01       	movw	r30, r24

		taskENTER_CRITICAL();
    2846:	0f b6       	in	r0, 0x3f	; 63
    2848:	f8 94       	cli
    284a:	0f 92       	push	r0
		{
			if( pxTCB->ucNotifyState == taskNOTIFICATION_RECEIVED )
    284c:	85 a1       	lds	r24, 0x45
    284e:	82 30       	cpi	r24, 0x02	; 2
    2850:	19 f4       	brne	.+6      	; 0x2858 <xTaskNotifyStateClear+0x22>
			{
				pxTCB->ucNotifyState = taskNOT_WAITING_NOTIFICATION;
    2852:	15 a2       	lds	r17, 0x95
				xReturn = pdPASS;
    2854:	81 e0       	ldi	r24, 0x01	; 1
    2856:	01 c0       	rjmp	.+2      	; 0x285a <xTaskNotifyStateClear+0x24>
			}
			else
			{
				xReturn = pdFAIL;
    2858:	80 e0       	ldi	r24, 0x00	; 0
			}
		}
		taskEXIT_CRITICAL();
    285a:	0f 90       	pop	r0
    285c:	0f be       	out	0x3f, r0	; 63

		return xReturn;
	}
    285e:	08 95       	ret

00002860 <memcpy>:
    2860:	fb 01       	movw	r30, r22
    2862:	dc 01       	movw	r26, r24
    2864:	02 c0       	rjmp	.+4      	; 0x286a <memcpy+0xa>
    2866:	01 90       	ld	r0, Z+
    2868:	0d 92       	st	X+, r0
    286a:	41 50       	subi	r20, 0x01	; 1
    286c:	50 40       	sbci	r21, 0x00	; 0
    286e:	d8 f7       	brcc	.-10     	; 0x2866 <memcpy+0x6>
    2870:	08 95       	ret

00002872 <_exit>:
    2872:	f8 94       	cli

00002874 <__stop_program>:
    2874:	ff cf       	rjmp	.-2      	; 0x2874 <__stop_program>
